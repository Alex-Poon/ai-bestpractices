---
title: "Claude Opus 4.6"
source_url: "https://www.anthropic.com/news/claude-opus-4-6"
hn_url: "https://news.ycombinator.com/item?id=46902223"
date: 2026-02-05
hn_points: 1981
hn_comment_count: 106
tags: [model-release, anthropic, claude, opus, benchmarks, agent-teams, long-context]
tier: 2
weight: 1
---

## Summary

Anthropic announced Claude Opus 4.6, their most advanced model to date, featuring a landmark 1 million token context window in beta -- the first for an Opus-class model. The release emphasizes substantial improvements in agentic coding, long-context work, and sustained multi-step workflows.

On benchmarks, Opus 4.6 achieved the top score on Terminal-Bench 2.0 for agentic coding and led on Humanity's Last Exam for complex reasoning. On GDPval-AA, which measures economically valuable work tasks, it outperformed the industry's next-best model by a significant margin. Long-context retrieval accuracy hit 76% on needle-in-haystack tests compared to much lower scores from competitors.

The release coincided with Claude Code version 2.1.32, which introduced several notable features: a research preview of agent teams for multi-agent collaboration, automatic memory recording and recall during work sessions, and a "Summarize from here" message selector feature. The agent teams feature requires an experimental flag and is described as token-intensive.

Anthropic also offered promotional credits to encourage testing the new model. The release came less than 35 minutes before OpenAI announced GPT-5.3 Codex, creating a memorable moment of simultaneous frontier model launches.

Beyond coding, the model handles financial analysis, research, and document work. Safety evaluations show it maintains or exceeds standards of prior frontier models with low rates of misaligned behavior.

## Key Insights

- **1M context is the real headline**: While benchmarks impress, the Opus-class 1M token context window opens new use cases for working with entire codebases
- **Agent teams go native**: Multi-agent collaboration is now built into Claude Code, reducing friction compared to third-party coordination tools
- **Competitive pressure accelerates releases**: The near-simultaneous launch with GPT-5.3 Codex highlights the pace of frontier model competition

## Notable Quotes

> "We build Claude with Claude" — Anthropic (per blibble's commentary)

> "1M context on an Opus-class model is the real headline" — dmk

## HN Discussion Highlights

The discussion generated 1981 points and 106 comments. Key themes:

**Benchmark performance and real-world testing**
- **ck_one**: Tested the 1M context by searching all Harry Potter books for spells, finding 49 of 50 documented spells across four books fitting within the context window
- **gizmodo59**: Noted OpenAI's GPT-5.3 Codex launched within 35 minutes claiming higher Terminal-Bench scores, calling it the shortest-lived benchmark lead
- **blueblisters**: Found Opus 4.6 helpful when GPT-5.2 got stuck on unusual tasks like debugging VIO algorithms, though considers GPT models to have higher raw intelligence for coding

**Practical concerns and limitations**
- **hmaxwell**: Complained about strict rate limits making it impractical despite good output quality
- **replwoacause**: Described being conditioned to avoid Opus models on the Pro plan because light usage depletes daily allocation
- **atonse**: Reported the model making basic mistakes in its first 15 minutes of use, particularly when editing its own MCP configs

**Agent teams and multi-agent collaboration**
- **pjot**: Documented the Claude Code 2.1.32 release notes showing agent teams as a research preview requiring an experimental flag
- **anupamchugh**: Compared the built-in agent teams to existing mcp-agent-mail patterns, noting the native version wins on reduced friction for within-session coordination
- **Someone1234**: Raised questions about the economics of running multiple LLM agents and whether costs are falling enough to make agent teams practical

**Strategic observations**
- **legitster**: Questioned Anthropic's strategy of pursuing both consumer and developer markets, noting Claude excels at coding but ChatGPT and Gemini perform better for general research
