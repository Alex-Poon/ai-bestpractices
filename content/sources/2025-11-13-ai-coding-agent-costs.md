---
title: "I spent $638 on AI coding agents in 6 weeks"
source_url: "https://news.ycombinator.com/item?id=45914307"
hn_url: "https://news.ycombinator.com/item?id=45914307"
date: 2025-11-13
hn_points: 1
hn_comment_count: 5
tags: [cost-optimization, cursor, claude-code, model-selection, pricing]
tier: 2
weight: 97
---

## Summary

A founder and CTO building an AI-first CRM product shared a detailed breakdown of their AI coding costs, revealing surprisingly high expenses from using Cursor with Claude models. Over a six-week period spanning October and November 2025, the author accumulated $638 in on-demand charges, with October alone costing $348.56 and hitting Cursor's $400 limit.

The cost analysis revealed that Claude 4.5 Sonnet Thinking requests ranged from $0.02 to $0.06 depending on context size, which seemed modest per-request but compounded rapidly at 200+ daily requests. The author experimented with 7 different models (GPT-5, Gemini 2.5 Pro, Cheetah, and others) but found Claude consumed 85% of the budget because it consistently produced the best results.

The post asked fundamental questions about the sustainability of AI-assisted development costs, projecting annual expenses of $5,500+ just for code assistance. It raised the question of whether the productivity gains justify these costs and at what price point developers would reconsider their usage patterns.

A follow-up comment from the author included detailed Cursor usage statistics generated by Sonnet: total cost of $928.45 over 70 days, average of 70.7 requests per 5-hour block, median time between requests of just 13 seconds indicating burst activity patterns, and an impressive 88.8% cache hit rate that significantly reduced what costs would otherwise have been.

## Key Insights

- **Costs compound at scale**: Per-request costs of $0.02-0.06 seem trivial but reach $400+/month with heavy usage patterns of 200+ daily requests
- **Model quality drives spend**: Despite trying 7 alternatives, 85% of budget went to Claude because quality differences in output justified the premium
- **Cache hit rates matter**: An 88.8% cache hit rate significantly controlled costs, suggesting caching strategies are critical for heavy users
- **Pricing model instability**: The author observed that AI coding pricing has not stabilized, creating uncertainty for budgeting

## Notable Quotes

> "more than some cloud bills" — nthypes (HN submission)

## HN Discussion Highlights

*8 comments total*

**nthypes** (OP): Shared detailed Cursor-generated usage stats: $928.45 over 70 days, average $0.06/request, projected monthly cost ~$416. Median time between requests was just 13 seconds (burst activity). Cache hit rate of 88.8% saved significant costs...

**Rochus**: Asked about concrete ROI. Reported mixed results with Claude Sonnet and Opus where re-work consumed most time savings. Found GPT-5 via Perplexity produced code that usually compiles and runs correctly up front...

> **nthypes**: Replied that the value-to-token ratio feels off. Many of those 340M tokens feel wasteful — the LLM uses 50k tokens exploring dead ends before finding a solution expressible in 5k tokens. The productivity gain is real but feels like paying 10x more than fair...

**Woods369**: Agreed with the closing questions. Noted pricing fluctuation as companies find the sweet spot. Mentioned Warp terminal's new plan with lower cost per request, citing their acknowledgment that plans didn't scale sustainably at full usage...

**mnky9800n**: Recommended Claude Code Max ($125/month flat) — runs multiple agents on clusters doing research as a scientist with no cost surprises. Suggested the $638/6 weeks is a budget question for the founder to decide...

> **nthypes**: Noted even Claude Code Max's $200/month plan has weekly rate limits (240-480 hours Sonnet 4, 24-40 hours Opus 4/week). Main concern: if AI coding becomes a $5-6k/year baseline expense per developer, it changes unit economics for early-stage companies...

>> **mnky9800n**: Argued that when testing ideas you can't also be thinking about efficiency. The LLM explores different solutions to arrive at ones that work — those tokens on bad solutions were useful. Many software licenses cost multiples of $5-6k/year and are still worth it...

**6510**: Suggested it's important to consider training costs — proficiency requires practice, and from now on everything you do will be this expensive.
