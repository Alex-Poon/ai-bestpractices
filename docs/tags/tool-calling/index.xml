<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tool-Calling on AI Best Practices Knowledge Base</title>
    <link>/tags/tool-calling.html</link>
    <description>Recent content in Tool-Calling on AI Best Practices Knowledge Base</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Feb 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/tool-calling/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>I Improved 15 LLMs at Coding in One Afternoon. Only the Harness Changed.</title>
      <link>/sources/2026-02-12-harness-problem-hashline.html</link>
      <pubDate>Thu, 12 Feb 2026 00:00:00 +0000</pubDate>
      <guid>/sources/2026-02-12-harness-problem-hashline.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;Can Boluk argues that the biggest bottleneck in LLM-assisted coding is not the model itself but the harness — the layer that translates a model&amp;rsquo;s intent into actual file edits. Most current edit mechanisms force models to reproduce existing code verbatim in order to specify what they want to change, and this reproduction step is where things break down. Patch-based formats (used by OpenAI&amp;rsquo;s Codex ecosystem) suffer catastrophic failure rates on non-Codex models, with some models failing nearly half their edit attempts. String replacement approaches (used by Claude Code and Gemini CLI) require exact character-for-character matching including whitespace, leading to frequent &amp;ldquo;string not found&amp;rdquo; errors. Cursor addressed this by training a dedicated 70B parameter model just to merge edits — an enormous investment that sidesteps rather than solves the underlying problem.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Code Claude Code in 200 Lines of Code</title>
      <link>/sources/2026-01-08-claude-code-200-lines.html</link>
      <pubDate>Thu, 08 Jan 2026 00:00:00 +0000</pubDate>
      <guid>/sources/2026-01-08-claude-code-200-lines.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;Mihail Eric&amp;rsquo;s article, provocatively titled &amp;ldquo;The Emperor Has No Clothes,&amp;rdquo; argues that AI coding assistants are not magical — they follow a simple architectural loop. The user sends a request, the LLM decides which tools to call, your code executes those tools locally, and the results flow back to the LLM for context. The critical mental model is that the LLM never actually touches your filesystem; it asks for things to happen, and your code makes them happen.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
