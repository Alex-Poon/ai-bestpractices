<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Model-Selection on AI Best Practices Knowledge Base</title>
    <link>/tags/model-selection.html</link>
    <description>Recent content in Model-Selection on AI Best Practices Knowledge Base</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Feb 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/model-selection/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Model Deep Dive</title>
      <link>/tools/models.html</link>
      <pubDate>Fri, 06 Feb 2026 00:00:00 +0000</pubDate>
      <guid>/tools/models.html</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;../../practices/model-selection.html&#34;&gt;model selection&lt;/a&gt; practice page covers the principles. This page is the complement &amp;ndash; what each model actually feels like to use, based on 800+ practitioner reports gathered from Hacker News discussions and targeted Algolia searches. Specs and pricing live in the &lt;a href=&#34;#compact-reference&#34;&gt;compact reference&lt;/a&gt; at the bottom.&lt;/p&gt;&#xA;&lt;h2 id=&#34;how-practitioners-describe-these-models&#34;&gt;How Practitioners Describe These Models&lt;/h2&gt;&#xA;&lt;p&gt;Before the deep dives, the metaphors practitioners reach for:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Claude Code (Opus):&lt;/strong&gt; &amp;ldquo;A shitty, but very fast and very knowledgeable junior developer&amp;rdquo; requiring constant supervision (msikora). Required over a month to reach baseline productivity.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Codex CLI (GPT-5.2):&lt;/strong&gt; &amp;ldquo;Felt like working with a peer&amp;rdquo; for the first time in 20+ years of development (dudeinhawaii). Also: &amp;ldquo;an outsourced consultant who refuses to say I can&amp;rsquo;t do that&amp;rdquo; (theshrike79).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;GPT-5.2:&lt;/strong&gt; &amp;ldquo;Rude and cold&amp;rdquo; but strict instruction-following (jorl17). Hallucinating CLI utilities and non-existent features is a recurring pattern (heavyset_go).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Gemini 3:&lt;/strong&gt; &amp;ldquo;Biased toward action and uncontrollable&amp;rdquo; (mmaunder). Fast for agent loops but generates a &amp;ldquo;fog of code&amp;rdquo; where developers struggle to understand what was generated (sottol).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;o3/o3-pro:&lt;/strong&gt; &amp;ldquo;o3 for thinking, Claude for doing&amp;rdquo; &amp;ndash; the dominant practitioner workflow. One-shots problems other models fail on, but 10-15 minute response times make interactive use impractical.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;claude-family-anthropic&#34;&gt;Claude Family (Anthropic)&lt;/h2&gt;&#xA;&lt;p&gt;The defining split in the Claude family is philosophical: &lt;strong&gt;Opus 4.5 is a guided pair programmer&lt;/strong&gt;; &lt;strong&gt;Opus 4.6 is an autonomous agent&lt;/strong&gt;. This isn&amp;rsquo;t just marketing &amp;ndash; practitioners experience them as fundamentally different tools.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apple picks Gemini to power Siri</title>
      <link>/sources/2026-01-12-apple-picks-gemini-siri.html</link>
      <pubDate>Mon, 12 Jan 2026 00:00:00 +0000</pubDate>
      <guid>/sources/2026-01-12-apple-picks-gemini-siri.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;Apple announced a partnership with Google to use Gemini as the foundational AI technology powering Siri, marking one of the most significant strategic moves in the AI industry. The deal, reportedly valued near $1 billion, represents Apple&amp;rsquo;s acknowledgment that building competitive frontier AI models in-house is not where their advantage lies.&lt;/p&gt;&#xA;&lt;p&gt;Apple&amp;rsquo;s decision was driven by several practical realities. Despite having world-class edge inference silicon through their Neural Engine, Apple has effectively zero presence in training datacenters &amp;ndash; lacking the TPU pods or GPU clusters needed to train frontier models from scratch. Google, by contrast, has deep pockets, enterprise infrastructure experience, and diversified revenue streams that make them a stable long-term partner.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Model Selection</title>
      <link>/practices/model-selection.html</link>
      <pubDate>Fri, 06 Feb 2026 00:00:00 +0000</pubDate>
      <guid>/practices/model-selection.html</guid>
      <description>&lt;p&gt;Model selection is the skill of matching the right model to the right task. The gap between a well-chosen and poorly-chosen model often matters more than the quality of the prompt itself. As models proliferate and differentiate, this is no longer a set-and-forget decision &amp;ndash; it is an ongoing practice of matching capability to need.&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-model-selection-is&#34;&gt;What Model Selection Is&lt;/h2&gt;&#xA;&lt;p&gt;Model selection means choosing which AI model (or combination of models) to use for a specific task, based on the task&amp;rsquo;s complexity, error tolerance, speed requirements, and cost constraints. It also means knowing when to switch models mid-task, when to use multiple models for cross-validation, and when to escalate from a cheap model to an expensive one.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Coding with LLMs in 2026: The Model Matters More Than the Prompts</title>
      <link>/sources/2026-01-18-model-matters-more-than-prompts.html</link>
      <pubDate>Sun, 18 Jan 2026 00:00:00 +0000</pubDate>
      <guid>/sources/2026-01-18-model-matters-more-than-prompts.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;This post by @slow_developer on X (formerly Twitter) argues that the shift from 2025 to 2026 in AI-assisted coding has been defined by a fundamental rebalancing: model choice now outweighs prompt engineering as the primary lever for coding quality. Where 2025 workflows focused heavily on crafting precise prompts and structuring interactions carefully, the advancements in frontier models have made the underlying model capability the dominant factor in output quality.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM coding workflow going into 2026</title>
      <link>/sources/2026-01-10-llm-coding-workflow-2026.html</link>
      <pubDate>Sat, 10 Jan 2026 00:00:00 +0000</pubDate>
      <guid>/sources/2026-01-10-llm-coding-workflow-2026.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;Addy Osmani, a well-known Google engineering leader, shared his comprehensive approach to integrating LLMs into daily coding workflows. The article frames LLMs not as autonomous coders but as powerful pair programmers requiring clear direction, context, and consistent oversight.&lt;/p&gt;&#xA;&lt;p&gt;The workflow begins with collaborative planning, where the developer works with an AI to develop detailed specifications and project plans before writing code. Osmani describes this as achieving a traditional waterfall planning cycle compressed into roughly 15 minutes. Implementation then proceeds in small, iterative chunks sized to fit within context windows and remain comprehensible for human review.&lt;/p&gt;</description>
    </item>
    <item>
      <title>I spent $638 on AI coding agents in 6 weeks</title>
      <link>/sources/2025-11-13-ai-coding-agent-costs.html</link>
      <pubDate>Thu, 13 Nov 2025 00:00:00 +0000</pubDate>
      <guid>/sources/2025-11-13-ai-coding-agent-costs.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;A founder and CTO building an AI-first CRM product shared a detailed breakdown of their AI coding costs, revealing surprisingly high expenses from using Cursor with Claude models. Over a six-week period spanning October and November 2025, the author accumulated $638 in on-demand charges, with October alone costing $348.56 and hitting Cursor&amp;rsquo;s $400 limit.&lt;/p&gt;&#xA;&lt;p&gt;The cost analysis revealed that Claude 4.5 Sonnet Thinking requests ranged from $0.02 to $0.06 depending on context size, which seemed modest per-request but compounded rapidly at 200+ daily requests. The author experimented with 7 different models (GPT-5, Gemini 2.5 Pro, Cheetah, and others) but found Claude consumed 85% of the budget because it consistently produced the best results.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
