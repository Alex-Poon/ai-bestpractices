<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Anthropic on AI Best Practices Knowledge Base</title>
    <link>/tags/anthropic.html</link>
    <description>Recent content in Anthropic on AI Best Practices Knowledge Base</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Feb 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/anthropic/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Claude Code is being dumbed down?</title>
      <link>/sources/2026-02-11-claude-code-dumbed-down.html</link>
      <pubDate>Wed, 11 Feb 2026 00:00:00 +0000</pubDate>
      <guid>/sources/2026-02-11-claude-code-dumbed-down.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;A blog post from SymmetryBreak criticizes Anthropic for reducing transparency in Claude Code version 2.1.20. The update replaced detailed file-level information during agent operations with vague summaries — instead of showing which specific files were read or which patterns were searched, the tool now displays generic messages like &amp;ldquo;Read 3 files&amp;rdquo; or &amp;ldquo;Searched for 1 pattern.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;The author argues this represents a classic product management anti-pattern: stripping useful information under the banner of simplification. Multiple GitHub issues document user complaints about the change, but the response from Anthropic was to point users toward &amp;ldquo;verbose mode&amp;rdquo; as a workaround. The author finds this inadequate — verbose mode dumps excessive debug output including full file contents and sub-agent transcripts, creating a binary choice between too little and too much information.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Claude Opus 4.6</title>
      <link>/sources/2026-02-05-claude-opus-4-6.html</link>
      <pubDate>Thu, 05 Feb 2026 00:00:00 +0000</pubDate>
      <guid>/sources/2026-02-05-claude-opus-4-6.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;Anthropic announced Claude Opus 4.6, their most advanced model to date, featuring a landmark 1 million token context window in beta &amp;ndash; the first for an Opus-class model. The release emphasizes substantial improvements in agentic coding, long-context work, and sustained multi-step workflows.&lt;/p&gt;&#xA;&lt;p&gt;On benchmarks, Opus 4.6 achieved the top score on Terminal-Bench 2.0 for agentic coding and led on Humanity&amp;rsquo;s Last Exam for complex reasoning. On GDPval-AA, which measures economically valuable work tasks, it outperformed the industry&amp;rsquo;s next-best model by a significant margin. Long-context retrieval accuracy hit 76% on needle-in-haystack tests compared to much lower scores from competitors.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How AI assistance impacts the formation of coding skills</title>
      <link>/sources/2026-01-30-ai-assistance-coding-skills.html</link>
      <pubDate>Fri, 30 Jan 2026 00:00:00 +0000</pubDate>
      <guid>/sources/2026-01-30-ai-assistance-coding-skills.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;Anthropic published a randomized controlled study examining how AI assistance affects skill acquisition among junior software engineers. The research involved 52 participants divided into AI-assisted and control groups, tasked with learning and using Trio (a Python asynchronous programming library). After completing coding tasks, participants took a comprehension quiz covering debugging, code reading, code writing, and conceptual understanding.&lt;/p&gt;&#xA;&lt;p&gt;The results revealed a significant trade-off between speed and learning. The AI-assisted group scored 17% lower on the comprehension quiz, a gap the researchers characterized as equivalent to nearly two letter grades, with a large effect size (Cohen&amp;rsquo;s d of 0.738, p=0.01). The largest performance gap appeared on debugging questions, suggesting that AI assistance particularly impairs the development of error identification skills. Meanwhile, AI users finished tasks roughly two minutes faster on average, though this speed advantage was not statistically significant.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tell HN: Claude Has Had 57 Incidents in the Past 3 Months</title>
      <link>/sources/2026-02-04-claude-57-incidents-3-months.html</link>
      <pubDate>Wed, 04 Feb 2026 00:00:00 +0000</pubDate>
      <guid>/sources/2026-02-04-claude-57-incidents-3-months.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;This HN text post by shikkra documents reliability concerns with Anthropic&amp;rsquo;s Claude service, providing a detailed incident count from the official status page (status.claude.com). The author, a $100/month Max plan subscriber, was prompted to investigate after encountering a retry issue where Claude attempted to generate a response 10 times with Opus 4.5 and extended thinking enabled before silently switching to a different model without indication or confirmation.&lt;/p&gt;&#xA;&lt;p&gt;The incident data paints a concerning picture of service reliability. February 2026 had 10 incidents in just 4 days. January 2026 had 26 incidents. December 2025 had 21 incidents. At least 16 of these directly affected Claude Opus 4.5: 3 incidents in December (21-23), 9 in January (across 7-28), and 4 in February (1-4). Ten additional incidents affected the claude.ai platform itself.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
