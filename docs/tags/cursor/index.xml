<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cursor on AI Best Practices Knowledge Base</title>
    <link>//localhost:1314/tags/cursor.html</link>
    <description>Recent content in Cursor on AI Best Practices Knowledge Base</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Feb 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="//localhost:1314/tags/cursor/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Cursor</title>
      <link>//localhost:1314/tools/cursor.html</link>
      <pubDate>Fri, 06 Feb 2026 00:00:00 +0000</pubDate>
      <guid>//localhost:1314/tools/cursor.html</guid>
      <description>&lt;p&gt;Cursor is a VS Code fork with AI capabilities built directly into the editor. It offers both autocomplete (Tab) and agentic (Composer/Agent) modes as first-class features, multi-model support with user-selectable models, and pricing starting at $20/month with usage-based tiers for heavier workloads. It has the largest adoption among AI coding tools in the IDE-first category.&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-cursor-does-well&#34;&gt;What Cursor Does Well&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Low friction entry point.&lt;/strong&gt; Because Cursor is a VS Code fork, developers who already use VS Code can switch with minimal disruption. Extensions, keybindings, and settings transfer directly. This removes the adoption barrier that CLI-first tools face with developers unfamiliar with terminal workflows.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Coding with LLMs in 2026: The Model Matters More Than the Prompts</title>
      <link>//localhost:1314/sources/2026-01-18-model-matters-more-than-prompts.html</link>
      <pubDate>Sun, 18 Jan 2026 00:00:00 +0000</pubDate>
      <guid>//localhost:1314/sources/2026-01-18-model-matters-more-than-prompts.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;This post by @slow_developer on X (formerly Twitter) argues that the shift from 2025 to 2026 in AI-assisted coding has been defined by a fundamental rebalancing: model choice now outweighs prompt engineering as the primary lever for coding quality. Where 2025 workflows focused heavily on crafting precise prompts and structuring interactions carefully, the advancements in frontier models have made the underlying model capability the dominant factor in output quality.&lt;/p&gt;</description>
    </item>
    <item>
      <title>I spent $638 on AI coding agents in 6 weeks</title>
      <link>//localhost:1314/sources/2025-11-13-ai-coding-agent-costs.html</link>
      <pubDate>Thu, 13 Nov 2025 00:00:00 +0000</pubDate>
      <guid>//localhost:1314/sources/2025-11-13-ai-coding-agent-costs.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;A founder and CTO building an AI-first CRM product shared a detailed breakdown of their AI coding costs, revealing surprisingly high expenses from using Cursor with Claude models. Over a six-week period spanning October and November 2025, the author accumulated $638 in on-demand charges, with October alone costing $348.56 and hitting Cursor&amp;rsquo;s $400 limit.&lt;/p&gt;&#xA;&lt;p&gt;The cost analysis revealed that Claude 4.5 Sonnet Thinking requests ranged from $0.02 to $0.06 depending on context size, which seemed modest per-request but compounded rapidly at 200+ daily requests. The author experimented with 7 different models (GPT-5, Gemini 2.5 Pro, Cheetah, and others) but found Claude consumed 85% of the budget because it consistently produced the best results.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
