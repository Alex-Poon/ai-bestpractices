<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Coding-Agents on AI Best Practices Knowledge Base</title>
    <link>//localhost:1314/tags/coding-agents.html</link>
    <description>Recent content in Coding-Agents on AI Best Practices Knowledge Base</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 Jan 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="//localhost:1314/tags/coding-agents/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How to Code Claude Code in 200 Lines of Code</title>
      <link>//localhost:1314/sources/2026-01-08-claude-code-200-lines.html</link>
      <pubDate>Thu, 08 Jan 2026 00:00:00 +0000</pubDate>
      <guid>//localhost:1314/sources/2026-01-08-claude-code-200-lines.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;Mihail Eric&amp;rsquo;s article, provocatively titled &amp;ldquo;The Emperor Has No Clothes,&amp;rdquo; argues that AI coding assistants are not magical â€” they follow a simple architectural loop. The user sends a request, the LLM decides which tools to call, your code executes those tools locally, and the results flow back to the LLM for context. The critical mental model is that the LLM never actually touches your filesystem; it asks for things to happen, and your code makes them happen.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
