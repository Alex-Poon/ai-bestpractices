<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Memory-Systems on AI Best Practices Knowledge Base</title>
    <link>//localhost:1314/tags/memory-systems.html</link>
    <description>Recent content in Memory-Systems on AI Best Practices Knowledge Base</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Jan 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="//localhost:1314/tags/memory-systems/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Agentic Frameworks in 2026: Less Hype, More Autonomy</title>
      <link>//localhost:1314/sources/2026-01-06-agentic-frameworks-2026.html</link>
      <pubDate>Tue, 06 Jan 2026 00:00:00 +0000</pubDate>
      <guid>//localhost:1314/sources/2026-01-06-agentic-frameworks-2026.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;This HN text post by raghavchamadiya provides a practitioner-level comparison of agentic frameworks in 2026, focusing on lived behavior rather than benchmarks. The author has built, broken, and rebuilt agents across several stacks and shares observations on how the ecosystem has matured.&lt;/p&gt;&#xA;&lt;p&gt;The core thesis is that the key differentiator for frameworks has shifted from how they wrap prompting and tool calls (the 2024 approach) to how they model time, memory, and failure. Agents that cannot reason over long horizons or learn from their own mistakes collapse under real workloads regardless of how clever the prompt engineering looks in demos.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
