<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Code-Review on AI Best Practices Knowledge Base</title>
    <link>/tags/code-review.html</link>
    <description>Recent content in Code-Review on AI Best Practices Knowledge Base</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Feb 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/code-review/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Verification: Reading AI-Generated Code</title>
      <link>/skills/verification.html</link>
      <pubDate>Fri, 06 Feb 2026 00:00:00 +0000</pubDate>
      <guid>/skills/verification.html</guid>
      <description>&lt;p&gt;As AI takes over more code generation, the developer&amp;rsquo;s primary contribution shifts from writing to reading. Verification &amp;ndash; the ability to evaluate whether AI-generated code is correct, secure, and aligned with intent &amp;ndash; becomes the skill that separates productive AI usage from expensive mistakes.&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-verification-matters-more-than-generation&#34;&gt;Why Verification Matters More Than Generation&lt;/h2&gt;&#xA;&lt;p&gt;The economics of AI-assisted development are asymmetric. Generating code is now cheap and fast. Deploying broken code is still expensive and slow to fix. The bottleneck has moved from production to quality control.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Two Kinds of Vibe Coding</title>
      <link>/sources/2025-12-18-two-kinds-vibe-coding.html</link>
      <pubDate>Thu, 18 Dec 2025 00:00:00 +0000</pubDate>
      <guid>/sources/2025-12-18-two-kinds-vibe-coding.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;David Bau distinguishes between two fundamentally different approaches to what has broadly been called &amp;ldquo;vibe coding.&amp;rdquo; The first type involves delegating small tasks to an LLM while the human programmer remains fully informed and in control, reviewing each piece of work and making all key decisions. The second type involves surrendering cognitive control to an AI agent, allowing it to build towers of complexity that go beyond what the developer has time to understand in detail.&lt;/p&gt;</description>
    </item>
    <item>
      <title>My LLM Coding Workflow Going into 2026</title>
      <link>/sources/2026-01-04-llm-coding-workflow-2026.html</link>
      <pubDate>Sun, 04 Jan 2026 00:00:00 +0000</pubDate>
      <guid>/sources/2026-01-04-llm-coding-workflow-2026.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;Addy Osmani, a well-known figure in the web development community, shares his comprehensive approach to AI-augmented software engineering. The central philosophy treats LLMs as powerful pair programmers that require clear direction, context, and human oversight rather than autonomous replacements for developers.&lt;/p&gt;&#xA;&lt;p&gt;The workflow is structured around several core practices. First, planning comes before coding — create detailed specifications, use AI to iteratively flesh out requirements and edge cases, and generate project plans that break work into bite-sized tasks. Osmani describes this as completing a &amp;ldquo;waterfall in 15 minutes&amp;rdquo; to prevent wasted development cycles. Second, iterative chunking — break projects into small manageable pieces rather than requesting monolithic outputs, processing one feature at a time while maintaining context of previous work. Third, context provision — feed the AI all relevant code, documentation, and constraints using tools like gitingest or repo2txt to bundle repository information, and provide style guides through CLAUDE.md files.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM coding workflow going into 2026</title>
      <link>/sources/2026-01-10-llm-coding-workflow-2026.html</link>
      <pubDate>Sat, 10 Jan 2026 00:00:00 +0000</pubDate>
      <guid>/sources/2026-01-10-llm-coding-workflow-2026.html</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;Addy Osmani, a well-known Google engineering leader, shared his comprehensive approach to integrating LLMs into daily coding workflows. The article frames LLMs not as autonomous coders but as powerful pair programmers requiring clear direction, context, and consistent oversight.&lt;/p&gt;&#xA;&lt;p&gt;The workflow begins with collaborative planning, where the developer works with an AI to develop detailed specifications and project plans before writing code. Osmani describes this as achieving a traditional waterfall planning cycle compressed into roughly 15 minutes. Implementation then proceeds in small, iterative chunks sized to fit within context windows and remain comprehensible for human review.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
