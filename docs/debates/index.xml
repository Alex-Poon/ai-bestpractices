<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Debates on AI Best Practices Knowledge Base</title>
    <link>/debates/index.html</link>
    <description>Recent content in Debates on AI Best Practices Knowledge Base</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Feb 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="/debates/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Is AI-Assisted Coding Getting Worse?</title>
      <link>/debates/is-it-getting-worse.html</link>
      <pubDate>Fri, 06 Feb 2026 00:00:00 +0000</pubDate>
      <guid>/debates/is-it-getting-worse.html</guid>
      <description>&lt;h2 id=&#34;the-question&#34;&gt;The Question&lt;/h2&gt;&#xA;&lt;p&gt;Few topics generate more heat in developer communities than the question of whether AI coding tools are getting worse over time. The complaint surfaces constantly: tasks that worked last month now require more prompting, models seem to lose coherence during US business hours, and context windows that once felt adequate now collapse under normal workloads.&lt;/p&gt;&#xA;&lt;p&gt;The stakes are real. Developers are paying $125-400+ per month for AI coding tools and building workflows around model capabilities they believe were promised. When those capabilities seem to fluctuate &amp;ndash; or quietly degrade &amp;ndash; trust erodes. And in a market where providers compete fiercely for developer loyalty, the perception of degradation can be as damaging as actual degradation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Vibe Coding Question</title>
      <link>/debates/vibe-coding.html</link>
      <pubDate>Fri, 06 Feb 2026 00:00:00 +0000</pubDate>
      <guid>/debates/vibe-coding.html</guid>
      <description>&lt;h2 id=&#34;the-question&#34;&gt;The Question&lt;/h2&gt;&#xA;&lt;p&gt;Andrej Karpathy coined the term &amp;ldquo;vibe coding&amp;rdquo; to describe a mode of AI-assisted development where you fully cede implementation to the model, accepting code you don&amp;rsquo;t fully understand as long as it works. The term quickly became a lightning rod &amp;ndash; embraced by some as the future of software development, rejected by others as professional malpractice.&lt;/p&gt;&#xA;&lt;p&gt;But the community has moved beyond a simple for-or-against debate. Practitioners now describe a spectrum from full delegation to tight step-by-step control, with most experienced developers settling somewhere in between. The real question isn&amp;rsquo;t whether vibe coding is good or bad &amp;ndash; it&amp;rsquo;s where on this spectrum responsible development should land, and whether the answer changes depending on context.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Does AI Prevent Junior Developer Skill Formation?</title>
      <link>/debates/junior-skills.html</link>
      <pubDate>Fri, 06 Feb 2026 00:00:00 +0000</pubDate>
      <guid>/debates/junior-skills.html</guid>
      <description>&lt;h2 id=&#34;the-question&#34;&gt;The Question&lt;/h2&gt;&#xA;&lt;p&gt;In early 2026, Anthropic published a study on AI-assisted coding that confirmed what many practitioners already suspected: developers using AI tools showed impaired conceptual understanding and weaker debugging skills compared to those who struggled through problems manually. The study landed in a community already anxious about what AI means for the next generation of programmers.&lt;/p&gt;&#xA;&lt;p&gt;The implications are profound. If AI tools prevent junior developers from forming the deep skills that senior developers rely on, the industry faces a compounding problem. Today&amp;rsquo;s juniors become tomorrow&amp;rsquo;s seniors. If they never develop the judgment to direct and verify AI output, who reviews the code? Who diagnoses production failures? Who makes architectural decisions that AI can&amp;rsquo;t yet make well?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Engineering vs. Programming: Is This &#39;Real&#39; Development?</title>
      <link>/debates/engineering-vs-programming.html</link>
      <pubDate>Fri, 06 Feb 2026 00:00:00 +0000</pubDate>
      <guid>/debates/engineering-vs-programming.html</guid>
      <description>&lt;h2 id=&#34;the-question&#34;&gt;The Question&lt;/h2&gt;&#xA;&lt;p&gt;Something uncomfortable is happening to the developer identity. Tools that were supposed to make programming more productive are instead making some developers feel like they&amp;rsquo;re not programming at all. When your day consists of writing prompts, reviewing AI output, and shepherding agents through tasks, the question becomes unavoidable: is this still engineering?&lt;/p&gt;&#xA;&lt;p&gt;The tension runs deep because it touches on why people entered the field. Some developers are in it to build things &amp;ndash; shipping products, solving user problems, creating value. For them, AI is a superpower that eliminates the tedious translation between intent and implementation. Others are in it because they love the craft of programming itself &amp;ndash; the elegance of a well-structured algorithm, the satisfaction of making something work through direct understanding. For them, AI threatens the very activity that makes the work meaningful.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Is the AI Coding Tool Economy Sustainable?</title>
      <link>/debates/cost-sustainability.html</link>
      <pubDate>Fri, 06 Feb 2026 00:00:00 +0000</pubDate>
      <guid>/debates/cost-sustainability.html</guid>
      <description>&lt;h2 id=&#34;the-question&#34;&gt;The Question&lt;/h2&gt;&#xA;&lt;p&gt;The AI coding tool economy in early 2026 runs on a contradiction: developers are addicted to tools whose providers are hemorrhaging cash. OpenAI projects billions in losses, Anthropic burns through venture capital to subsidize Claude Code subscriptions, and Google treats Gemini as a loss leader to protect search revenue. Developers pay $20 to $200 per month for tools that consume far more in compute than those subscriptions cover.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cognitive Dependency: Are Developers Losing Their Edge?</title>
      <link>/debates/brain-atrophy.html</link>
      <pubDate>Fri, 06 Feb 2026 00:00:00 +0000</pubDate>
      <guid>/debates/brain-atrophy.html</guid>
      <description>&lt;h2 id=&#34;the-question&#34;&gt;The Question&lt;/h2&gt;&#xA;&lt;p&gt;Andrej Karpathy, one of the most prominent voices in AI, admitted that he can barely write C++ anymore after years of relying on AI assistants. For many developers, this confession crystallized a fear they had been quietly carrying: that the tools making them faster are simultaneously making them less capable.&lt;/p&gt;&#xA;&lt;p&gt;The atrophy question cuts deeper than the related debate about whether juniors can develop skills with AI assistance. This is about experienced developers &amp;ndash; people who already had hard-won expertise &amp;ndash; watching those abilities fade. It is the difference between never learning to navigate without GPS and being a former navigator who can no longer read a map. The loss feels more personal and more concrete.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Is AI Coding Killing Open Source?</title>
      <link>/debates/open-source-impact.html</link>
      <pubDate>Fri, 06 Feb 2026 00:00:00 +0000</pubDate>
      <guid>/debates/open-source-impact.html</guid>
      <description>&lt;h2 id=&#34;the-question&#34;&gt;The Question&lt;/h2&gt;&#xA;&lt;p&gt;Open source software has been the bedrock of modern computing for decades. Linux runs the cloud, Apache and Nginx serve the web, React and Vue power the frontend, and tens of thousands of libraries form the invisible infrastructure of every application we use. The people who built and maintained this commons did so for a complex mix of reasons: personal satisfaction, reputation building, community belonging, and the belief that shared code makes everyone better off.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Which Programming Languages Work Best with AI?</title>
      <link>/debates/language-matters.html</link>
      <pubDate>Fri, 06 Feb 2026 00:00:00 +0000</pubDate>
      <guid>/debates/language-matters.html</guid>
      <description>&lt;h2 id=&#34;the-question&#34;&gt;The Question&lt;/h2&gt;&#xA;&lt;p&gt;When developers adopt AI coding tools, they quickly discover that results vary by programming language. Python and TypeScript seem to get the best outputs. Rust and Go produce code that at least compiles. C++ and niche languages often yield frustrating results. But is this a fundamental property of the languages, a reflection of training data distribution, or something that will be optimized away as models improve?&lt;/p&gt;&#xA;&lt;p&gt;The question matters because language choice has long-term consequences. Teams choosing a technology stack in 2026 must consider not only the traditional factors &amp;ndash; performance, ecosystem, hiring &amp;ndash; but also how well their chosen language works with the AI tools that are rapidly becoming essential to developer productivity. If language choice determines a 2x or 5x difference in AI-assisted productivity, that factor could outweigh nearly everything else.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
