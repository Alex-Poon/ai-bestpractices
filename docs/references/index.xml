<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>References on AI Best Practices Knowledge Base</title>
    <link>//localhost:1313/references/index.html</link>
    <description>Recent content in References on AI Best Practices Knowledge Base</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Feb 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="//localhost:1313/references/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Daily Agent-Assisted Development Checklist</title>
      <link>//localhost:1313/references/daily-workflow-checklist.html</link>
      <pubDate>Thu, 05 Feb 2026 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/references/daily-workflow-checklist.html</guid>
      <description>&lt;p&gt;A practical checklist for developers using AI coding agents as part of their daily workflow. Derived from practitioner patterns observed across Mitchell Hashimoto&amp;rsquo;s adoption journey and the Hacker News discussion community.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;before-starting&#34;&gt;Before Starting&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Review AGENTS.md / CLAUDE.md&lt;/strong&gt; &amp;ndash; Is anything outdated? Any patterns to add from yesterday&amp;rsquo;s work? Remove entries that no longer apply. Add entries for mistakes you remember correcting but did not document in the moment.&lt;/li&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Identify 2-3 tasks suitable for agent delegation&lt;/strong&gt; &amp;ndash; These should have clear scope, verifiable output, and no architectural decisions embedded in them. If you cannot describe what &amp;ldquo;done&amp;rdquo; looks like in two sentences, the task is not ready.&lt;/li&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Check if any overnight agent results are ready for review&lt;/strong&gt; &amp;ndash; If you launched exploration or research tasks at end of day yesterday, review the output now while the context is fresh.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;during-work&#34;&gt;During Work&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;For each agent task: Write the spec/plan yourself, delegate implementation.&lt;/strong&gt; The design is your job. The typing is the agent&amp;rsquo;s job. If you find yourself letting the agent make structural decisions, stop and reclaim the planning step.&lt;/li&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Scope check: Can you verify the output in under 2 minutes?&lt;/strong&gt; If not, break the task down further before delegating. Two minutes is the threshold. Beyond that, you are likely approving output you have not fully understood.&lt;/li&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Review diffs incrementally.&lt;/strong&gt; Do not let changes accumulate without verification. Each agent-produced change should be reviewed and verified before moving to the next task. Batching review is how drift accumulates undetected.&lt;/li&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;When an agent makes a mistake: document it in AGENTS.md before moving on.&lt;/strong&gt; This takes thirty seconds and prevents hours of future re-correction. The discipline is in doing it immediately, not later. &amp;ldquo;Later&amp;rdquo; means &amp;ldquo;never.&amp;rdquo;&lt;/li&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Control your attention.&lt;/strong&gt; Disable agent notifications. Check agent results on YOUR schedule, not the agent&amp;rsquo;s. The agent works for you, not the other way around. If you are context-switching every time the agent produces output, you are losing more productivity to interruption than you are gaining from delegation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;end-of-day&#34;&gt;End of Day&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Launch 1-2 agents for overnight research, exploration, or issue triage.&lt;/strong&gt; These should be tasks where the output is informational, not code that will be merged without review. Good candidates: investigating a bug, summarizing documentation, exploring library options, triaging open issues.&lt;/li&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Queue up &amp;ldquo;slam dunk&amp;rdquo; tasks for tomorrow&amp;rsquo;s delegation.&lt;/strong&gt; Identify tasks that are clearly well-scoped and likely to succeed. Having these ready means tomorrow starts productively instead of with a scoping exercise.&lt;/li&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Update AGENTS.md with any new patterns, mistakes, or conventions discovered today.&lt;/strong&gt; End-of-day is the second-best time to document (immediately is best, but a daily sweep catches what you missed).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;weekly&#34;&gt;Weekly&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Review and refine AGENTS.md.&lt;/strong&gt; Remove outdated entries. Consolidate entries that address the same underlying issue. Reorganize if the file has grown unwieldy. The harness should be concise and scannable, not a sprawling document.&lt;/li&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Assess: What types of tasks consistently succeed? Which consistently fail?&lt;/strong&gt; Build a mental (or written) model of the agent&amp;rsquo;s reliability frontier. Expand delegation into areas of consistent success. Pull back from areas of consistent failure.&lt;/li&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Consider building a new tool/script if you have seen the same agent failure 3+ times.&lt;/strong&gt; Repeated failures in the same category signal a structural problem that documentation alone cannot fix. A purpose-built tool (filtered test runner, output formatter, context assembler) may be warranted.&lt;/li&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Check costs.&lt;/strong&gt; Are you getting value proportional to spend? If you are on a usage-based plan, review the past week&amp;rsquo;s spending. If you are on a flat rate, assess whether you are using the tool enough to justify the subscription. Nobody should be paying for AI tools they are not actively using.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;signs-you-are-doing-it-right&#34;&gt;Signs You Are Doing It Right&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;You spend more time reading and verifying than writing prompts.&lt;/strong&gt; The bottleneck has shifted from generation to verification. This is the correct state.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Your AGENTS.md is growing steadily.&lt;/strong&gt; Not explosively (that suggests too many mistakes) and not stagnating (that suggests you are not documenting). Steady growth means you are capturing institutional knowledge.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Agent mistakes are NEW mistakes, not repeated ones.&lt;/strong&gt; The harness is working. Old failure modes are documented and prevented. Errors that occur are genuinely novel.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;You have a backlog of tasks ready for delegation.&lt;/strong&gt; You are not scrambling to find things for the agent to do. You have a pipeline of well-scoped tasks identified in advance.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;You control your attention.&lt;/strong&gt; The agent does not interrupt you. You check results when you are ready. Your focus time is protected.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;signs-you-are-doing-it-wrong&#34;&gt;Signs You Are Doing It Wrong&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;You are &amp;ldquo;drawing the owl.&amp;rdquo;&lt;/strong&gt; Giant tasks with vague goals handed to the agent as a single prompt. The output is impressive-looking but subtly wrong in ways you discover too late.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;You are re-explaining the same constraints every session.&lt;/strong&gt; If you have told the agent the same thing three times across different sessions, it should be in AGENTS.md. You are burning time on repetition instead of building persistent infrastructure.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;You are not verifying output before moving on.&lt;/strong&gt; Approving agent diffs without reading them, running tests, or checking behavior. This builds accumulated drift that compounds into serious problems.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;The agent is driving your attention.&lt;/strong&gt; Notifications are on. You context-switch every time the agent produces output. Your workflow is reactive instead of deliberate.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;You do not know what your monthly AI spend is.&lt;/strong&gt; You are making investment decisions (time, money, workflow changes) without data. Track your costs.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This checklist puts into daily practice the principles from &lt;a href=&#34;../patterns/task-scoping.html&#34;&gt;Task Scoping&lt;/a&gt;, &lt;a href=&#34;../patterns/harness-engineering.html&#34;&gt;Harness Engineering&lt;/a&gt;, and &lt;a href=&#34;../guides/adoption-stages.html&#34;&gt;The Six Stages of AI Adoption&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Coding Tools: A Practitioner&#39;s Comparison</title>
      <link>//localhost:1313/references/tool-landscape.html</link>
      <pubDate>Thu, 05 Feb 2026 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/references/tool-landscape.html</guid>
      <description>&lt;h2 id=&#34;use-a-decision-framework-not-rankings&#34;&gt;Use a Decision Framework, Not Rankings&lt;/h2&gt;&#xA;&lt;p&gt;The AI coding tool landscape changes faster than any comparison can keep up with. Models improve monthly. Pricing shifts quarterly. New entrants appear constantly. Nearly $2 billion has been raised by coding agent startups in just the past five months.&lt;/p&gt;&#xA;&lt;p&gt;Rather than ranking tools, this page provides a decision framework based on factors that are relatively stable: workflow type, pricing model, extensibility, and integration approach. Use these to evaluate any tool, including ones that do not exist yet.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The AGENTS.md / CLAUDE.md Guide</title>
      <link>//localhost:1313/references/agents-md-guide.html</link>
      <pubDate>Thu, 05 Feb 2026 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/references/agents-md-guide.html</guid>
      <description>&lt;h2 id=&#34;what-these-files-are&#34;&gt;What These Files Are&lt;/h2&gt;&#xA;&lt;p&gt;AGENTS.md and CLAUDE.md are project-root files that AI coding agents read at the start of every session. They give agents persistent, project-specific context that would otherwise be lost between conversations. Different tools use different filenames &amp;ndash; Claude Code reads CLAUDE.md, Amp reads AGENTS.md, and most tools now support both &amp;ndash; but the purpose is identical: tell the agent how to work in this codebase.&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-they-matter-the-compounding-effect&#34;&gt;Why They Matter: The Compounding Effect&lt;/h2&gt;&#xA;&lt;p&gt;Every time you correct an agent&amp;rsquo;s mistake, you face a choice: fix it once and move on, or document the correction so it never happens again. The AGENTS.md file is where those corrections accumulate.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
