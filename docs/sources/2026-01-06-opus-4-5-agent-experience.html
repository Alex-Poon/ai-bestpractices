<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Opus 4.5 is not the normal AI agent experience | AI Best Practices Knowledge Base</title>
  <meta name="description" content="What actually works in AI-assisted development — synthesized from 6,000&#43; practitioner comments across 20 major HN discussions.">
  <meta name="color-scheme" content="dark light">

  
  <meta property="og:title" content="Opus 4.5 is not the normal AI agent experience">
  <meta property="og:description" content="What actually works in AI-assisted development — synthesized from 6,000&#43; practitioner comments across 20 major HN discussions.">
  <meta property="og:type" content="article">

  
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

  
  <link rel="stylesheet" href="../css/style.css">

  
  <link rel="icon" href="../favicon.svg" type="image/svg+xml">
</head>
<body class="section-sources"><header class="site-header">
  <nav class="nav-container">
    <a class="nav-logo" href="../index.html">
      <svg width="22" height="22" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
        <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"/>
        <circle cx="12" cy="8" r="2" fill="currentColor"/>
        <circle cx="7" cy="15" r="2" fill="currentColor"/>
        <circle cx="17" cy="15" r="2" fill="currentColor"/>
        <line x1="12" y1="10" x2="7" y2="13" stroke="currentColor" stroke-width="1.5"/>
        <line x1="12" y1="10" x2="17" y2="13" stroke="currentColor" stroke-width="1.5"/>
        <line x1="7" y1="15" x2="17" y2="15" stroke="currentColor" stroke-width="1.5"/>
      </svg>
      <span>AI Best Practices</span>
    </a>
    <div class="nav-links">
      <a class="nav-link" data-section="guide" href="../guide/index.html">Guide</a>
      <a class="nav-link" data-section="practices" href="../practices/index.html">Practices</a>
      <a class="nav-link" data-section="debates" href="../debates/index.html">Debates</a>
      <a class="nav-link" data-section="tools" href="../tools/index.html">Tools</a>
      <a class="nav-link" data-section="evidence" href="../evidence/index.html">Evidence</a>
      <a class="nav-link" data-section="voices" href="../voices/index.html">Voices</a>
      <a class="nav-link" data-section="sources" href="../sources/index.html">Sources</a>
    </div>
    <div class="nav-actions">
      <button class="nav-search-btn" type="button" aria-label="Search" id="searchTrigger">
        <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"><circle cx="11" cy="11" r="8"/><line x1="21" y1="21" x2="16.65" y2="16.65"/></svg>
        <span>Search</span>
        <kbd>/</kbd>
      </button>
      <button class="dark-mode-toggle" aria-label="Toggle dark mode" type="button">
        <svg class="icon-sun" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round">
          <circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/>
        </svg>
        <svg class="icon-moon" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round">
          <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
        </svg>
      </button>
      <button class="nav-toggle" aria-label="Toggle menu" type="button">
        <span></span>
      </button>
    </div>
  </nav>
</header>

    <div class="search-overlay" id="searchOverlay">
      <div class="search-container">
        <div class="search-input-wrap">
          <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"><circle cx="11" cy="11" r="8"/><line x1="21" y1="21" x2="16.65" y2="16.65"/></svg>
          <input type="text" class="search-input" id="searchInput" placeholder="Search articles, tools, patterns..." autocomplete="off">
        </div>
        <div class="search-results" id="searchResults"></div>
        <div class="search-hint">
          <span><kbd>Esc</kbd> close</span>
          <span><kbd>&uarr;</kbd><kbd>&darr;</kbd> navigate</span>
          <span><kbd>Enter</kbd> open</span>
        </div>
      </div>
    </div>

    <main>
<div class="page-container">
  
<nav class="breadcrumbs" aria-label="Breadcrumb">
  <ol>
    <li><a href="../index.html">Home</a></li>
    
      
    
      
        <li><a href="../sources/index.html">Sources</a></li>
      
    
    <li aria-current="page">Opus 4.5 is not the normal AI agent experience</li>
  </ol>
</nav>



  <div class="article-layout has-toc">
    <article class="article">
      <header class="article-header">
        <h1 class="article-title">Opus 4.5 is not the normal AI agent experience</h1>
        <div class="meta-bar">
  
  <time class="meta-date" datetime="2026-01-06">
    January 6, 2026
  </time>
  

  

  <span class="meta-reading-time">121 min read</span>

  
  <span class="tier-badge tier-badge--2">Tier 2</span>
  

  <div class="meta-links">
    
    <a href="https://burkeholland.github.io/posts/opus-4-5-change-everything/" class="meta-link" target="_blank" rel="noopener">Source &#8599;</a>
    
    
    
    <a href="https://news.ycombinator.com/item?id=46515696" class="meta-link" target="_blank" rel="noopener">HN &#8599;</a>
    
    
  </div>

  
  <span class="meta-stat">879 points</span>
  
  
  
  <span class="meta-stat">131 comments</span>
  
  
</div>

        
<div class="tag-pills">
  
  
  
  <a href="../tags/opus.html" class="tag-pill">opus</a>
  
  
  
  
  <a href="../tags/claude-code.html" class="tag-pill">claude-code</a>
  
  
  
  
  <a href="../tags/agent-workflows.html" class="tag-pill">agent-workflows</a>
  
  
  
  
  <a href="../tags/vibe-coding.html" class="tag-pill">vibe-coding</a>
  
  
  
  
  <a href="../tags/ai-capabilities.html" class="tag-pill">ai-capabilities</a>
  
  
  
  
  <a href="../tags/developer-experience.html" class="tag-pill">developer-experience</a>
  
  
</div>


      </header>

      <div class="article-content">
        <h2 id="summary">Summary</h2>
<p>Burke Holland wrote an enthusiastic account of his experience using Claude&rsquo;s Opus 4.5 model, arguing it represents a fundamental shift in AI agent capabilities that goes beyond anything he had previously experienced. His central claim is that Opus 4.5 delivers on promises that earlier AI coding agents could not fulfill, particularly around autonomous problem-solving and first-attempt success rates.</p>
<p>Holland completed four substantial projects in rapid succession: an image conversion utility, a video editor, a social media automation app, and a route optimization tool. He highlighted the model&rsquo;s ability to handle full-stack development spanning frontend, backend, authentication, database integration, and cloud infrastructure &ndash; areas that had traditionally been weak points for AI agents.</p>
<p>Key capabilities he observed included autonomous self-correction and debugging without human intervention, the ability to learn new tools like Firebase CLI without explicit instruction, and sophisticated framework comprehension. The model would read error logs, identify issues, and iterate on fixes independently.</p>
<p>Holland proposed a provocative &ldquo;LLM-first&rdquo; coding philosophy that optimizes for machine maintainability rather than human readability, prioritizing linear control flow, explicit code, and regenerability over traditional software design aesthetics. However, he acknowledged security as a primary concern, estimating only about 80% confidence in robust implementations.</p>
<p>The HN discussion was extensive and polarized, with many experienced developers pushing back on the replacement narrative while acknowledging genuine productivity gains for greenfield projects and personal tools.</p>
<h2 id="key-insights">Key Insights</h2>
<ul>
<li><strong>First-attempt success is the differentiator</strong>: Unlike prior agents that required extensive back-and-forth, Opus 4.5 often solved problems correctly on the first try</li>
<li><strong>Full-stack autonomy</strong>: The model handled end-to-end development including auth, databases, and cloud infra &ndash; historically the weakest areas for AI agents</li>
<li><strong>LLM-first coding philosophy</strong>: Holland proposed optimizing code for machine maintainability rather than human readability, a controversial but thought-provoking stance</li>
</ul>
<h2 id="notable-quotes">Notable Quotes</h2>
<blockquote>
<p>&ldquo;Opus 4.5 feels like the model that we were promised&rdquo; — Burke Holland</p>
</blockquote>
<blockquote>
<p>&ldquo;It&rsquo;s still not as smart as a good human programmer&rdquo; — mcv</p>
</blockquote>
<h2 id="hn-discussion-highlights">HN Discussion Highlights</h2>
<p><em>807 comments total</em></p>
<p><strong>OldGreenYodaGPT</strong>: Most software engineers are seriously sleeping on how good LLM agents are right now, especially something like Claude Code. Once you’ve got Claude Code set up, you can point it at your codebase, have&hellip;</p>
<blockquote>
<p><strong>klaussilveira</strong>: I made a similar comment on a different thread, but I think it also fits here: I think the disconnect between engineers is due to their own context. If you work with frontend applications, specially&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>JDye</strong>: We have an in-house, Rust-based proxy server. Claude is unable to contribute to it meaningfully outside of grunt work like minor refactors across many files. It doesn&rsquo;t seem to understand proxying&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>dpc_01234</strong>: &gt; We have an in-house, Rust-based proxy server. Claude is unable to contribute to it meaningfully outside I have a great time using Claude Code in Rust projects, so I know it&rsquo;s not about the language&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>kevin42</strong>: This isn&rsquo;t meant as a criticism, or to doubt your experience, but I&rsquo;ve talked to a few people who had experiences like this. But, I helped them get Claude code setup, analyze the codebase and&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>turkey99</strong>: Are you still talking about Opus 4.5 I’ve been working on a Rust, kotlin and c++ and it’s been doing well. Incredible at C++, like the number of mistakes it doesn’t make</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>parliament32</strong>: &gt; I still believe those who rave about it are not writing anything I would consider &ldquo;engineering&rdquo;. Correct. In fact, this is the entire reason for the disconnect, where it seems like half the people&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>wild_egg</strong>: I&rsquo;ve had Opus 4.5 hand rolling CUDA kernels and writing a custom event loop on io_uring lately and both were done really well. Need to set up the right feedback loops so it can test its work&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>jaggederest</strong>: Yeah I&rsquo;ve handed it a naive scalar implementation and said &ldquo;Make this use SIMD for Mac Silicon / NEON&rdquo; and it just spits out a working implementation that&rsquo;s 3-6x faster and passes the tests, which&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>lelandfe</strong>: I&rsquo;m a quite senior frontend using React and even I see Sonnet 4.5 struggle with basic things. Today it wrote my Zod validation incorrectly, mixing up versions, then just decided it wasn&rsquo;t working and&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>baq</strong>: There’s little reason to use sonnet anymore. Haiku for summaries, opus for anything else. Sonnet isn’t a good model by today’s standards.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>subomi</strong>: Why do we all of a sudden hold these agents to some unrealistic high bar? Engineers write bugs all the time and write incorrect validations. But we iterate. We read the stacktrace in Sentry and&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>CapsAdmin</strong>: I built an open to &ldquo;game engine&rdquo; entirely in Lua a many years ago, but relying on many third party libraries that I would bind to with FFI. I thought I&rsquo;d revive it, but this time with Vulkan and no&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>3D30497420</strong>: I&rsquo;ll second this. I&rsquo;m making a fairly basic iOS/Swift app with an accompanying React-based site. I was able to vibe-code the React site (it isn&rsquo;t pretty, but it works and the code is fairly decent)&hellip;.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>rootusrootus</strong>: I had surprising success vibe coding a swift iOS app a while back.  Just for fun, since I have a bluetooth OBD2 dongle and an electric truck, I told Claude to make me an app that could connect to the&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>billbrown</strong>: I hate &ldquo;vibe code&rdquo; as a verb. May I suggest &ldquo;prompt&rdquo; instead? &ldquo;I was able to prompt the React site….&rdquo;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>348512469721</strong>: &gt; It also can&rsquo;t do rust really well I have not had this experience at all. It often doesn&rsquo;t get it right on the first pass, yes, but the advantage with Rust vibecoding is that if you give it a rule&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>jessoteric</strong>: i&rsquo;ve also been using opus 4.5 with lots of heavy rust development. i don&rsquo;t &ldquo;vibe code&rdquo;, but lead it with a relatively firm hand- and it produces pretty good results in surprisingly complicated tasks&hellip;.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>UncleOxidant</strong>: I&rsquo;ve had pretty good luck with LLM agents coding C. In this case a C compiler that supports a subset of C and targets a customizable microcoded state machine/processor. Then I had Gemini code up a&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>HarHarVeryFunny</strong>: That&rsquo;s remarkably similar to something I&rsquo;ve just started on - I want to create a self-compiling C compiler targeting (and to run on) an 8-bit micro via a custom VM. This a basically a retro-computing&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>nycdatasci</strong>: Have you experimented with all of these things on the latest models (e.g. Opus 4.5) since Nov 2025?  They are significantly better at coding than earlier models.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>klaussilveira</strong>: Yes, December 2025 and January 2026.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ryandrake</strong>: I&rsquo;ve found it to be pretty hit-or-miss with C++ in general, but it&rsquo;s really, REALLY bad at 3D graphics code. I&rsquo;ve tried to use it to port an OpenGL project to SDL3_GPU, and it really struggled. It&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>Wowfunhappy</strong>: I hope I’m not committing a faux pas by saying this—and please feel free to tell me that I’m wrong—but I imagine a human who has been blind since birth would also struggle to build 3D graphics code&hellip;.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>antonvs</strong>: &gt; It also can&rsquo;t do Rust really well, once you get to the meat of it. Not sure why that is Because types are proofs and require global correctness, you can&rsquo;t just iterate, fix things locally, and wait&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>nopakos</strong>: I have not tried C++, but Codex did a good job with low-level C code, shaders as well as porting 32 bit to 64 bit assembly drawing routines. I have also tried it with retro-computing programming with&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ivm</strong>: &gt; Mobile From what I&rsquo;ve seen, CC has troubles with the latest Swift too, partially because of it being latest and partially because it&rsquo;s so convoluted nowadays. But it&rsquo;s übercharged™ for C#</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>spaceman_2020</strong>: I really think a lof of people tried AI coding earlier, got frustrated at the errors and gave up. That&rsquo;s where the rejection of all these doomer predictions comes from. And I get it. Coding with&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ryandrake</strong>: This was me. I was a huge AI coding detractor on here for a while (you can check my comment history). But, in order to stay informed and not just be that grouchy curmudgeon all the time, I kept up&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>mikestorrent</strong>: I have a few Go projects now and I speak Go as well as you speak Kotlin. I predict that we&rsquo;ll see some languages really pull ahead of others in the next few years based on their advantages for&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>myk9001</strong>: Oh, wow, that&rsquo;s impressive, thanks for sharing! Going to one-up you though &ndash; here&rsquo;s a literal one-liner that gets me a polished media center with beautiful interface and powerful skinning engine. It&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>ku1ik</strong>: How do you know “it has no memory leaks, crashes, ANRs, no performance problems, no network latency bugs or anything” if you built it just yesterday? Isn’t it a bit too early for claims like this? I&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>rdedev</strong>: I decided to vibe code something myself last week at work. I&rsquo;ve been wanting to create a poc that involves a coding agent create custom bokeh plots that a user can interact with and ask follow up&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>yieldcrv</strong>: I recently replaced my monitor with one that could be vertically oriented, because I&rsquo;m just using Claude Code in the terminal and not looking at file trees at all but I do want a better way to glance&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>libraryofbabel</strong>: Thanks for posting this. It&rsquo;s a nice reminder that despite all the noise from hype-mongers and skeptics in the past few years, most of us here are just trying to figure this all out with an open mind&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>fpauser</strong>: &gt; Oh, and I did this all without ever opening a single source file or even looking at the proposed code changes while Opus was doing its thing. I don&rsquo;t even know Kotlin and still don&rsquo;t know it. &hellip;&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>theshrike79</strong>: &gt; &ldquo;asking it to fix it.&rdquo; This is what people are still doing wrong. Tools in a loop people, tools in a loop. The agent has to have the tools to detect whatever it just created is producing errors&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>ikornaselur</strong>: Last weekend I was debugging some blocking issue on a microcontroller with embassy-rs, where the whole microcontroller would lock up as soon as I started trying to connect to an MQTT server. I was&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>gck1</strong>: This is kind of why I&rsquo;m not really scared of losing my job. While Claude is amazing at writing code, it still requires human operators. And even experienced human operators are bad at operating this&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>nprateem</strong>: Jules is slow incompetent shit and that uses tools in a loop, so no&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ern</strong>: I have been out of the loop for a couple of months (vacation). I tried Claude Opus 4.5 at the end of November 2025 with the corporate Github Copilot subscription in Agent mode and it was awful:&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>everfrustrated</strong>: As someone coming from GitHub copilot in vscode and recently trying Claude Code plugin for vscode I don&rsquo;t get the fuss about Claude. Copilot has by far the best and most intuitive agent UI. Just make&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>Dusseldorf</strong>: I suspect that&rsquo;s the other thing at play here; many people have only tried Copilot because it&rsquo;s cheap with all the other Microsoft subscriptions many companies have. Copilot frankly is garbage&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>AstroBen</strong>: my issue hasn&rsquo;t been for a long time now that the code they write works or doesn&rsquo;t work. My issues all stem from that it works, but does the wrong thing</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>zmmmmm</strong>: &gt; My issues all stem from that it works, but does the wrong thing It&rsquo;s an opportunity, not a problem. Because it means there&rsquo;s a gap in your specifications and then your tests. I use Aider not Claude&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>simonw</strong>: If it does the wrong thing you tell it what the right thing is and have it try again. With the latest models if you&rsquo;re clear enough with your requirements you&rsquo;ll usually find it does the right thing&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>jmathai</strong>: I think it&rsquo;s worth understanding why. Because that&rsquo;s not everyone&rsquo;s experience and there&rsquo;s a chance you could make a change such that you find it extremely useful. There&rsquo;s a lesser chance that you&rsquo;re&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>solumunus</strong>: Correct it then, and next time craft a more explicit plan.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>scubbo</strong>: This was me. I have done a full 180 over the last 12 months or so, from &ldquo;they&rsquo;re an interesting idea, and technically impressive, but not practically useful&rdquo; to &ldquo;holy shit I can have entire&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>littlestymaar</strong>: &gt; I really think a lof of people tried AI coding earlier, got frustrated at the errors and gave up. That&rsquo;s where the rejection of all these doomer predictions comes from. It&rsquo;s not just the&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>roadside_picnic</strong>: I feel similar, I&rsquo;m not against the idea that maybe LLMs have gotten so much better&hellip; but I&rsquo;ve been told this probably 10 times in the last few years working with AI daily. The funny part about&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>spaceman_2020</strong>: You enter some text and a computer spits out complex answers generated on the spot Right or wrong - doesn’t matter. You typed in a line of text and now your computer is making 3000 word stories,&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>troupo</strong>: &gt; Opus 4.5 really is at a new tier however. It just&hellip;works. Literally tried it yesterday. I didn&rsquo;t see a single difference with whatever model Claude Code was using two months ago. Same crippled&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>EMM_386</strong>: The context window isn&rsquo;t &ldquo;crippled&rdquo;. Create a markdown document of your task (or use CLAUDE.md), put it in &ldquo;plan mode&rdquo; which allows Claude to use tool calls to ask questions before it generates the&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>mikestorrent</strong>: 200k+ tokens is a pretty big context window if you are feeding it the right context. Editors like Cursor are really good at indexing and curating context for you; perhaps it&rsquo;d be worth trying&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>pluralmonad</strong>: I&rsquo;m not familiar with any form of intelligence that does not suffer from a bloated context. If you want to try and improve your workflow, a good place to start is using sub-agents so individual task&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>iwontberude</strong>: I use Sonnet and Opus all the time and the differences are almost negligible</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>llmslave2</strong>: That&rsquo;s because Opus has been out for almost 5 months now lol. Its the same model, so I think people have been vibe coding with a heavy dose of wine this holiday and are now convinced its the future.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>iwontberude</strong>: Opus 4.5 is fucking up just like Sonnet really. I don&rsquo;t know how your use is that much different than mine.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>animegolem</strong>: I know someone who is using a vibe coded or at least heavily assisted text editor, praising it daily, while also saying llms will never be productive. There is a lot of dissonance right now.</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>enum</strong>: I teach at a university, and spend plenty of time programming for research and for fun. Like many others, I spent some time on the holidays trying to push the current generation of Cursor, Claude&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>realusername</strong>: This is where the LLM coding shines in my opinion, there&rsquo;s a list of things they are doing very well: - single scripts. Anything which can be reduced to a single script. - starting greenfield&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>enum</strong>: I&rsquo;m trying to determine what programming tasks are not in this list. :) I think it is trying to exclude adding new features and fixing bugs in existing code. I&rsquo;ve done enough of that with LLMs,&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>vercaemert</strong>: How do you compare Claude Code to Cursor? I&rsquo;m a Cursor user quietly watching the CC parade with curiosity. Personally, I haven&rsquo;t been able to give up the IDE experience.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>kaydub</strong>: Im so sold on the cli tools that I think IDEs are basically dead to me. I only have an IDE open so I can read the code, but most often I&rsquo;m just changing configs (like switching a bool, or bumping up&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>lizardking</strong>: When I&rsquo;m using Claude Code, I usually have a text editor open as well. The CC plugin works well enough to achieve most of what Cursor was doing for me in showing real-time diffs, but in my&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>tstrimple</strong>: I use CC for so much more than just writing code that I cannot imagine being constrained within an IDE. Why would I want to launch an IDE to have CC update the *arr stack on my NAS to the latest&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>subomi</strong>: I was here a few weeks ago, but I&rsquo;m now on the CC train. The challenge is that the terminal is quite counterintuitive. But if you put on the Linux terminal lens from a few years ago, and you start&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>enum</strong>: I don&rsquo;t think I can scientifically compare the agents. As it is, you can use Opus / Codex in Cursor. The speed of Cursor composer-1 is phenomenal &ndash; you can use it interactively for many tasks. There&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>smw</strong>: Just FYI, these days cc has &lsquo;ide integration&rsquo; too, it&rsquo;s not just a cli. Grab the vscode extension.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>franktankbank</strong>: What did you build?  I think people talk passed eachother when people don&rsquo;t share what exactly they were trying to do and achieving success/failure.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>enum</strong>: Referring to this: <a href="https://github.com/arjunguha/slopcoder">https://github.com/arjunguha/slopcoder</a> I then proceeded to use it to hack on its own codebase, and close a bunch of issues in a repository that I maintain&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>TacticalCoder</strong>: &gt; Most software engineers are seriously sleeping on how good LLM agents are right now, especially something like Claude Code. Nobody is sleeping. I&rsquo;m using LLMs daily to help me in simple coding&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>simonw</strong>: I think getting proficient at using coding agents effectively takes a few months of practice. It&rsquo;s also a skill that compounds over time, so if you have two years of experience with them you&rsquo;ll be&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>vidarh</strong>: &gt; Nobody is sleeping. I&rsquo;m using LLMs daily to help me in simple coding tasks. That is sleeping. &gt; But really where is the hurry? At this point not a few weeks go by without the next best thing since&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>jasonfarnon</strong>: &ldquo;But really where is the hurry?&rdquo; It just depends on why you&rsquo;re programming. For many of us not learning and using up to date products leads to a disadvantage relative to our competition. I personally&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>BatteryMountain</strong>: The crazy part is, once you have it setup and adapted your workflow, you start to notice all sorts of other &ldquo;small&rdquo; things: claude can call ssh and do system admin tasks. It works amazingly well. I&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>vidarh</strong>: &gt; claude can call ssh and do system admin tasks Claude set up a Raspberry Pi with a display and conference audio device for me to use as an Alexa replacement tied to Home Assistant. I gave it an ssh&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>theshrike79</strong>: I have a /fix-ci-build slash command that instructs Claude how to use <code>gh</code> to get the latest build from that specific project&rsquo;s Github Actions and get the logs for the build In addition there are&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>Loeffelmann</strong>: Why do all these AI generated readmes have a directory structure sections it&rsquo;s so redundant because you know I could just run tree</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>sonnig</strong>: It makes me so exhausted trying to read them&hellip; my brain can tell immediately when there&rsquo;s so much redundant information that it just starts shutting itself off.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>bakies</strong>: comments? also reading into an agent so the agent doesnt have to tool-call/bash out</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>6177c40f</strong>: I think we&rsquo;re entering a world where programmers as such won&rsquo;t really exist (except perhaps in certain niches). Being able to program (and read code, in particular) will probably remain useful,&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>wiml</strong>: We&rsquo;ve been living in that world since the invention of the compiler (&ldquo;automatic programming&rdquo;). Few people write machine code any more. If you think of LLMs as a new variety of compiler, a lot of&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>qwm</strong>: My compiler runs on my computer and produces the same machine code given the same input. Neither of these are true with AI.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>bdangubic</strong>: last thing I want is non-deterministic compiler, do not vibe this analogy at all…</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>moffkalast</strong>: Finally we&rsquo;ve invented a compiler that we can yell at when it gives bullshit errors. I really missed that with gcc.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>pseidemann</strong>: Isn&rsquo;t there more indirection as long as LLMs use &ldquo;human&rdquo; programming languages?</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>xarope</strong>: If you think of the training data, e.g. SO, github etc, then you have a human asking or describing a problem, then the code as the solution.  So I suspect current-gen LLMs are still following this&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>6177c40f</strong>: More indirection in the sense that there&rsquo;s a layer between you and the code, sure. Less in that the code doesn&rsquo;t really matter as such and you&rsquo;re not having to think hard about the minutiae of&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>layer8</strong>: It’s not clear how affordances of programming languages really differ between humans and LLMs.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>Yoric</strong>: You intrigue me. &gt; have it learn your conventions, pull in best practices What do you mean by &ldquo;have it learn your conventions&rdquo;? Is there a way to somehow automatically extract your conventions and&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ac29</strong>: &gt; What do you mean by &ldquo;have it learn your conventions&rdquo;? I&rsquo;ll give you an example: I use ruff to format my python code, which has an opinionated way of formatting certain things. After an initial&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>UncleMeat</strong>: Isn&rsquo;t this a meaningless example? Formatters already exist. Generating code that doesn&rsquo;t need to be formatted is exactly the same as generating code and then formatting it. I care about the norms in&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>gingersnap</strong>: Starting to use Opus 4.5 I&rsquo;m reduces instrutions in claude.md and just ask claude to look in the codebase to understand the patterns already in use. Going from prompts/docs to instead having code&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>zoilism</strong>: The Ash framework takes the approach you describe. From the docs (<a href="https://hexdocs.pm/ash/what-is-ash.html)">https://hexdocs.pm/ash/what-is-ash.html)</a>: &ldquo;Model your application&rsquo;s behavior first, as data, and derive everything else&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>kaydub</strong>: I feel like I&rsquo;ve been doing this since Sonnet 3.5 or Sonnet 4. I&rsquo;ll clone projects/modules/whatever into the working directory and tell claude to check it out. Voila, now it knows your standards and&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>oncallthrow</strong>: When I ask Claude to do something, it independently, without me even asking or instructing it to, searches the codebase to understand what the convention is. I’ve even found it searching node_modules&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>jack_pp</strong>: This sounds like it would take a huge amount of tokens. I&rsquo;ve never used agents so could you disclose how much you pay for it?</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>vidarh</strong>: Just ask it to. /init in Claude Code already automatically extracts a bunch, but for something more comprehensive, just tell it which additional types of things you want it to look for and document&hellip;.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>kaydub</strong>: &ldquo;Claude, clone this repo <a href="https://github.com/repo">https://github.com/repo</a>, review the coding conventions, check out any markdown or readme files. This is an example of coding conventions we want to use on this project&rdquo;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>dmbche</strong>: Oh! An ad!</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>savanaly</strong>: The most effective kind of marketing is viral word of mouth from users who love your product. And Claude Code is benefiting from that dynamic.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>OldGreenYodaGPT</strong>: lol does sound like and ad, but is true. Also forgot about hooks use hooks too! I just use voice to text then had claude reword it. Still my real world ideas</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>Rapzid</strong>: Exactly what an ad would say.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>majormajor</strong>: All of these things work very well IMO in a professional context. Especially if you&rsquo;re in a place where a lot of time was spent previously revising PRs for best practices, etc, even for&hellip;</p>
</blockquote>
<blockquote>
<p><strong>keybored</strong>: &gt; (used voice to text then had claude reword, I am lazy and not gonna hand write it all for yall sorry!) Reword? But why not just voice to text alone&hellip; Oh but we all read the partially synthetic ad&hellip;</p>
</blockquote>
<blockquote>
<p><strong>maxkfranz</strong>: &gt; Once you’ve got Claude Code set up, you can point it at your codebase, have it learn your conventions, pull in best practices, and refine everything until it’s basically operating like a&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>vidarh</strong>: I&rsquo;d really encourage you to try using agents for tasks that are repeatable and/or wordy but where most of the words are not relevant for ongoing understanding. It&rsquo;s a tiny step further, and&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>maxkfranz</strong>: That&rsquo;s a great point.  There are a lot of things you can do to optimise things, and your suggestion is one of the lower hanging fruits. I was trying to get across the point that today you can get a&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>hoten</strong>: Mind sharing the bill for all that?</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>OldGreenYodaGPT</strong>: My company pays for the team Claude code plan which is like $200 a month for each dev. The workflows cost like 10 - 50 cents a PR</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>blahblaher</strong>: It will have to quintuple or more to make business sense for Anthropic. Sure, still cheaper than a full time developer, but don&rsquo;t expect it to stay at $200 for a long time. And then, when you explain&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>square_usual</strong>: It&rsquo;s $150, not a huge difference but worth noting that it&rsquo;s not the same ast the 20x Max plan.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>6177c40f</strong>: Cheaper than hiring another developer, probably. My experience: for a few dollars I was able to extensively refactor a Python codebase in half a day. This otherwise would have taken multiple days of&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>blahblaher</strong>: And that&rsquo;s what the C-suite wants to know. Prepare yourself to be replaced in the not so distant future. Hope you have a good &ldquo;nest&rdquo; to support yourself when you&rsquo;re inevitably fired.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>aschobel</strong>: i&rsquo;ve never hit a limit with my $200 a month plan</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>jdthedisciple</strong>: I&rsquo;m curious: With that much Claude Code usage, does that put your monthly Anthropic bill above $1000/mo?</p>
</blockquote>
<blockquote>
<p><strong>nijave</strong>: I still struggle with these things being <em>too</em> good at generating code. They have a tendency to add abstractions, classes, wrappers, factories, builders to things that didn&rsquo;t really need all that. I&hellip;</p>
</blockquote>
<blockquote>
<p><strong>risyachka</strong>: They are sleeping on it because there is absolutely no incentive to use it. When needed it can be picked up in a day. Otherwise they are not paid based in tickets solved etc.  If the incentives were&hellip;</p>
</blockquote>
<blockquote>
<p><strong>dominicrose</strong>: Use Claude Code&hellip; to do what? There are multiple layers of people involved in the decision process and they only come up with a few ideas every now and then. Nothing I can&rsquo;t handle. AI helps but it&hellip;</p>
</blockquote>
<blockquote>
<p><strong>aschobel</strong>: Agreed and skills are a huge unlock. codex cli even has a skill to create skills; it&rsquo;s super easy to get up to speed with them <a href="https://github.com/openai/skills/blob/main/skills/.system/sk">https://github.com/openai/skills/blob/main/skills/.system/sk</a>&hellip;</p>
</blockquote>
<blockquote>
<p><strong>chandureddyvari</strong>: Came across official anthropic repo on gh actions very relevant to what you mentioned. Your idea on scheduled doc updation using llm is brilliant, I’m stealing this idea&hellip;.</p>
</blockquote>
<blockquote>
<p><strong>avereveard</strong>: Also new haiku. Not as smart but lighting fast, I&rsquo;ve it review code changes impact or if i need a wide but shallow change done I&rsquo;ve it scan the files and create a change plan. Saves a lot of time&hellip;</p>
</blockquote>
<blockquote>
<p><strong>andrekandre</strong>: &gt; we have another Claude Code agent that does a full PR review, following a detailed markdown checklist we’ve written for it. (if you know) how is that compared to coderabbit? i&rsquo;m seriously looking&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>megalomanu</strong>: Never tried coderabbit, just because this is already good enough with Claude Code. It helped us to catch dozens of important issues we wouldn&rsquo;t have caught. We gave some instructions in the CLAUDE.md&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>andrekandre</strong>: thanks for the reply, yea we have a claude.md file, but coderabbit doesn&rsquo;t seem to pick it up or ignore it&hellip; hmmm wish we could try out claude code.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>ndesaulniers</strong>: Thanks for the example! There&rsquo;s a lot (of boilerplate?) here that I don&rsquo;t understand. Does anyone have good references for catching up to speed what&rsquo;s the purpose of all of these files in the demo?</p>
</blockquote>
<blockquote>
<p><strong>profstasiak</strong>: I use claude code all the time, but never allow it to edit my code. It proposes spaghetti code almost 80% of time</p>
</blockquote>
<blockquote>
<p><strong>philipwhiuk</strong>: I was expecting a showcase to showcase what you&rsquo;ve done with it, not just another person&rsquo;s attempt at instructing an AI to follow instructions.</p>
</blockquote>
<blockquote>
<p><strong>moltar</strong>: If anyone is excited about, and has experience with this kind of stuff, please DM. I have a role open for setting up these kinds of tools and workflows.</p>
</blockquote>
<blockquote>
<p><strong>theanonymousone</strong>: Is Claude &ldquo;Code&rdquo; anything special,or it&rsquo;s mostly the LLM and other CLIs (e.g. Copilot) also work?</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>square_usual</strong>: I&rsquo;ve tried most of the CLI coding tools with the Claude models and I keep coming back to Claude Code. It hits a sweet spot of simple and capable, and right now I&rsquo;d say it&rsquo;s the best from an &ldquo;it just&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>kaydub</strong>: In my experience the CLI tool is part of the secret sauce. I haven&rsquo;t tried switching models per each CLI tool though. I use claude exclusively at work and for personal projects I use claude, codex,&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>speedgoose</strong>: It’s mostly the model, Copilot, Claude Code, OpenCode, snake oil like Oh My OpenCode, it’s not huge differences.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>troupo</strong>: Claude Code seems to package a relatively smart prompt as well, as it seems to work better even with one-line prompts than alternatives that just invoke the API. Key word: seems. It&rsquo;s impossible to&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>pluralmonad</strong>: Why do you call Oh My OpenCode snake oil?</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>gjvc</strong>: &gt; (used voice to text then had claude reword, I am lazy and not gonna hand write it all for yall sorry!) take my downvote as hard as you can.  this sort of thing is awfully off-putting.</p>
</blockquote>
<blockquote>
<p><strong>kaydub</strong>: I&rsquo;m at the point where I say fuck it, let them sleep. The tech industry just went through an insane hiring craze and is now thinning out. This will help to separate the chaff from the wheat. I don&rsquo;t&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>throw1235435</strong>: Not entirely disagreeing with your point but I think they&rsquo;ve mostly been forced to pivot recently for their own sakes; they will never say it though. As much as they may seem eager the most public&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>ps</strong>: OK, I am gonna be the guy and put my skin in the game here. I kind of get the hype, but the experience with e.g. Claude Code (or Github Copilot previously and others as weel) has so far been pretty&hellip;</p>
</blockquote>
<blockquote>
<p><strong>lfliosdjf</strong>: Why dont I see any streams building apps as quickly as they say? Just HYpe</p>
</blockquote>
<blockquote>
<p><strong>winterbloom</strong>: Didn&rsquo;t feel like reading all this so I shortened it! sorry! I shortened it for anyone else that might need it &mdash;- Software engineers are sleeping on Claude Code agents. By teaching it your&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>gjvc</strong>: you are part of the problem</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>mcny</strong>: Everybody says how good Claude is and I go to my code base and I can&rsquo;t get it to correctly update one xaml file for me. It is quicker to make changes myself than to explain exactly what I need or&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>spaceman_2020</strong>: What&rsquo;s even the point of this comment if you self-admittedly don&rsquo;t have access to the flagship tool that everyone has been using to make these big bold coding claims?</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>hu3</strong>: isn&rsquo;t Claude Teams powerful? does it not have access to Opus? pardon my ignorance. I use GitHub Copilot which has access to llms like Gemini 3, Sonnet/Opus 4.5 ang GPT 5.2</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>halfmatthalfcat</strong>: Because the same claims of &ldquo;AI tool does everything&rdquo; are made over and over again.</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>mcv</strong>: Opus 4.5 ate through my Copilot quota last month, and it&rsquo;s already halfway through it for this month. I&rsquo;ve used it a lot, for really complex code. And my conclusion is: it&rsquo;s still not as smart as a&hellip;</p>
<blockquote>
<p><strong>hawtads</strong>: Copilot and many coding agents truncates the context window and uses dynamic summarization to keep costs low for them. That&rsquo;s how they are able to provide flat fee plans. You can see some of the&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>verdverm</strong>: Gerring off of their plans and prompts is so worth it, I know from experience, I&rsquo;m paying less and getting more so far, paying by token, heavy gemini-3-flash user, it&rsquo;s a really good model, this is&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>mcv</strong>: Maybe not, then. I&rsquo;m afraid I have no idea what those numbers mean, but it looks like Gemini and ChatGPT 4 can handle a much larger context than Opus, and Opus 4.5 is cheaper than older versions. Is&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>esperent</strong>: I don&rsquo;t know about GPT4 but the latest one (GPT 5.2) has 200k context window while Gemini has 1m, five times higher. You&rsquo;ll be wanting to stay within the first 100k on all of them to avoid hitting&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>cma</strong>: You need to find where context breaks down, Claude was better at it even when Gemini had 5X more on paper, but both have improved with last releases.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>deanc</strong>: People are completely missing the points about agentic development. The model is obviously a huge factor in the quality of the output, but the real magic lies in how the tools are managing and&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>port3000</strong>: Interesting you have this opinion yet you&rsquo;re using Cursor instead of Claude Code. By the same logic, you should get even better results directly using Anthropic&rsquo;s wrapper for their own model.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>deanc</strong>: My employer doesn&rsquo;t allow for Claude Code yet. I&rsquo;m fully aware from speaking to other peers, that they are getting even better performance out of Claude Code.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>causal</strong>: In my experience GPT-5 is also much more effective in the Cursor context than the Codex context. Cursor deserves props for doing something right under the hood.</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>zmmmmm</strong>: yes just using AI for code analysis is way under appreciated I think. Even the most sceptical people on using it for coding should try it out as a tool for Q&amp;A style code interrogation as well as&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>sfink</strong>: (I haven&rsquo;t used AI much, so feel free to ignore me.) This is one thing I&rsquo;ve tried using it for, and I&rsquo;ve found this to be very, very tricky. At first glance, it seems unbelievably good. The comments&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>zmmmmm</strong>: My main experience is with anthropic models. I&rsquo;ve had some encounters with inaccuracies but my general experience has been amazing. I&rsquo;ve cloned completely foreign git repos, cranked up the tool and&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>mcv</strong>: They do have a knack for missing the point. Even Opus 4.5 can laser focus on the wrong thing. It does take skill and experience to interpret them correctly and set them straight when they go wrong&hellip;.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>josu</strong>: &gt;So my verdict is that it&rsquo;s great for code analysis, and it&rsquo;s fantastic for injecting some book knowledge on complex topics into your programming, but it can&rsquo;t tackle those complex problems by&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>johndough</strong>: All the naysayer here have clearly no idea. Your large matrix multiplication implementation is quite impressive! I have set up a benchmark loop and let GPT-5.1-Codex-Max experiment for a bit (not&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>josu</strong>: Thank you. Yeah, I&rsquo;m doing all those things, which do get you close to the top. The rest of things I&rsquo;m doing are mostly micro-optimizations such as finding a way to avoid AVX→SSE transition penalty&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>zarzavat</strong>: How are you qualified to judge its performance on real code if you don&rsquo;t know how to write a hello world? Yes, LLMs are very good at writing code, they are so good at writing code that they often&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>josu</strong>: I know what&rsquo;s like running a business, and building complex systems. That&rsquo;s not the point. I used highload as an example because it seems like an objective rebuttal to the claim that &ldquo;but it can&rsquo;t&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>VMG</strong>: &gt; Claude is very useful but it&rsquo;s not yet anywhere near as good as a human software developer. Like an excitable puppy it needs to be kept on a short leash. The skill of &ldquo;a human software developer&rdquo;&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>FeepingCreature</strong>: &gt; How are you qualified to judge its performance on real code if you don&rsquo;t know how to write a hello world? The ultimate test of all software is &ldquo;run it and see if it&rsquo;s useful for you.&rdquo; You do not&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>throw1235435</strong>: If that is true; then all the commentary around software people having jobs still due to &ldquo;taste&rdquo; and other nice words is just that. Commentary. In the end the higher level stuff still needs someone&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ModernMech</strong>: None of the problems you&rsquo;ve shown there are anything close to &ldquo;very complex computer engineering problems&rdquo;, they&rsquo;re more like &ldquo;toy problems with widely-known solutions given to students to help them&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>josu</strong>: I think you misunderstood, it&rsquo;s not about solving the problem, is about finding the most efficient solution. Give it a shot, and see if you can get to the top 10 on any task.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>dajoh</strong>: &gt;I&rsquo;m currently #1 on 5 different very complex computer engineering problems Ah yes, well known very complex computer engineering problems such as: * Parsing JSON objects, summing a single field *&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>josu</strong>: Lol, the problem is not finding a solution, the problem is solving it in the most efficient way. If you think you can beat an LLM, the leaderboard is right there.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>yieldcrv</strong>: It acts differently when using it through a third party tool Try it again using Claude Code and a subscription to Claude. It can run as a chat window in VS Code and Cursor too.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>mcv</strong>: My employer gets me a Copilot subscription with access to Claude, not a subscription to Claude Code, unfortunately.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>yieldcrv</strong>: at this point I would suggest getting a $20 subscription to start, seeing if you can expense it the tooling is almost as important as the model</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>NSPG911</strong>: &gt; Opus 4.5 ate theough my Copilot quota last month Sure, Copilot charges 3x tokens for using Opus 4.5, but, how were you still able to use up half the allocated tokens not even one week into January?&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>mcv</strong>: I have no idea. Careless use, I guess. I was fixing a bunch of mocks in some once-great but now poorly maintained code, and I wasn&rsquo;t really feeling it so I just fed everything to Claude. Opus,&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>Davidzheng</strong>: If it can consistently verify that the error persists after fix&ndash;you can run (ok maybe you can&rsquo;t budget wise but theoretically) 10000 parallel instances of fixer agents then verify afterwards (this&hellip;</p>
</blockquote>
<p><strong>multisport</strong>: What bothers me about posts like this is: mid-level engineers are not tasked with atomic, greenfield projects. If all an engineer did all day was build apps from scratch, with no expectation that&hellip;</p>
<blockquote>
<p><strong>redhale</strong>: Not necessarily responding to you directly, but I find this take to be interesting, and I see it every time an article like this makes the rounds. Starting back in 2022/2023: - (~2022) It can&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>arkensaw</strong>: &gt; It&rsquo;s pretty clear to me where this is going. The only question is how long it takes to get there. I don&rsquo;t think its a guarantee. all of the things it can do from that list are greenfield, they just&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>namrog84</strong>: While I do agree with you.  To play the counterpoint advocate though. What if we get to the point where all software is basically created &lsquo;on the fly&rsquo; as greenfield projects as needed? And you never&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>bayindirh</strong>: Well, the first 90% is easy, the hard part is the second 90%. Case in point: Self driving cars. Also, consider that we need to pirate the whole internet to be able to do this, so these models are not&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>throwthrowuknow</strong>: Even if Opus 4.5 is the limit it’s still a massively useful tool. I don’t believe it’s the limit though for the simple fact that a lot could be done by creating more specialized models for each&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>literalAardvark</strong>: They&rsquo;re not blenders. This is clear from the fact that you can distill the logic ability from a 700b parameter model into a 14b model and maintain almost all of it. You just lose knowledge, which can&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>mcfedr</strong>: i like to think of LLMs as random number generators with a filter</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>rat9988</strong>: &gt; Well, the first 90% is easy, the hard part is the second 90%. You&rsquo;d need to prove that this assertion applies here. I understand that you can&rsquo;t deduce the future gains rate from the past, but you&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>PunchyHamster</strong>: Note that blog posts rarely show the 20 other times it failed to build something and only that time that it happened to work. We&rsquo;ve been having same progression with self driving cars and they are&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>redhale</strong>: I agree with your observation, but not your conclusion. The 20 times it failed basically don&rsquo;t matter &ndash; they are branches that can just be thrown away, and all that was lost is a few dollars on&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>theshrike79</strong>: With &ldquo;art&rdquo; we&rsquo;re now at a situation where I can get 50 variations of a image prompt within seconds from an LLM. Does it matter that 49 of them &ldquo;failed&rdquo;? It cost me fractions of a cent, so not really&hellip;.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>sanderjd</strong>: Yeah maybe, but personally it feels more like a plateau to me than an exponential takeoff, at the moment. And this isn&rsquo;t a pessimistic take! I love this period of time where the models themselves are&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>throwthrowuknow</strong>: I can agree that it doesn’t seem exponential yet but this is at least linear progression not a plateau.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>Scea91</strong>: &gt; - (~2023) Ok, it can write a full function, but it can&rsquo;t write a full feature. The trend is definitely here, but even today, heavily depends on the feature. While extra useful, it requires intense&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>EthanHeilman</strong>: I haven&rsquo;t seen an AI successfully write a full feature to an existing codebase without substantial help, I don&rsquo;t think we are there yet. &gt; The only question is how long it takes to get there. This is&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>kubb</strong>: Each of these years we’ve had a claim that it’s about to replace all engineers. By your logic, does it mean that engineers will never get replaced?</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>fernandezpablo</strong>: Starting back in 2022/2023: - (~2022) &ldquo;It&rsquo;s so over for developers&rdquo;. 2022 ends with more professional developers than 2021. - (~2023) &ldquo;Ok, now it&rsquo;s really over for developers&rdquo;. 2023 ends with more&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>HarHarVeryFunny</strong>: Sure, eventually we&rsquo;ll have AGI, then no worries, but in the meantime you can only use the tools that exist today, and dreaming about what should be available in the future doesn&rsquo;t help. I suspect&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>itsthecourier</strong>: I use it on a 10 years codebase, needs to explain where to get context but successfully works 90% of time</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>mjr00</strong>: This is disingenuous because LLMs were already writing full, simple applications in 2023.[0] They&rsquo;re definitely better now, but it&rsquo;s not like ChatGPT 3.5 couldn&rsquo;t write a full simple todo list app in&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>blitz_skull</strong>: What LLM were you using to build full applications in 2023? That certainly wasn’t my experience.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ugurs</strong>: Ok, it can create a long-lived complex codebase for a product that is extensible and scalable over the long term, but it doesn&rsquo;t have cool tattoos and can&rsquo;t fancy a matcha</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>FloorEgg</strong>: There are two types of right/wrong ways to build: the context specific right/wrong way to build something and an overly generalized engineer specific right/wrong way to build things. I&rsquo;ve worked on&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ozim</strong>: *I&rsquo;ve worked on teams where multiple engineers argued about the &ldquo;right&rdquo; way to build something. I remember thinking that they had biases based on past experiences and assumptions about what mattered&hellip;.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>mrheosuper</strong>: &gt;someone had a case that burned them in some previous project and now his life mission is to prevent that from happening ever again Isn&rsquo;t that what makes them senior ? If you dont want that&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>yourapostasy</strong>: &gt; &hellip;multiple engineers argued about the &ldquo;right&rdquo; way to build something. I remember thinking that they had biases based on past experiences and assumptions about what mattered. I usually resolve this&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>gleenn</strong>: That&rsquo;s awesome, but I feel like half the time most people aren&rsquo;t in the position to add requirements so a lot of shenanigans still happens, especially in big corps</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>kalaksi</strong>: &gt; I&rsquo;ve worked on teams where multiple engineers argued about the &ldquo;right&rdquo; way to build something. I remember thinking that they had biases based on past experiences and assumptions about what&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>Ericson2314</strong>: I know what you are talking about, but there is more to life than just product-market fit. Hardly any of us are working on Postgres, Photoshop, blender, etc. but it&rsquo;s not just cope to wish we were&hellip;.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>sanderjd</strong>: &gt; I&rsquo;m hoping for a world where more end users code (vibe or otherwise) and the solve their own problems with their own software. I think that will make more a smaller, more elite software industry&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>swat535</strong>: Users will not care about the quality of your code, or the backed architecture, or your perfectly strongly typed language. They only care about their problems and treat their computers like an&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>saxenaabhi</strong>: &gt; There are legitimate reasons for the startup ecosystem to focus firstly and primarily on getting the users/customers. I&rsquo;m not arguing against that. What I am arguing is why does the industry need&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>fenwick67</strong>: Another thing that gets me with projects like this, there are already many examples of image converters, minesweeper clones etc that you can just fork on GitHub, the value of the LLM here is largely&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>sksishbs</strong>: It’s kind of funny - there’s another thread up where a dev claimed a 20-50x speed up. To their credit they posted videos and links to the repo of their work. And when you check the work, a large&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>yourapostasy</strong>: Reminds me of a post I read a few days ago of someone crowing about an LLM writing for them an email format validator. They did not have the LLM code up an accompanying send-an-email-validation loop,&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>suzzer99</strong>: I&rsquo;ve hand-rolled my own ultra-light ORM because the off-the-shelf ones always do 100 things you don&rsquo;t need.* And of course the open source ones get abandoned pretty regularly. Type ORM, which a 3rd&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>patates</strong>: It seems to me these days, any code I want to write tries to solve problems that LLMs already excel at. Thankfully my job is perhaps just 10% about coding, and I hope people like you still have some&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>paipa</strong>: &ldquo;And likely just creating more debt down the road&rdquo; In the most inflationary era of capabilities we&rsquo;ve seen yet, it could be the right move. What&rsquo;s debt when in a matter of months you&rsquo;ll be able to&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>melagonster</strong>: - I cloned a project from GitHub and made some minor modifications. - I used AI-assisted programming to create a project. Even if the content is identical, or if the AI is smart enough to replicate&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>jasonfarnon</strong>: I think I would prefer the former if I were reviewing a CV. It at least tells me they understood the code well enough to know where to make their minor tweaks. (I&rsquo;ve spent hours reading through a&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>fenwick67</strong>: Do people really see a CV and read &ldquo;computer mommy made me a program&rdquo; and think it&rsquo;s impressive</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>zwnow</strong>: I&rsquo;d quickly trash your application if I see you just vibe coded some bullshit app. Developing is about working smart, and its not smart to ask AI to code stuff that already exists, its in fact&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>infinitezest</strong>: A CV for the disappearing job market as you shovel money into a oligarchy.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>scotty79</strong>: Have you ever tried to find software for a specific need? I usually spend hours investigating anything I can find only to discover that all options are bad in one way or another and cover my use case&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>coffeebeqn</strong>: Anecdata but I’ve found Claude code with Opus 4.5 able to do many of my real tickets in real mid and large codebases at a large public startup. I’m at senior level (15+ years). It can browse and&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>wiz21c</strong>: Same anecdote for me (except I&rsquo;m +/- 40 years experience). I consider my self a pretty good dev for non-web dev (GPU&rsquo;s, assembly, optimisation,&hellip;) and my conclusion is the same as you: impressive&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>murukesh_s</strong>: Scary is that the LLM might have been trained on the entire open source code ever produced - which is far beyond human comprehension - and with ever growing capability (bigger context window, more&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>weatherlite</strong>: I&rsquo;m seeing this as well. Not huge codebases but not tiny - 4 year old startup. I&rsquo;m new there and it would have been impossible for me to deliver any value this soon.  12 years experience; this thing&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>jarjoura</strong>: I&rsquo;ve also found it to keep such a constrained context window (on large codebases), that it writes a secondary block of code that already had a solution in a different area of the same file. Nothing I&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>sreekanth850</strong>: Same exist in humans also, I worked with a developer who had 15 year experience and was tech lead in a big Indian firm, We started something together, 3 months back when I checked the Tables I was&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>pastage</strong>: This sounds like a culture issue in the development process, I have seen this prevented many times. Sure I did have to roll back a feature I did not sign off just before new years. So as you say it&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>potamic</strong>: How did he not share code if you&rsquo;re working together?</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>sreekanth850</strong>: yes, it was my mistake. I trusted him because he was my childhood friend and my cousin. He was a tech lead in CMMI Level  5 (serving fortune 500 firms) company at the time he joined with me. I had&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>SeanAppleby</strong>: One thing I&rsquo;ve been tossing around in my head is: - How quickly is cost of refactor to a new pattern with functional parity going down? - How does that change the calculus around tech debt? If&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ekidd</strong>: &gt; But if claude can reliably reorganize code, fix patterns, and write working migrations for state when prompted to do so, it seems like the entire way to reason about tech debt has changed. Yup, I&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>edg5000</strong>: Good point. Most of the cost in dealing with tech debt is reading the code and noting the issues. I found that Claude can produce much better code when it has a functionally correct reference&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>whynotminot</strong>: &gt; The hard thing about engineering is not &ldquo;building a thing that works&rdquo;, its building it the right way, in an easily understood way, in a way that&rsquo;s easily extensible. You’re talking like in the year&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>nine_k</strong>: This sounds like magical thinking. For one, there are objectively detrimental ways to organize code: tight coupling, lots of mutable shared state, etc. No matter who or what reads or writes the code,&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>scotty79</strong>: &gt; For one, there are objectively detrimental ways to organize code: tight coupling, lots of mutable shared state, etc. No matter who or what reads or writes the code, such code is more error-prone,&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>cryptica</strong>: Yes LLMs aren&rsquo;t very good at architecture. I suspect because the average project online has pretty bad architecture. The training set is poisoned. It&rsquo;s kind of bittersweet for me because I was&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>Bridged7756</strong>: Opus 4.5 is writing code that Opus 5.0 will refactor and extend. And Opus 5.5 will take that code and rewrite it in C from the ground up. And Opus 6.0 will take that code and make it assembly. And&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>TheOtherHobbes</strong>: Objectively, we are talking about systems that have gone from being cute toys to outmatching most juniors using only rigid and slow batch training cycles. As soon as models have persistent memory for&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>latentsea</strong>: Can&rsquo;t wait to see what Opus 13.0 does with the multiverse.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>mfalcon</strong>: Wake me up at Opus 12</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>lomase</strong>: Just one more OPUS bro.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>zwnow</strong>: I also love how AI enthusiasts just ignore the issue of exhausted training data&hellip; You cant just magically create more training data. Also synthetic training data reduces the quality of models.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>BobbyJo</strong>: Up until now, no business has been built on tools and technology that no one understands. I expect that will continue. Given that, I expect that, even if AI is writing all of the code, we will still&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>hnfong</strong>: &gt; Up until now, no business has been built on tools and technology that no one understands. I expect that will continue. Big claims here. Did brewers and bakers up to the middle ages understand&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>gabriel-uribe</strong>: Does the corner bakery need a moat to be a business? How many people understand the underlying operating system their code runs on? Can even read assembly or C? Even before LLMs, there were plenty of&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>pillefitz</strong>: Most legacy apps are barely understood by anyone, and yet continue to generate value and and are (somehow) kept alive.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>gf000</strong>: &gt; no business has been built on tools and technology that no one understands Well, there are quite a few common medications we don&rsquo;t really know how they work. But I also think it can be a huge&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>devinplatt</strong>: In my experience, using LLMs to code encouraged me to write better documentation, because I can get better results when I feed the documentation to the LLM. Also, I&rsquo;ve noticed failure modes in LLM&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>mcv</strong>: I&rsquo;ve also noticed that going off the rails. At the start of a session, they&rsquo;re pretty sharp and focused, but the longer the session lasts, the more confused they get. At some point they start&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>Ericson2314</strong>: We don&rsquo;t know what Opus 5.0 will be able to refactor. If argument is &ldquo;humans and Opus 4.5 cannot maintain this, but if requirements change we can vibe-code a new one from scratch&rdquo;, that&rsquo;s a coherent&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>sponnath</strong>: Refactoring does always cost something and I doubt LLMs will ever change that. The more interesting question is whether the cost to refactor or &ldquo;rewrite&rdquo; the software will ever become negligible&hellip;.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>sanderjd</strong>: This is the question! Your narrative is definitely plausible, and I won&rsquo;t be shocked if it turns out this way. But it still isn&rsquo;t my expectation. It wasn&rsquo;t when people were saying this in 2023 or in&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>whynotminot</strong>: Yeah, I might be early to this. And certainly, I still read a lot of code in my day to day right now. But I sure write a lot less of it, and the percentage I write continues to go down with every new&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>maplethorpe</strong>: Yeah I think it&rsquo;s a mistake to focus on writing &ldquo;readable&rdquo; or even &ldquo;maintainable&rdquo; code. We need to let go of these aging paradigms and be open to adopting a new one.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>aeternum</strong>: In my experience, LLMs perform significantly better on readable maintainable code. It&rsquo;s what they were trained on after-all. However what they produce is often highly readable but not very&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>alexjplant</strong>: &gt; Poe&rsquo;s law is an adage of Internet culture which says that any parodic or sarcastic expression of extreme views can be mistaken for a sincere expression of those views. The things you mentioned are&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>foldingmoney</strong>: as depressing as it is to say, i think it&rsquo;s a bit like the year is 1906 and we&rsquo;re complaining that these new tyres for cars they&rsquo;re making are bad because they&rsquo;re no longer backwards compatible with&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>jjaksic</strong>: Do readability and maintainability not matter when AI &ldquo;reads&rdquo; and maintains the code? I&rsquo;m pretty sure they do.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>gf000</strong>: If that would be true, you could surely ask an LLM to write the same complexity apps in brainfuck, right?</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>koyote</strong>: A greenfield project is definitely &rsquo;easy mode&rsquo; for an LLM; especially if the problem area is well understood (and documented). Opus is great and definitely speeds up development even in larger code&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>pigpop</strong>: You have to think of Opus as a developer whose job at your company lasts somewhere between 30 to 60 minutes before you fire them and hire a new one. Yes, it&rsquo;s absurd but it&rsquo;s a better metaphor than&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>suzzer99</strong>: &gt; You have to think of Opus as a developer whose job at your company lasts somewhere between 30 to 60 minutes before you fire them and hire a new one. I am stealing the heck out of this.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>pigpop</strong>: Follow up: Opus is also great for doing the planning work before you start. You can use plan mode or just do it in a web chat and have them create all of the necessary files based on your&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>Sammi</strong>: I just did something similar and it went swimmingly by doing this: Keep the plan and status in an md file. Tell it to finish one file at a time and run tests and fix issues and then to ask whether to&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>koyote</strong>: I might give that a go in the future, but in this case it would&rsquo;ve been faster for me to just do the work than to coach it for each file. Also as this was an architectural change there are no tests&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>edg5000</strong>: This will work (if you add more details): &ldquo;Have an agent investiate issue X in modules Y and Z. The agent should place a report at ./doc/rework-xyz-overview.md with all locations that need&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>gck1</strong>: And you can automate all this so that it happens every time. I have an <code>/implement</code> command that is basically instructed to launch the agents and then do back and forth between them. Then there&rsquo;s a&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>svara</strong>: &gt; If all an engineer did all day was build apps from scratch, with no expectation that others may come along and extend, build on top of, or depend on, then sure, Opus 4.5 could replace them. Why do&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>girvo</strong>: Because we’re expensive and companies would love to get rid of us</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>whatever1</strong>: Their thesis is that code quality does not matter as it is now a cheap commodity. As long as it passes the tests today it&rsquo;s great. If we need to refactor the whole goddamn app tomorrow, no problem,&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>estimator7292</strong>: The fundamental assumption is completely wrong. Code is not a cheap commodity. It is in fact so disastrously expensive that the entire US economy is about to implode while we&rsquo;re unbolting jet engines&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>whatever1</strong>: It is massively cheaper than an overseas engineer. A cheap engineer can pump out maybe 1000 lines of low quality code in an hour. So like 10k tokens per hour for $50. So best case scenario $5/1000&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>PunchyHamster</strong>: Now that entirely depends on app. A lot of software industry is popping out and maintaining relatively simple apps with small differences and customizations per client.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>babelfish</strong>: [citation needed]</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>throwaway173738</strong>: It matters for all the things you’d be able to justify paying a programmer for. What’s about to change is that there will be tons of these little one-off projects that previously nobody could justify&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>inopinatus</strong>: We already know what that looks like, because PHP happened.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>Ancapistani</strong>: &gt; Their thesis is that code quality does not matter as it is now a cheap commodity. That&rsquo;s not how I read it. I would say that it&rsquo;s more like &ldquo;If a human no longer needs to read the code, is it&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>multisport</strong>: Yes agreed, and tbh even if that thesis is wrong, what does it matter?</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>lacunary</strong>: in my experience, what happens is the code base starts to collapse under its own weight. it becomes impossible to fix one thing without breaking another. the coding agent fails to recognize the&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>whatever1</strong>: The whole point of good engineering was not about just hitting the hard specs, but also have extendable, readable, maintainable code. But if today it’s so cheap to generate new code that meets&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>qingcharles</strong>: I had Opus write a whole app for me in 30 seconds the other night. I use a very extensive AGENTS.md to guide AI in how I like my code chiseled. I&rsquo;ve been happily running the app without looking at a&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>lomase</strong>: Can you show us that amazing 10/10 app?</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>qingcharles</strong>: It&rsquo;s a not very exciting C# command-line app that takes a PDF and emits it as a sprite sheet with a text file of all the pixel positions of each page :)</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>philipodonnell</strong>: You should just need the AGENTS.md right?</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>coldtea</strong>: &gt;What bothers me about posts like this is: mid-level engineers are not tasked with atomic, greenfield projects They get those ocassionally all the time though too. Depends on the company. In some&hellip;</p>
</blockquote>
<blockquote>
<p><strong>coryrc</strong>: &gt; its building it the right way, in an easily understood way, in a way that&rsquo;s easily extensible. When I worked at Google, people rarely got promoted for doing that. They got promoted for delivering&hellip;</p>
</blockquote>
<blockquote>
<p><strong>lallysingh</strong>: Yeah.  Just like another engineer.  When you tell another engineer to build you a feature, it&rsquo;s improbable they&rsquo;ll do it they way that you consider &ldquo;right.&rdquo; This sounds a lot like the old arguments&hellip;</p>
</blockquote>
<blockquote>
<p><strong>patates</strong>: You can look at my comment history to see the evidence to how hostile I was to agentic coding. Opus 4.5 completely changed my opinion. This thing jumped into a giant JSF (yes, JSF) codebase and&hellip;</p>
</blockquote>
<blockquote>
<p><strong>EthanHeilman</strong>: Even if you are going green field, you need to build it the way it is likely to be used based a having a deep familiarity with what that customer&rsquo;s problems are and how their current workflow is&hellip;</p>
</blockquote>
<blockquote>
<p><strong>qwm</strong>: My favorite benchmark for LLMs and agents is to have it port a medium-complexity library to another programming language. If it can do that well, it&rsquo;s pretty capable of doing real tasks. So far, I&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>Rastonbury</strong>: Comments on here often criticise ports as easy for LLMs to do because there&rsquo;s a lot of training and tests are all there, which is not as complex as real word tasks</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>ivanech</strong>: I find Opus 4.5 very, very strong at matching the prevailing conventions/idioms/abstractions in a large, established codebase. But I guess I&rsquo;m quite sensitive to this kind of thing so I explicitly&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>falkensmaize</strong>: I don’t know what I’m doing wrong. Today I tried to get it to upgrade Nx, yarn and some resolutions in a typescript monorepo with about 20 apps at work (Opus 4.5 through Kiro) and it just…couldn’t do&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>tac19</strong>: &gt;  ask Opus 4.5 to read adjacent code which is perhaps why it does it so well. All it takes is a sentence or two, though. People keep telling me that an LLM is not intelligence, it&rsquo;s simply spitting&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>latentsea</strong>: I used to agree with this stance, but lately I&rsquo;m more in the &ldquo;LLMs are just fancy autocomplete&rdquo; camp. They can just autocomplete increasingly more things, and when they can&rsquo;t, they fail in ways that&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>colechristensen</strong>: &gt;day to day, when I ask it &ldquo;build me this feature&rdquo; it uses strange abstractions, and often requires several attempts on my part to do it in the way I consider &ldquo;right&rdquo; Then don&rsquo;t ask it to &ldquo;build me&hellip;</p>
</blockquote>
<blockquote>
<p><strong>Madmallard</strong>: Based on my experience using these LLMs regularly I strongly doubt it could even build any application with realistic complexity without screwing things up in major ways everywhere, and even on top&hellip;</p>
</blockquote>
<blockquote>
<p><strong>michael_forrest</strong>: This! I can count on one hand the number of times I&rsquo;ve had a chance to spin up a greenfield project, prototype or proof of concept in my 30 year career. Those were always stolen moments, and the&hellip;</p>
</blockquote>
<blockquote>
<p><strong>miki123211</strong>: In my personal experience, Claude is better at greenfield, Codex is better at fitting in. Claude is the perfect tool for a &ldquo;vibe coder&rdquo;, Codex is for the serious engineer who wants to get great and&hellip;</p>
</blockquote>
<blockquote>
<p><strong>Balinares</strong>: Exactly. The main issue IMO is that &ldquo;software that seems to work&rdquo; and &ldquo;software that works&rdquo; can be very hard to tell apart without validating the code, yet these are drastically different in terms of&hellip;</p>
</blockquote>
<blockquote>
<p><strong>avereveard</strong>: But&hellip; you can ask! Ask claude to use encapsulation, or to write the equivalent of interfaces in the language you using, and to map out dependencies and duplicate features, or to maintain a&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>verall</strong>: But time I spend asking is time I could have been writing exactly what I wanted in the first place, if I already did the planning to understand what I wanted. Once I know what I want, it doesn&rsquo;t take&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>AndrewKemendo</strong>: &gt; The hard thing about engineering is not &ldquo;building a thing that works&rdquo;, its building it the right way, in an easily understood way, in a way that&rsquo;s easily extensible. The number of production&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>kaashif</strong>: I think there is a subjective difference. When a human builds dogshit at least you know they put some effort and the hours in. When I&rsquo;m reading piles of LLM slop, I know that just reading it is&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>parpfish</strong>: If you are heavily using LLMs, you need to change the way you think about reviews I think most people now approach it as: Dev0 uses an LLM to build a feature super fast, Dev1 spends time doing a in&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>AndrewKemendo</strong>: Your comment doesn’t address what I said and instead finds a new reason that it’s invalid because “reviewing code from a machine system is beneath me” Get over yourself</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>KentLatricia</strong>: Another thing these posts assume is a single developer keep working on the product with a number of AI agents, not a large team. I think we need to rethink how teams work with AI. Its probably not&hellip;</p>
</blockquote>
<blockquote>
<p><strong>noodletheworld</strong>: It might scale. So far, Im not convinced, but lets take a look at fundmentally whats happening and why humans &gt; agents &gt; LLMs. At its heart, programming is a constraint satisfaction problem. The more&hellip;</p>
</blockquote>
<blockquote>
<p><strong>nialse</strong>: After recently applying Codex to a gigantic old and hairy project that is as far from greenfield it can be, I can assure you this assertion is false. It’s bonkers seeing 5.2 churn though the&hellip;</p>
</blockquote>
<blockquote>
<p><strong>herpdyderp</strong>: On the contrary, Opus 4.5 is the best agent I’ve ever used for making cohesive changes across many files in a large, existing codebase. It maintains our patterns and looks like all the other code&hellip;.</p>
</blockquote>
<blockquote>
<p><strong>scotty79</strong>: If you have microservices architecture in your project you are set for AI. You can swap out any lacking, legacy microservice in your system with &ldquo;greenfield&rdquo; vibecoded one.</p>
</blockquote>
<blockquote>
<p><strong>Havoc</strong>: &gt; greenfield LLMs are pretty good at picking up existing codebases. Even with cleared context they can do „look at this codebase and this spec doc that created it. I want to add feature x“</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>le-mark</strong>: What size of code base are you talking about? And this is your personal experience?</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>Havoc</strong>: Overall Codebase size vs context matter less when you set it up as microservices style architecture from the starts. I just split it into boundaries that make sense to me. Get the LLM to make a quick&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>volkanvardar</strong>: I totally agree. And welcome to disposable software age.</p>
</blockquote>
<blockquote>
<p><strong>fooker</strong>: It just one shots bug fixes in complex codebases. Copy-paste the bug report and watch it go.</p>
</blockquote>
<blockquote>
<p><strong>epolanski</strong>: Yeah, all of those applications he shows do not really expose any complex business logic. With all the due respect: a file converter for windows is glueing few windows APIs with the relevant codec&hellip;.</p>
</blockquote>
<blockquote>
<p><strong>wilg</strong>: you can definitely just tell it what abstractions you want when adding a feature and do incremental work on existing codebase. but i generally prefer gpt-5.2</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>boppo1</strong>: I&rsquo;ve been using 5.2 a lot lately but hit my quota for the first time (and will probably continue to hit it most weeks) so I shelled out for claude code. What differences do you notice? Any &lsquo;metagame&rsquo;&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>wilg</strong>: I just use Cursor because I can pick any mode. The difference is hard to say exactly, Opus seems good but 5.2 seems smarter on the tasks I tried. Or possibly I just &ldquo;trust&rdquo; it more. I tend to use&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>kevinsync</strong>: Man, I&rsquo;ve been biting my tongue all day with regards to this thread and overall discussion. I&rsquo;ve been building a somewhat-novel, complex, greenfield desktop app for 6 months now, conceived and&hellip;</p>
</blockquote>
<blockquote>
<p><strong>llm_nerd</strong>: &ldquo;its building it the right way, in an easily understood way, in a way that&rsquo;s easily extensible&rdquo; I am in a unique situation where I work with a variety of codebases over the week. I have had no&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>what</strong>: &gt;llm_nerd &gt;created two years ago You AI hype thots/bots are all the same. All these claims but never backed up with anything to look at. And also alway claiming “you’re holding it wrong”.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>pigpop</strong>: I don&rsquo;t see how &ldquo;two years ago&rdquo; is incongruous with having been using LLMs for coding, it&rsquo;s exactly the timeline I would expect. Yes, some people do just post &ldquo;git gud&rdquo; but there are many people ITT&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>llm_nerd</strong>: &gt;You AI hype thots/bots are all the same This isn&rsquo;t twitter, so save the garbage rhetoric. And if you must question my account, I create a new account whenever I setup a new main PC, and randomly&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>doxeddaily</strong>: I also have &gt;30 years and I&rsquo;ve had the same experience.  I noticed an immediate improvement with 4.5 and I&rsquo;ve been getting great results in general. And yes I do make sure it&rsquo;s not generating crazy&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>llm_nerd</strong>: HN has a subset of users &ndash; they&rsquo;re a minority, but they hit threads like this super hard &ndash; who really, truly think that if they say that AI tools suck and are only for nubs loud enough and&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>s-macke</strong>: Opus 4.5 has become really capable. Not in terms of knowledge. That was already phenomenal. But in its ability to act independently: to make decisions, collaborate with me to solve problems, ask&hellip;</p>
<blockquote>
<p><strong>s-macke</strong>: Just some examples I’ve already made public. More complex ones are in the pipeline. With [0], I’m trying to benchmark different coding-agents. With [1], I successfully reverse-engineered an old C64&hellip;</p>
</blockquote>
<blockquote>
<p><strong>lelanthran</strong>: &gt; You have to experience it yourself on your own real problems and over the course of days or weeks. How do you stop it from over-engineering everything?</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>petcat</strong>: This has always been my problem whether it&rsquo;s Gemini, openai or Claude. Unless you hand-hold it to an extreme degree, it is going to build a mountain next to a molehill. It may end up working, but the&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>jama211</strong>: Not in my experience - you need to build the fact that you don’t want it to do that into your design and specification.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>spaceman_2020</strong>: It&rsquo;s very good at following instructions. You can build dedicated agents for different tasks (backend, API design, database design) and make it follow design and coding patterns. It&rsquo;s verbose by&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>s-macke</strong>: Difficult and it really depends on the complexity. I definitely work in a spec-driven way, with a step-by-step implementation phase. If it goes the wrong way I prefer to rewrite the spec and throw&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ryanchants</strong>: I have it propose several approaches, pick and choose from each, and remove what I don&rsquo;t want done. &ldquo;Use the general structure of A, but use the validation structure of D. Using a view translation&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>dbbk</strong>: The Plan mode already does this, it makes multiple plans and then synthesises them</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>bdangubic</strong>: “Everything Should Be Made as Simple as Possible, But Not Simpler” should be the ending of every prompt :)</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>myvoiceismypass</strong>: I personally try to narrow scope as much as possible to prevent this. If a human hands me a PR that is not digestible size-wise and content-wise (to me), I am not reviewing and merging it. Same thing&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>verdverm</strong>: Instructions, in the system prompt for not doing that Once more people realize how easy it is to customize and personalized your agent, I hope they will move beyond what cookie cutter Big AI like&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>jghn</strong>: I find my sweet spot is using the Claude web app as a rubber duck as well as feeding it snippets of code and letting it help me refine the specific thing I&rsquo;m doing. When I use Claude Code I find that&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>pigpop</strong>: I&rsquo;ve had similar experiences but I&rsquo;ve been able to start using Claude Code for larger projects by doing some refactoring with the goal of making the codebase understandable by just looking at the&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>fragmede</strong>: By &ldquo;the website&rdquo; do you mean you&rsquo;re copy pasting, or are you using the code system where Anthropic clones your code from GitHub and interacts with it in a VM/container for you.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>jghn</strong>: Just pasting code snippets, and occasionally an entire file or two into the main claude.com site. I usually already know what I want and need, but just want to speed up the process on how to get&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>giancarlostoro</strong>: &gt; In the traditional sense, I haven’t really coded privately at all in recent weeks. Instead, I’ve been guiding and directing, having it write specifications, and then refining and improving them&hellip;.</p>
</blockquote>
<blockquote>
<p><strong>jesse_dot_id</strong>: This has also been my experience.</p>
</blockquote>
<p><strong>YesBox</strong>: I&rsquo;ve noticed a huge drop in negative comments on HN when discussing LLMs in the last 1-2 months. All the LLM coded projects I&rsquo;ve seen shared so far[1] have been tech toys though. I&rsquo;ve watched things&hellip;</p>
<blockquote>
<p><strong>blibble</strong>: &gt; I&rsquo;ve noticed a huge drop in negative comments on HN when discussing LLMs in the last 1-2 months. real people get fed up of debating the same tired &ldquo;omg new model 1000x better now&rdquo; posts/comments&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>hollowturtle</strong>: Simply this ^ I&rsquo;m tired of debating bots and people paid to grow the hype, so I won&rsquo;t anymore I&rsquo;ll just work and look for the hype passing by from a distance. In the meanwhile I&rsquo;ll keep waiting for&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>g947o</strong>: Especially when 90% of these articles are based on personal, anecdotally evidence and keep repeating the same points without offering anything new. If these articles actually provide quantitative&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>simonw</strong>: You&rsquo;re only hurting yourself if you decide there&rsquo;s some wild conspiracy afoot here to pay shills to tell people that coding agents are useful&hellip; as opposed to people finding them useful enough to&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>dudeinhawaii</strong>: This is a cringe comment from an era of when &ldquo;Micro$oft&rdquo; was hip and reads like you are a fanboi for Anthropic/Google foaming at the mouth. Would be far more useful if you provided actual verifiable&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>simonw</strong>: It could be that the people who are focused on building monetizable products with LLMs don&rsquo;t feel the need to share what they are doing - they&rsquo;re too busy quietly getting on with building and&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>enraged_camel</strong>: I admit I&rsquo;m in this boat. I get immense value from LLMs, easily 5x if not more, and the codebases I work in are large, mature and complex. But providing &ldquo;receipts&rdquo; as the kids call it these days&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>YesBox</strong>: Agreed! LLMs are a force multiplier for real products too. They&rsquo;re going to augment people who are willing to do the real work. But, Im also wondering if LLMs are going to create a new generation of&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>lillutoo</strong>: I feel weird when I read comments that have words like &ldquo;force mulitplier&rdquo;. This sounds like an LLM comment. But you probably are a real person. So are you just becoming more like an LLM because you&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>yeasku</strong>: What would be more likely, That people making startups is too bussy working to share it on HN or that AI is useless in real projects.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>pigpop</strong>: If you haven&rsquo;t noticed, people come here to kill time. If you&rsquo;re killing time then you&rsquo;re not being productive, therefor the people who are heads down trying to launch their startup before they run&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>atonse</strong>: The former.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>bombdailer</strong>: The type of people to use AI are necessarily the people who will struggle most when it comes time to do the last essential 20% of the work that AI can&rsquo;t do. Once thinking is required to bring all the&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>Krei-se</strong>: I think you can tell from some answers here that people talk to these models a lot and adapt their language structure :( Means they stop asking themselves whether it makes any sense what they ask the&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>simonw</strong>: Using AI tools makes me think harder.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>acosmism</strong>: harder != better</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>TheAceOfHearts</strong>: Deploying and maintaining something in a production-ready environment is a huge amount of work. It&rsquo;s not surprising that most people give up once they have a tech demo, especially if they&rsquo;re not&hellip;</p>
</blockquote>
<blockquote>
<p><strong>Havoc</strong>: &gt; huge drop in negative comments on HN when discussing LLMs I interpret it more as spooked silence</p>
</blockquote>
<blockquote>
<p><strong>bcrosby95</strong>: Yeah, I do a lot of hobby game making and the 80/20 rule definitely applies.  Your game will be &ldquo;done&rdquo; in 20% of the time it takes to create a polished product ready for mass consumption. Stopping&hellip;</p>
</blockquote>
<blockquote>
<p><strong>elzbardico</strong>: Sometimes I feel like a lot of those posts are instances of Kent Brockman: &ldquo;I for one, welcome our new insect overlords.&rdquo; Given the enthusiasm of our ruling class towards automating software&hellip;</p>
</blockquote>
<p><strong>rcarmo</strong>: I had a similar set of experiences with GPT 5.x over the holiday break, across somewhat more disparate domains: <a href="https://taoofmac.com/space/notes/2025/12/31/1830">https://taoofmac.com/space/notes/2025/12/31/1830</a> I hacked together a Swift tool to&hellip;</p>
<blockquote>
<p><strong>heavyset_go</strong>: To add to the anecdata, today GPT 5.2-whatever hallucinated the existence of two CLI utilities, and when corrected, then hallucinated the existence of non-existent, but plausible, features/options of&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>simonw</strong>: Were you running it inside a coding agent like Codex? If so then it should have realized its mistake when it tried to run those CLI commands and saw the error message. Then it can try something&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>heavyset_go</strong>: No, Codex doesn&rsquo;t have permission to install random software on my machine and then execute it to see if it&rsquo;s real or a hallucination. CLI utility here means software with a CLI, not classic Unix-y&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>hashhar</strong>: Codex for me behaves very junior engineer-ish. Claude is smarter and tries to think long term. A great example of their behaviours for a problem that isn&rsquo;t 100% specified in detail (because detail&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>tezza</strong>: Yeah, it needs a steady hand on the tiller. However throw together improvements of 70%, -15%, 95%, 99%, -7% across all the steps and overall you&rsquo;re way ahead. SimonW&rsquo;s approach of having a suite of&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>Kerrick</strong>: Gemini 3 Pro (High) via Antigravity has been similarly great recently. So have tools that I imagine call out to these higher-power models: Amp and Junie. In a two-week blur I brought forth the bulk&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>chaostheory</strong>: Were they able to link Antigravity to your paid subscription? I have a Google ultra AI sub and antigrav ran out of credits within 30 minutes for me. Of course that was a few weeks ago, and I’m hoping&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>Kerrick</strong>: Yes. I was on a 30-day trial of Google AI Pro and I got a few big wins each out of Gemini 3 Pro (High) and Claude 4.5 Opus (Thinking) before my quota got reset. Then I&rsquo;d cycle through Gemini 3 Flash&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>kgeist</strong>: I tried generating code with ChatGPT 5.2, but the results weren&rsquo;t that great: 1) It often overcomplicates things for me. After I refactor its code, it&rsquo;s usually half the size and much more readable&hellip;.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>rcarmo</strong>: Well, like I pointed out somewhere else, VS Code gives it a set of prompts and tools that makes it very effective for me. I see that a lot of people are still copy/pasting stuff instead of having the&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>IgorPartola</strong>: The thing is that CLI utilities code is probably easier to write for an LLM than most other things. In my experience an LLM does best with backend and terminal things. Anything that resembles&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>simonw</strong>: I&rsquo;ve been having a surprising amount of success recently telling Claude Code to test the frontend it&rsquo;s building using Playwright, including interacting with the UI and having it take its own&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>throwup238</strong>: That works well with QT and desktop apps as well. Asking Claude Code to write an MCP integrated into a desktop all implementing the same features as Playwright is a half hour exercise.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>johnfn</strong>: It&rsquo;s kind of funny that we posted basically the exact comment at the same time, down to quoting &ldquo;see&rdquo;!</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>smoe</strong>: In my experience with a combo of Claude Code and Gemini Pro (and having added Codex to the mix about a week ago as well), it matters less whether it’s CLI, backend, frontend, DB queries, etc. but&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>rcarmo</strong>: Since one of my holiday projects was completely rebuilding the Node-RED dashboard in Preact, I have to challenge that a bit. How were you using the model?</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>johnfn</strong>: I couldn&rsquo;t disagree more. I&rsquo;ve had Claude absolutely demolish large HTML/CSS/JS/React projects. One key is to give it some way to &ldquo;see&rdquo; and interact with the page. I usually use Playwright for this&hellip;.</p>
</blockquote>
</blockquote>
<p><strong>tripledry</strong>: Putting the performance aside for now as I just started trying out Opus 4.5, can&rsquo;t say too much yet, I don&rsquo;t hype or hate AI as of now, it&rsquo;s simply useful. Time will tell what happens, but if&hellip;</p>
<blockquote>
<p><strong>keychera</strong>: I have similar stance to you. LLM has been very useful for me but it doesn&rsquo;t really change the fun-ness of programming since my circumstances has allowed me find programming to be very fun. I also&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>tripledry</strong>: Yes, not too optimistic on the art side when it comes to commercial stuff - if you can generate it cheaply it will be used. On the hobby side (music) I don&rsquo;t feel the pressure as bad but that&rsquo;s&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>weatherlite</strong>: &gt; Time will tell what happens, but if programming becomes &ldquo;prompt engineering&rdquo;, I&rsquo;m planning on quitting my job and pivoting to something else. It&rsquo;s nice to get stuff working fast, but AI just sucks&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>tripledry</strong>: Sure, IF the performance + economics is there. But that doesn&rsquo;t sound like an enjoyable profession to me. I enjoy the plan, think, code cycle - it&rsquo;s just fun. My brain has problems with not&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>weatherlite</strong>: To me it&rsquo;s more of a mixed bag. On the one hand - disheartening to see how the knowledge base and skills I&rsquo;ve worked more than a decade to develop became of little value (not worthless, but not as&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>seanmcdirmid</strong>: Pity, prompt engineering is just another kind of programming, I find it to be fun, but I guess lots of other people would see it differently.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>friendzis</strong>: The venn diagram of engineering and prompting is two circles, maybe a tiny overlap with integrated environments like claude code. A program, by definition, is analyzable and repeatable, whereas&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>seanmcdirmid</strong>: As long as your program is large and multi-threaded (most programs that matter commercially), it is not very analyzable or repeatable. You replace those qualities with QA and tests, the same is true&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>tripledry</strong>: Indeed it is another kind of programming, I simply don&rsquo;t enjoy it. But it is also very early to say, maybe the next iteration of tools will completely change my perspective, I might enjoy it some day!</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>FiberBundle</strong>: Programming without flow state. Nice.</p>
</blockquote>
</blockquote>
<p><strong>honeycrispy</strong>: A couple weeks ago I had Opus 4.5 go over my project and improve anything it could find. It &ldquo;worked&rdquo; but the architecture decisions it made were baffling, and had many, many bugs. I had to rewrite&hellip;</p>
<blockquote>
<p><strong>tda</strong>: Instead you should prompt it to come up with suggestions, look for inconsistencies etc. Then you get a list, and you pick the ones you find promising. Then you ask Claude to explain what why and how&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>hollowturtle</strong>: And waste a lot of time reviewing and baby sitting</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>thousand_nights</strong>: these models work best when you know what you want to achieve and it helps you get there while you guide it. &ldquo;Improve anything you can find&rdquo; sounds like you didn&rsquo;t really know</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>mcv</strong>: As a tool to help developers I think it&rsquo;s really useful. It&rsquo;s great at stuff people are bad at, and bad at stuff people are good at. Use it as a tool, not a replacement.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>suzzer99</strong>: &ldquo;Improve anything you can find&rdquo; is like going to your mechanic and saying &ldquo;I&rsquo;m going on a long road trip, can you tell me anything that needs to be fixed?&rdquo; They&rsquo;re going to find a lot of stuff to fix.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>blub</strong>: Doing a vehicle check-up is a pretty normal thing to do, although in my case the mandatory (EU law) periodic ones are happening often enough that I generally don’t have to schedule something out of&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>oncallthrow</strong>: In my experience these models (including opus) aren’t very good at “improving” existing code. I’m not exactly sure why, because the code they produce themselves is generally excellent.</p>
</blockquote>
<blockquote>
<p><strong>sothatsit</strong>: I like these examples that predictably show the weaknesses of current models. This reminds me of that example where someone asked an agent to improve a codebase in a loop overnight and they woke up&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>pugworthy</strong>: To me, this doesn&rsquo;t show the weakness of current models, it shows the variability of prompts and the influence on responses.  Because without the prompt it&rsquo;s hard to tell what influenced the outcome&hellip;.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>sothatsit</strong>: It is definitely a weakness of current models. The fact that people find ways around those weaknesses does not mean the weaknesses do not exist. Your approach is also very similar to spec driven&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>OccamsMirror</strong>: So which approach worked better?</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>enraged_camel</strong>: &raquo; A couple weeks ago I had Opus 4.5 go over my project and improve anything it could find. It &ldquo;worked&rdquo; but the architecture decisions it made were baffling, and had many, many bugs. So you gave it&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>NewsaHackO</strong>: Exactly, imagine if someone gave you a 100k LOC project and said improve anything you can.</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>vbezhenar</strong>: I&rsquo;m using AI tools to find issues in my code. 9/10 of their suggestions are utter nonsense and fixing them would make my code worse. That said, there are real issues they&rsquo;re finding, so it&rsquo;s worth&hellip;</p>
</blockquote>
<blockquote>
<p><strong>rleigh</strong>: I&rsquo;ve found it to be terrible when you allow it to be creative.  Constrain it, and it does much better. Have you tried the planning mode?  Ask it to review the codebase and identify defects, but don&rsquo;t&hellip;</p>
</blockquote>
<p><strong>hollandburke</strong>: Author of the post here. I appreciate the spirited debate and I agree with most of it - on both sides. It&rsquo;s a strange place to be where I think both arguments for and against this case make perfect&hellip;</p>
<blockquote>
<p><strong>thesabreslicer</strong>: I would be really interested to learn more behind the scenes of the iOS app process. Having tried Claude Code to develop an iOS app ~6 months ago, it was pretty painful to get it to make something&hellip;</p>
</blockquote>
<blockquote>
<p><strong>qnleigh</strong>: What do you think about the market for custom apps? Like one app, one customer? You describe future businesses as having one app/service and using AI to add more features, but you did something very&hellip;</p>
</blockquote>
<p><strong>simonw</strong>: Opus 4.5 really is something else. I&rsquo;ve been having a ton of fun throwing absurdly difficult problems at it recently and it keeps on surprising me. A JavaScript interpreter written in Python? How&hellip;</p>
<blockquote>
<p><strong>krackers</strong>: &gt;A JavaScript interpreter written in Python? I&rsquo;m assuming this refers to the python port of Bellard&rsquo;s MQJS [1]? It&rsquo;s impressive and very useful, but leaving out the &ldquo;based on mqjs&rdquo; part is&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>simonw</strong>: That&rsquo;s why I built the WebAssembly one - the JavaScript one started with MQJS, but for the WebAssembly one I started with just a copy of the <a href="https://github.com/webassembly/spec">https://github.com/webassembly/spec</a> repo. I haven&rsquo;t quite&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>dvrp</strong>: Isn’t that telling though?</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>burntsushi</strong>: &gt; How about porting BurntSushi&rsquo;s absurdly great Rust optimized string search routines to C and making them faster? How did it do? :-)</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>simonw</strong>: Alarmingly well! <a href="https://gisthost.github.io/?1bf98596a83ff29b15a2f4790d71c41d">https://gisthost.github.io/?1bf98596a83ff29b15a2f4790d71c41d</a>&hellip; It couldn&rsquo;t quite beat the Rust implementation on everything, but it managed to edge it out on at least some of the&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>burntsushi</strong>: Nice. Yeah I&rsquo;d have to actually look at what it did. For the task of substring search, it&rsquo;s extremely easy to fall into a local optima. The <code>memchr</code> crate has oodles of benchmarks, and some of them&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>aizk</strong>: What are you using to easily share the conversation as its own webpage? Very nice and tidy.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>falloutx</strong>: I have tried to give it extreme problems like creating slime mold pathing algorithm  and creating completely new shoe-lacing patterns and it starts struggling with problems which use visual reasoning&hellip;</p>
</blockquote>
<blockquote>
<p><strong>ronsor</strong>: One of my first tests with it was &ldquo;Write a Python 3 interpreter in JavaScript.&rdquo; It produced tests, then wrote the interpreter, then ran the tests and worked until all of them passed. I was genuinely&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>Calavar</strong>: There are multiple Python 3 interpreters written in JavaScript that were very likely included in the training data. For example [1] [2] [3] I once gave Claude (Opus 3.5) a problem that I thought was&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>wubrr</strong>: It&rsquo;s ability to test/iterate and debug issues is pretty impressive. Though it seems to work best when context is minimized. Once the code passes a certain complexity/size it starts making very silly&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>Loocid</strong>: I&rsquo;m not super surprised that these examples worked well. They are complex and a ton of work, but the problems are relatively well defined with tons of documentation online. Sounds ideal for an LLM no?</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>simonw</strong>: Yes, that&rsquo;s a point I&rsquo;ve been trying to emphasize: if a problem is well specified a coding agent can crunch for hours on it to get to a solution. Even better if there&rsquo;s an existing conformance suite&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>troupo</strong>: On the other hand when I tried it just yesterday, I couldn&rsquo;t really see a difference. As I wrote elsewhere: same crippled context window, same &ldquo;I&rsquo;ll read 10 irrelevant lines from a file&rdquo;, same random&hellip;</p>
</blockquote>
<blockquote>
<p><strong>Krei-se</strong>: Insanely difficult to you maybe because you stopped learning. What you cannot create you don&rsquo;t understand.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>simonw</strong>: Are you honestly saying that building a new spec-compliant WebAssembly runtime from scratch isn&rsquo;t an absurdly difficult project?</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>Krei-se</strong>: i took the time to review your python wasm project and restate the fact that you seem to have 0 idea about how a compiler works. Its simple and rigid rules an AI can pick up easily. If you lack this&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>Herring</strong>: Me and Opus have a lot in common. We both hit our weekly limit on Monday at 10am.</p>
<blockquote>
<p><strong>michaelsalim</strong>: I use pay as you go for this very reason, so the limit is my pocket haha. It does make me conscious to keep it under $20 per month though.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>square_usual</strong>: You&rsquo;re overpaying by a factor of 4, easily. I use <code>ccusage</code>&rsquo;s statusline in claude code, and even with my personal $20/mo subscription I don&rsquo;t think there&rsquo;s been a single month where I didn&rsquo;t touch&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>port3000</strong>: How do you manage that? /ccusage and &ndash;ccusage no longer work for me, I can only see the usage bars in /usage</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>theshrike79</strong>: You can use both btw. Get the $20 plan and turn on &ldquo;extra usage&rdquo; in billing. Then you can use the basic plan first and if it runs out, it uses token-based billing for the overflow.</p>
</blockquote>
</blockquote>
<p><strong>poisonborz</strong>: I see these posts left and right but no one mentions the <em>actual</em> thing developers are hired for, responsibility. You could use whatever tools to aid coding already, even copy paste from&hellip;</p>
<blockquote>
<p><strong>simonw</strong>: That&rsquo;s quickly becoming the most important part of our jobs - we&rsquo;re the ones with agency and the ability to take responsibility for the work we are producing. I&rsquo;m fine with contributed AI-generated&hellip;</p>
</blockquote>
<blockquote>
<p><strong>g-mork</strong>: We still do that, it&rsquo;s just that realtime code review basically becomes the default mode. That&rsquo;s not to say it&rsquo;s not obvious there will not be a lot less of us in future. I vibed about 80% of a SaaS&hellip;</p>
</blockquote>
<blockquote>
<p><strong>kace91</strong>: &gt;the <em>actual</em> thing developers are hired for, responsibility. It is a well known fact that people advance their tech careers by building something new and leaving maintenance to others. Google is&hellip;</p>
</blockquote>
<blockquote>
<p><strong>prisenco</strong>: Which is why I&rsquo;m more comfortable using AI as an editor/reviewer than as a writer. I&rsquo;ll write the code, it can help me explore options, find potential problems and suggest tests, but I&rsquo;ll write the&hellip;</p>
</blockquote>
<p><strong>jedberg</strong>: I had an app I wanted for over a decade.  I even wrote a prototype 10 years ago.  It was fine but wasn&rsquo;t good enough to use, so I didn&rsquo;t use it. This weekend I explained to Claude what I wanted the&hellip;</p>
<blockquote>
<p><strong>gabriel-uribe</strong>: This reminds me of how much screensavers on Mac are a PITA. But yes, such a boon for us doodad makers.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>jedberg</strong>: And dads who just don&rsquo;t have time to make doodads like we used to!</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>firemelt</strong>: what plan do you have on claude?</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>jedberg</strong>: The cheapest one above free.</p>
</blockquote>
</blockquote>
<p><strong>tannedNerd</strong>: The problem with this is none of this is production quality.  You haven’t done edge case testing for user mistakes, a security audit, or even just maintainability. Yes opus 4.5 seems great but most&hellip;</p>
<blockquote>
<p><strong>structural</strong>: Yes, but my junior coworkers also don&rsquo;t reliably do edge case testing for user errors either unless specifically tasked to do so, likely with a checklist of specific kinds of user errors they need to&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>sksishbs</strong>: The best specification is code. English is a very poor approximation. I can’t get past that by the time I write up an adequate spec and review the agents code, I probably could have done it myself by&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ncruces</strong>: How will those juniors ever grow up to be seniors now?</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>throw234234234</strong>: My theory is that this (juniors unable to get in) is generally how industries/jobs die and phase out in a healthy manner that causes the least pain to its workers. I&rsquo;ve seen this happen to a number&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>LinXitoW</strong>: Even better. Job security for current seniors.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>pseudosavant</strong>: Isn&rsquo;t it though? I&rsquo;ve worked with plenty of devs who shipped much lower quality code into production than I see Claude 4.5 or GPT 5.2 write. I find that SOTA models are more likely to: write tests,&hellip;</p>
</blockquote>
<blockquote>
<p><strong>jonas21</strong>: I can generally get  maintainable results simply by telling Claude &ldquo;Please keep the code as simple as possible. I plan on extending this later so readability is critical.&rdquo;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>tannedNerd</strong>: Yeah some of it is probably related to me primarily using it for swift ui which doesn’t have years of stuff to scrape. But even with those and even telling that ios26 exists it will still at least&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>maherbeg</strong>: That may be true now, but think about how far we&rsquo;ve come in a year alone! This is really impressive, and even if the models don&rsquo;t improve, someone will build skills to attack these specific&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>afavour</strong>: There&rsquo;s a fallacy in here that is often repeated. We&rsquo;ve made it from 0 to 5, so we&rsquo;ll be at 10 any day now! But in reality there are any number of roadblocks that might mean progress halts at 7 for&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>christophilus</strong>: Even if progress halts here at 5, I think the programming profession is forever changed. That’s not hyperbole. Claude Code— if it doesn’t improve at all— has changed how I approach my job. I don’t&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>usefulposter</strong>: This comment addresses none of the concerns raised. It writes off entire fields of research (accessibility, UX, application security) as Just train the models more bro. Accelerate.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>maherbeg</strong>: Both accessibility, and application security are easier to build rules + improved models for because they have pretty solid constraints and outcomes. UX on the other hand is definitely more&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>bgirard</strong>: It&rsquo;s not from a few prompts, you&rsquo;re right. But if you layer on some follow-up prompts to add proper test suits, run some QA, etc&hellip; then the quality gets better. I predict in 2026 we&rsquo;re going to see&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>zamalek</strong>: I think someone around here said: LLMs are good at increasing entropy, experienced developers become good at reducing it. Those follow up prompts sounded additive, which is exactly where the problem&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>cyberpunk</strong>: You should try it with BEAM languages and the &rsquo;let it crash&rsquo; style of programming. With pattern matching and process isolated per request you basically only need to code the happy path, and if&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>layer8</strong>: Crashing is the good case. What people worry about is tacit data corruption, or other silently incorrect logic, in cases you didn’t explicitly test for.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>vbezhenar</strong>: You don&rsquo;t need BEAM languages. I&rsquo;m using Java and I always write my code in &ldquo;let it crash&rdquo; style, to spend time on happy paths and avoid spending time on error handling. I think that&rsquo;s the only sane&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>kid64</strong>: Depends on the audience</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>LatencyKills</strong>: Agree&hellip; but that is exactly what MVPs are. Humans have been shipping MVPs while calling them production-ready for decades.</p>
</blockquote>
<blockquote>
<p><strong>adriand</strong>: &gt; Its answer will be 10x harder to maintain and debug Maintain and debug by who? It&rsquo;s just going to be Opus 4.5 (and 4.6&hellip;and 5&hellip;etc.) that are maintaining and debugging it. And I don&rsquo;t think it&hellip;</p>
</blockquote>
<blockquote>
<p><strong>aschobel</strong>: there is are skills / subagents for that something like code-simplifier is surprisingly useful (as is /review) <a href="https://x.com/bcherny/status/2007179850139000872">https://x.com/bcherny/status/2007179850139000872</a></p>
</blockquote>
<blockquote>
<p><strong>joelthelion</strong>: Depends on the application. In many cases it&rsquo;s good enough.</p>
</blockquote>
<blockquote>
<p><strong>mikert89</strong>: Its so much easier to create production quality software</p>
</blockquote>
<p><strong>maciejzj</strong>: I&rsquo;ve been on a small adventure of posting more actively on HN since the release of Gemini 3, trying to stir debate around the more “societal” aspects of what&rsquo;s going on with AI. Regardless of how&hellip;</p>
<blockquote>
<p><strong>hollowturtle</strong>: I don&rsquo;t buy the huge impact, should already have happened and didn&rsquo;t actually happened by now. The day I&rsquo;ll see all these ai hypers producing products that will replace current gen/old gen products&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>mmkos</strong>: I see societal changes like container ships turning. Society has a massive cultural momentum so of course not much has changed today, but we&rsquo;ll have seen big changes years from now. The tools are&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>pmg101</strong>: The problem is that this is unfalsifiable. I could equally say that any recent events has caused a chain of events leading to anything I dream up &hellip; But we won&rsquo;t see the effects yet. It&rsquo;s a nonsense&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>smetj</strong>: it is happening, just not everywhere at the same time at once</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>hollowturtle</strong>: Where are the products then? Otherwise it&rsquo;s just marketing</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>cheschire</strong>: I’ve been thinking, what if all this robotics work doesn’t result in AI automating the real world, but instead results in third world slavery without the first world wages or immigration concerns&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>dbspin</strong>: This is exactly what Meredith Whittaker is saying&hellip; The &rsquo;edge conditions&rsquo; outside the training data will never go away, and &lsquo;AGI&rsquo; will for the foreseeable future simply mean millions in servitude&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>joncrocks</strong>: This was/is the plot to a movie - <a href="https://en.wikipedia.org/wiki/Sleep_Dealer">https://en.wikipedia.org/wiki/Sleep_Dealer</a></p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>emsign</strong>: AI won&rsquo;t work for us, it will tell us what to do and not to do. It doesn&rsquo;t really matter to me if it&rsquo;s an AGI or rather many AGIs or if it&rsquo;s our current clinically insane billionaires controlling our&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>keybored</strong>: It’s a class war where one side is publicly, openly, without reservation stating their intent to make people’s skillset built up through decades unemployable (those exact skillsets; may get some&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>maciejzj</strong>: I agree with you (and surprisingly so does Warren Buffet [1] if anyone doubts it). To add insult to the injury, I believe that people have lost some sense of basic self preservation instinct. Well&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>weatherlite</strong>: UBI (from taxing big tech) and retraining. In the U.S they&rsquo;ll have enough money to do this and it will still suck and many people won&rsquo;t recover the extreme loss of status and income (after we&rsquo;ve been&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>noisy_boy</strong>: Also, time to tax for AI use. Introduce AI usage disclosures for corporations. If a company&rsquo;s AI usage is X, they should pay Y tax because that effectively means they didn&rsquo;t employ Z people instead&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>randunel</strong>: I live in a country which does something similar with (legally) disabled employees. All companies with more than 30 employees must have at least 1 employee who is legally disabled (certificate of&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>weatherlite</strong>: You&rsquo;re right. But you know what they&rsquo;ll do - they&rsquo;ll offshore those &ldquo;jobs&rdquo; e.g token usage to countries that are A.I friendly or that can be bribed easily and do whatever they have to do to fight it&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>dbspin</strong>: Retraining to what exactly? The middle class is being hollowed out globally - so reduced demand for the service economy. If we get effective humanoid robots (seems inevitable) and reliable AI&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>neutronicus</strong>: Health care, elder care, child care are all chronically short of willing, able bodies. Most people want to do anything but these three things - society is in many a ways a competition for who gets to&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>weatherlite</strong>: &gt; If we get effective humanoid robots That&rsquo;s still an if and also a when; could be 2 decades from now or more till this reliably replaces a nurse. &gt; Retraining to what exactly? I wish I had a good&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>sensanaty</strong>: At a certain point people will break, and these sociopathic C-suites will be the first ones on the chopping block. Of course, that&rsquo;s why the biggest degenerates like Zucc are all off building&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>imiric</strong>: &gt; UBI (from taxing big tech) If you think those in power will pass regulations that make them less wealthy, I have a bridge to sell you. Besides, there&rsquo;s no chance something like UBI will ever be a&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>narrator</strong>: The tokens cost the same in Bangalore as they do in San Francisco. The robots will be able to make stuff in San Francisco just as well as they do in Bangalore.  The only thing that will matters is&hellip;</p>
</blockquote>
<blockquote>
<p><strong>epolanski</strong>: I don&rsquo;t know, I&rsquo;m a software engineer and I couldn&rsquo;t care less. It will have impact on me in the long run, sure, it will transform my job, sure, but I&rsquo;m confident my skills are engineering-related,&hellip;</p>
</blockquote>
<p><strong>ChrisbyMe</strong>: Mm this is my experience as well, but I&rsquo;m not particularly worried about software engineering a whole. If anything this example shows that these cli tools give regular devs much higher leverage&hellip;.</p>
<blockquote>
<p><strong>adriand</strong>: &gt; If anything this example shows that these cli tools give regular devs much higher leverage. This is also my take. When the printing press came out, I bet there were scribes who thought, &ldquo;holy shit,&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>edg5000</strong>: The mechanization and scaling up of farming caused a tectonic shift from rural residents moving to cities to take on factory jobs as well as office and retail jobs. We saw this in China until very&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>falkensmaize</strong>: What diminishes your value is that suddenly everybody can (in theory anyway) do this work. There’s a push at my company to start letting designers do their own llm-assisted merge requests to front&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>fragmede</strong>: There was a previous edit that made reference to the water usage of AI datacenter that I&rsquo;m responding to. If AI datacenters&rsquo; hungry need for energy gets us to nuclear power, which gets us the energy&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>names_are_hard</strong>: &gt; When the printing press came out, I bet there were scribes who thought, &ldquo;holy shit, there goes my job!&rdquo; But I bet there were other scribes who thought, &ldquo;holy shit, I don&rsquo;t have to do this by hand&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>techblueberry</strong>: The question I&rsquo;ve been wondering is.. I think for a while people have been talking about the fact that as all development tools have gotten better - the idea that a developer is a person who turns&hellip;</p>
</blockquote>
<blockquote>
<p><strong>elzbardico</strong>: In my experience, unless the US guy came from Stanford or some other similar place, there are plenty of mediocre US guys in software development.</p>
</blockquote>
<p><strong>soulofmischief</strong>: Opus 4.5 is currently helping me write a novel, comprehensive and highly performant programming language with all of the things I&rsquo;ve ever wanted, done in exactly my opinionated way. This project&hellip;</p>
<blockquote>
<p><strong>Madmallard</strong>: Unfortunately what likely will happen is that you miss tons of edge cases and certain implementations within the confines of your language will be basically impossible or horribly inefficient or&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>soulofmischief</strong>: That&rsquo;s not how this works. Assume less about my level of expertise. By the end of a session, I understand the internals of what I&rsquo;m implementing. What is shortened is the search space and&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>Madmallard</strong>: Are you making a DSL then? That would make more sense.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>jolt42</strong>: Long-term maybe we won&rsquo;t care about code because AI will just maintain it itself. Before that day comes, don&rsquo;t you want a coding language that isn&rsquo;t opinionated, but rather able to describe the&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>soulofmischief</strong>: You&rsquo;re reading too much into what I mean by &ldquo;opinionated&rdquo;. I have very specific requirements and constraints that come from knowledge and experience, having worked with dozens of languages. The&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>lawlessone</strong>: Why would anyone buy the novel?</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>welpo</strong>: I misread too. &ldquo;novel&rdquo; is being used as an adjective, not a noun. They are saying they are writing &ldquo;a novel […] programming language&rdquo;, not a novel.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>renecito</strong>: I&rsquo;d guess some people likes to read ¯_(ツ)_/¯</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>lawlessone</strong>: i know, there an inexhaustible amount of human written books to read before i&rsquo;d be desperate enough to read the Markov chain books.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>flanked-evergl</strong>: Helping you do something that nobody should be doing is not really compelling.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>soulofmischief</strong>: Did you have a specific criticism?</p>
</blockquote>
</blockquote>
<p><strong>kachapopopow</strong>: It&rsquo;s also the feeling I have, opus is not a ground-breaking model by any means. However, Opus 4.5 is incredible when you give it everything it needs, a direction, what you have versus what you want&hellip;</p>
<blockquote>
<p><strong>manmal</strong>: Off/nearshoring regularly produces worse code. I’ve seen it first hand.</p>
</blockquote>
<blockquote>
<p><strong>edg5000</strong>: Opus can produce beatiful code. It can outcode a good programmer. But getting it to do this reliably is something I&rsquo;ve gotten better at over the last year; it&rsquo;s a skill that took quite a bit of&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>kachapopopow</strong>: there is a big difference between a good programmer and a programmer that gives a shit so I disagree, opus can not come close to the code quality that someone can create and at that point it is the&hellip;</p>
</blockquote>
</blockquote>
<p><strong>losvedir</strong>: I&rsquo;m kind of surprised how many people are okay with deploying code that hasn&rsquo;t been audited. I read If Anyone Builds It Everyone Dies over the break. The basic premise was that we can&rsquo;t &ldquo;align&rdquo; AI so&hellip;</p>
<blockquote>
<p><strong>btown</strong>: Perhaps our only saving grace is that many LLMs at varying levels of &ldquo;dumbness&rdquo; exist. Is it possible to create an obfuscated quine that exhibits stable detection-avoiding behavior on every frontier&hellip;</p>
</blockquote>
<blockquote>
<p><strong>codyb</strong>: There&rsquo;s a really interesting story I read somewhere about some application which used neural nets to optimize for a goal (this was a while ago, it could have been merkel trees or something, who&hellip;</p>
</blockquote>
<blockquote>
<p><strong>TacticalCoder</strong>: Why think about nefarious intent instead of just user error? In this case LLM error instead of programmer error. Most RCEs, 0-days, and whatnots are not due to the NSA hiding behind the &ldquo;Jia Tan&rdquo;&hellip;</p>
</blockquote>
<p><strong>haolez</strong>: I have a different concern: the SOTA products are expensive and get dumbed down on busy times. My personal strategy has been to be a late follower, where I adopt new AI tools when the competition has&hellip;</p>
<blockquote>
<p><strong>becquerel</strong>: If you haven&rsquo;t tried it yet, OpenCode is quite good.</p>
</blockquote>
<p><strong>LatencyKills</strong>: I really wonder what means for software moving forward. In the last few months I&rsquo;ve used Claude Code to build personalized versions of Superwhisper (voice-to-text), CleanShot X (screenshot and image&hellip;</p>
<blockquote>
<p><strong>adriand</strong>: &gt; I really wonder what means for software moving forward. It means that it is going to be as easy to create software as it is to create a post on TikTok, and making your software commercially&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>manmal</strong>: Is that new though? Software has been hype and marketing driven forever.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>jetsetk</strong>: So nothing changed</p>
</blockquote>
</blockquote>
<p><strong>ben-gy</strong>: I second this article - I built twelve iOS/Mac apps in two weeks with Opus 4.5 - four of them are already in the App Store - I’m a Rails Engineer and never had the time to learn Swift but man does&hellip;</p>
<blockquote>
<p><strong>noworriesnate</strong>: Are there a lot of manual steps in managing an xcode project? E.g. does it say &ldquo;now go into xcode and change this setting&rdquo; instead of changing the setting directly? Or are you using a tool like&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ben-gy</strong>: Very few - the only manual things I do are;  - clicking the distribute button to push the bundle to the App Store  - filling in the compliance survey and App Store listing content  - linking some&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>bookmark99</strong>: Can you please share the links to these apps in the app store?</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ben-gy</strong>: <a href="https://apps.apple.com/au/app/events-canberra/id6756598656">https://apps.apple.com/au/app/events-canberra/id6756598656</a> - you can access the other ones by clicking the developer name in the listing</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>thesabreslicer</strong>: how did you use Opus to build the apps? I tried using Claude Code ~6 months ago to build an iOS app and I was not that impressed with the results, especially compared to this blog post, where the&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ben-gy</strong>: Opus 4.5 got released ~3 months ago - Claude Code started using it automatically (for me anyway) - I also tried iOS prior to that and had a similar experience to you</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>firemelt</strong>: what claude plan are u on?</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ben-gy</strong>: Max</p>
</blockquote>
</blockquote>
<p><strong>dzonga</strong>: what strikes me about these posts is they praise models for apps | utilities commonly found on GitHub. ie well known paths based on training data. what&rsquo;s never posted is someone building something&hellip;</p>
<blockquote>
<p><strong>nirolo</strong>: I used it with gemini 3 in tandem to build an app to simulate thermal bridges because I want to insulate a house. I explored this in various directions and there are some functionalities not&hellip;</p>
</blockquote>
<p><strong>qnleigh</strong>: So much of the conversation is around these models replacing software engineers. But the use cases described in the article sound like pretty compelling business opportunities; if the custom apps he&hellip;</p>
<blockquote>
<p><strong>raesene9</strong>: One problem with the idea of making businesses out of this kind of application is actually mentioned in passing in the article &ldquo;I decided to make up for my dereliction of duties by building her&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>ensocode</strong>: so everybody is making their own apps for their specific problem? Sounds as it will get a mess in the end. So maybe it will be more about ideas and concepts and not so much about know how to code.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>raesene9</strong>: Yep vast numbers of personalized apps seems like it would end up being pretty messy. I think the challenge of betting on ideas and concepts is that once you&rsquo;ve published something, someone else can&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>qnleigh</strong>: I think you&rsquo;re misunderstanding my point. If you can crank out a custom app this quickly, you don&rsquo;t make a commercial app and then try to sell it on an app store. Customers pay you to make apps for&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>raesene9</strong>: Why do they pay you though, why not just do it themselves? With improving models and surrounding tooling the barrier to creating apps is lowered, and it&rsquo;s easier for a user just to create their own&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>socalgal2</strong>: A coworker who’s never coded has made 25 small work automation/helper apps using ai vibe coding. She doesn’t need to hire anyone</p>
</blockquote>
<p><strong>artdigital</strong>: I switched my subscription from Claude to ChatGPT around 5.0 when SOTA was Sonnet 4.5 and found GPT-5-high (and now 5.2-high) so incredibly good, I could never imagine Opus is on its level. I give&hellip;</p>
<p><strong>Workaccount2</strong>: Anthropic dropped out of the general &ldquo;AGI&rdquo; race and seems to be purely focused on coding, maybe racing to get the first &ldquo;automated machine learning programmer&rdquo;. Whatever the case, it seems to be&hellip;</p>
<blockquote>
<p><strong>ethbr1</strong>: The benefit of focusing on coding is that it has an attractive non-deterministic / deterministic problem split. In that it&rsquo;s using a non-deterministic machine to build a deterministic one. Which&hellip;</p>
</blockquote>
<p><strong>fractallyte</strong>: That final line: &ldquo;Disclaimer: This post was written by a human and edited for spelling, grammer by Haiku 4.5&rdquo; Yeah, GRAMMAR For all the wonderment of the article, tripping up on a penultimate word&hellip;</p>
<blockquote>
<p><strong>simonw</strong>: Presumably that disclaimer was added manually after Haiku had run the checks.</p>
</blockquote>
<p><strong>fullstackchris</strong>: &gt; I don’t know if I feel exhilarated by what I can now build in a matter of hours, or depressed because the thing I’ve spent my life learning to do is now trivial for a computer. Both are true. I&rsquo;m&hellip;</p>
<p><strong>mpalmer</strong>: After reading that article, I see at least one thing that Opus 4.5 is clearly not going to change. There is no fixed truth regarding what an &ldquo;app&rdquo; is, does, or looks like. Let alone the device it&hellip;</p>
<blockquote>
<p><strong>NewsaHackO</strong>: &gt;the code will continue to be boring. Why would you not want you code to be boring?</p>
</blockquote>
<p><strong>bennydog224</strong>: Don&rsquo;t want to discredit Opus at all, it&rsquo;s easy at directed tasks but it&rsquo;s not the silver bullet yet. It is best in its class, but trips up frequently with complicated engineering tasks involving&hellip;</p>
<p><strong>mattfrommars</strong>: I’ve been saying this a countless time, LLM are great to build toy and experimental projects. I’m not shaming but I personally need to know if my sentiment is correct or not or I just don’t know how&hellip;</p>
<blockquote>
<p><strong>simonw</strong>: Your bar for being impressed by coding agents is &ldquo;can build a novel operating system that competes with Linux on a plan that costs a $20/month&rdquo;? Yeah, they can&rsquo;t do that.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>hollowturtle</strong>: In fact, like the author of the comment said, can just generated toys and experimental projects. I&rsquo;m all in for experiments and exploring ideas, but I have yet to see a great product all vibe coded&hellip;.</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>hu3</strong>: No human would pass that bar. Yet you expect $20 of computing to do it.</p>
</blockquote>
<blockquote>
<p><strong>ben_w</strong>: &gt; Can vibe coder gurus create operating system from scratch that competes with Linux and make it generate code that basically isn’t Linux since LLM are trained on said the source code … No&hellip;.</p>
</blockquote>
<blockquote>
<p><strong>fragmede</strong>: Consider your own emotions and the bias you have against it. If it is actually able to do the things it is hyped up to be, what does that mean for you, your job, and your career? Can you really&hellip;</p>
</blockquote>
<p><strong>headcanon</strong>: Yep, I literally built this last night with Opus 4.5 after my wife and I challenged each other to a typing competition. I gave it direction and feedback but it wrote all the actual code. Wasn&rsquo;t a one&hellip;</p>
<p><strong>oncallthrow</strong>: Yeah Opus 4.5 is a massive step change in my experience. I feel like I’m working with a peer, not a junior I’m having to direct. I can give it highly ambiguous and poorly specified tasks and it… just&hellip;</p>
<blockquote>
<p><strong>christophilus</strong>: It’s excellent at typescript in my experience. It’s also way better than I am at finding bits of code for reuse. I tell it, “I think I wrote this thing a while back, but it may never have been&hellip;</p>
</blockquote>
<blockquote>
<p><strong>Krei-se</strong>: If its a peer to you now the Ai has evolved while you didn&rsquo;t</p>
</blockquote>
<blockquote>
<p><strong>llmslave2</strong>: &gt; I feel like I’m working with a peer, not a junior I’m having to direct. I think this says a lot.</p>
</blockquote>
<p><strong>mr_o47</strong>: Reading this blog post makes me wanna rethink my career,  Opus 4.5 is really good I was recently working on solving my own problem by developing a software solution and let me tell you it was really&hellip;</p>
<p><strong>PaulHoule</strong>: I&rsquo;ll argue many of his cases are things that are straightforward except for the boilerplate that surrounds them which are often emotionally difficult or prone to rabbit holes. Like that first one&hellip;</p>
<p><strong>nphardon</strong>: Sonnet 4.5 did it for me.  Cant imagine coding without it now, and if you look at my comments from three months ago, you&rsquo;ll see I&rsquo;m eating crow now.  I easily hit &gt;10x productivity with Sonnet 4.5&hellip;</p>
<p><strong>raldi</strong>: Despite the abuse of quotation marks in the screenshot at the top of this link, Dario Amodei did not in fact say those words or any other words with the same meaning.</p>
<blockquote>
<p><strong>versteegen</strong>: Yes, unfortunate that people keep perpetuating that misquote. What he actually said was &ldquo;we are not far from the world—I think we’ll be there in three to six months—where AI is writing 90 percent of&hellip;</p>
</blockquote>
<p><strong>delduca</strong>: I agree, it wrote an entire NES emulator for me. <a href="https://news.ycombinator.com/item?id=46443767">https://news.ycombinator.com/item?id=46443767</a></p>
<blockquote>
<p><strong>lawlessone</strong>: It cloned one of the many open source ones available is what you mean.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>manmal</strong>: As long as you give it deterministic goals / test criteria (compiles, lints, tests, E2E tests, achieve 100% parity with existing solution etc) it will brute force its way to a solution. Codex will&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>xyzzy_plugh</strong>: No, it might figure out the solution but even after many days there&rsquo;s no assurance that it won&rsquo;t get stuck making the same mistakes over and over again, never getting closer to a solution. I&rsquo;ve seen&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>jama211</strong>: To be fair that’s what I’d have done had I had to build it. Use a lot of examples etc and build on what other people have done</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>koiueo</strong>: I assume, the purpose would be to learn how it&rsquo;s done.  There&rsquo;s no place for this when you vibecode. And if not learning, what&rsquo;s the point of implementing something that already exists? When I&rsquo;m&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>falloutx</strong>: Now ask it to create a NES game</p>
</blockquote>
<p><strong>smusamashah</strong>: What about Sonnet 4.5? I used both Opus and Sonnet on Claude.ai and found sonnet much better at following instructions and doing exactly what was asked. (it was for single html/js PWA to measure and&hellip;</p>
<p><strong>lagniappe</strong>: Title is: &ldquo;Opus 4.5 is going to change everything&rdquo;</p>
<blockquote>
<p><strong>minimaxir</strong>: A Hacker News moderator likely changed the title because it&rsquo;s uninformatively vague.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>lagniappe</strong>: Rules are rules, and excuses are excuses.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>minimaxir</strong>: Hacker News mods rewriting titles has been a standard since before I joined HN in 2012.</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>takinola</strong>: I guess the best analogy I can think of is the transition from writing assembly language and the introduction of compilers.  Now, (almost) no one knows, or cares, what comes out of the compiler.  We&hellip;</p>
<blockquote>
<p><strong>dpacmittal</strong>: A compiler is deterministic though.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>becquerel</strong>: Does a system being deterministic really matter if it&rsquo;s complex enough you can&rsquo;t predict it? How many stories are there about &lsquo;you need to do it in this specific way, and not this other specific way,&hellip;</p>
</blockquote>
</blockquote>
<p><strong>throw10920</strong>: Does anyone have a boring, multi-hour-long coding session with an agent that they&rsquo;ve recorded and put on Vimeo or something? As many other commentators have said, individual results vary extremely&hellip;</p>
<blockquote>
<p><strong>neochief</strong>: I tried to make several, but they all end up prematurely when the agent hits a wall in an hour or so, unless you make trivial shit.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>throw10920</strong>: That sounds like genuinely useful data, though! Please reply if you end up posting them!</p>
</blockquote>
</blockquote>
<p><strong>avidphantasm</strong>: Cool. Please check back in with us after they’ve raised the price 50x and you can no longer build anything because you are alienated from your tools.</p>
<blockquote>
<p><strong>atonse</strong>: I’ve said many times, I’d still pay even $1,000 a month for CC. But I’m a business owner so the calculus is different. But I don’t think they’ll raise prices uncontrollably because competition&hellip;</p>
</blockquote>
<p><strong>ycombiredd</strong>: I can&rsquo;t quite figure out what sort of irony the blurb at the bottom of the post is. (I&rsquo;m unsure if it was intentional snark, a human typo, or an inadvertent demonstration of Haiku not being well&hellip;</p>
<blockquote>
<p><strong>hu3</strong>: The most plausible explanation is that the only typo in that post was made by a human.</p>
</blockquote>
<p><strong>egorfine</strong>: So I decided to try the revered hands-off approach and have Claude Code create me a small tool in JS for *.dylib bundle consolidation on macOS. I have used AskUserQuestionTool to complete my initial&hellip;</p>
<blockquote>
<p><strong>stocksinsmocks</strong>: That’s the opposite of my experience. Weird. But I’m also not the kind of person who gets hung up on whether someone used a loop or recursion or if their methods are five times as long as what I&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>egorfine</strong>: Yes, this experience is unlike most people. Perhaps the problem is that most people are satisfied by the appearance of a working app despite it not working at all. Say, the first tool I was doing,&hellip;</p>
</blockquote>
</blockquote>
<p><strong>jcmfernandes</strong>: To the author: you wrote those apps. Not like you used to, but you wrote them. IMO, our jobs are safe. It&rsquo;s our ways of working that are changing. Rapidly.</p>
<blockquote>
<p><strong>Hammershaft</strong>: SWE jobs are in fact, not safe, if vaguely defined specifications can be translated into functioning applications. I don&rsquo;t think agents are good enough to do that in larger applications yet, but it&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>jcmfernandes</strong>: Depends on the software. IMO, development speed will increase, but humans will continue to be the limiting factor, so we are safe. Our jobs, however, are changing and will continue to.</p>
</blockquote>
</blockquote>
<p><strong>funnyfoobar</strong>: I was not expecting a couple of new apps being built, when the premise of the blog post talks about replacing &ldquo;mid level engineers&rdquo; the thing about being an engineer at commercial capacity is&hellip;</p>
<p><strong>MarsIronPI</strong>: It worries me that the best models, the ones that can one-shot apps and such, are all non-free and owned by companies who can&rsquo;t be trusted to have end-users&rsquo; best interests at heart.  It would be&hellip;</p>
<p><strong>shnpln</strong>: I have used Claude Code for a variety of hobby projects. I am truly astounded at its capabilities. If you tell it to use linters and other kinds of code analysis tools it takes it to the next level&hellip;.</p>
<p><strong>emsign</strong>: The worst part about this is that you can&rsquo;t know anymore whether the software you trustingly install on your hardware is clean or if it was coded by a misaligned coding model with a secret goal that&hellip;</p>
<blockquote>
<p><strong>neocron</strong>: I have to many machines standing around that are currently not powered on or are running somewhat airgapped with old software from around debian 8 and 9, so I guess they will be a safe haven once the&hellip;</p>
</blockquote>
<p><strong>oldnewthing</strong>: Claude Code is very good; good enough that I upgraded to the Max plan this week. However, it has a long way to go. It&rsquo;s great at one-shotting (with iterations) most ideas. However, it doesn&rsquo;t do as&hellip;</p>
<p><strong>daxfohl</strong>: This resonates with my experience in codex 5.2, at least directionally. I&rsquo;m pretty persnickety about code itself, so I&rsquo;m not to the point where I&rsquo;ll just let it rip. But in the last month or two&hellip;</p>
<p><strong>mcpar-land</strong>: It is very funny to start your article off with a bunch of breathless headlines about agents replacing human coders by the end of 2025, none of which happened, then the rest of the article is &ldquo;okay&hellip;</p>
<p><strong>Kon5ole</strong>: I agree with the OP that I can get LLM&rsquo;s to do things now that I wouldn&rsquo;t even attempt a year ago, but I feel it has more to do with my own experience using LLM&rsquo;s (and the surrounding tools) than the&hellip;</p>
<p><strong>evolve2k</strong>: &gt; Why does a human need to read this code at all? I use a custom agent in VS Code that tells Opus to write code for LLMs, not humans. Think about it—why optimize for human readability when the AI is&hellip;</p>
<p><strong>noisy_boy</strong>: All great until the code in production pushed by Opus 314.15 breaks and Opus 602.21, despite it&rsquo;s many tries, can&rsquo;t fix it and ends it with &ldquo;I apologize&rdquo;. That&rsquo;s when you need a  developer who can be&hellip;</p>
<p><strong>brushfoot</strong>: I pivoted into integrations in 2022. My day-to-day now is mostly in learning the undocumented quirks of other systems. I turn those into requirements, which I feed to the model du jour via GitHub&hellip;</p>
<p><strong>prokopton</strong>: I asked Claude’s opinion and it disagreed. :) Claude’s response: The article’s central tension is real - Burke went from skeptic to believer by building four increasingly complex apps in rapid&hellip;</p>
<p><strong>vl</strong>: Honestly, I don’t understand universal praise for Opus 4.5. It’s good, but really not better than other agents. Just today: Opus 4.5 Extended Thinking designed psql schema for “stream updates after&hellip;</p>
<blockquote>
<p><strong>giancarlostoro</strong>: Are you using Claude Code? Because that might be the secret cause you&rsquo;re missing. With Claude Code I can instruct it to validate things after its done with code, and usually it finds that it goofed&hellip;.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>vl</strong>: For schema design phase I used web UI for all three. Logical bug of using BIGSERIAL for tracking updates (generated at insert time, not commit time, so can be out of order) wouldn’t be caught by any&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>simonw</strong>: At this point having any LLM write code without giving it an environment that allows it to execute that code itself is like rolling a heavily-biased random number generator and hoping you get a&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>kace91</strong>: &gt;Disclaimer: This post was written by a human and edited for spelling, grammer by Haiku 4.5 Either it wasn’t that good, or the author failed in the one phrase they didn’t proofread. (No judgement&hellip;</p>
<p><strong>yardie</strong>: These are very simple utilities. I expect AI to be able to build them easily. Maybe in a few years it will be able to write a complete photo editor or CAD application from first principles.</p>
<blockquote>
<p><strong>fragmede</strong>: Then we&rsquo;re really screwed!</p>
</blockquote>
<p><strong>theappsecguy</strong>: It’s incredibly tiring to see this narrative peddled every damn day. I use opus 4.5 every day. It’s not much different than any previous models, still does dumb things all the time.</p>
<blockquote>
<p><strong>gpm</strong>: Same experience - I&rsquo;ve had it fail at the same reasonably simple tasks I had opus 4 and sonnet 4.5 and sonnet 4 fail at when they aren&rsquo;t carefully guided and their work check and fixed&hellip;</p>
</blockquote>
<p><strong>squirrellous</strong>: For some reason Opus 4.5 is blowing up recently after having been released for weeks. I guess because holidays are over? Active agent users should have discovered this for a while.</p>
<p><strong>Staross</strong>: I gave it a try, I asked to do a reddit like forum and it did pretty good but damn I quickly hit the daily limit of the $20 pro account, and it took 10% of the monthly just to do the setup and some&hellip;</p>
<p><strong>manmal</strong>: IMO codex produces working code slowly, while Opus produces superficially working code quickly. I like using Opus to drive codex sessions and checking its output. Clawdbot is really good at that but&hellip;</p>
<blockquote>
<p><strong>NitpickLawyer</strong>: &gt;  I like using Opus to drive codex sessions and checking its output. Why not the other way around? Have the quick brown fox churn out code, and have codex review it, guide changes, and loop? I&rsquo;ve&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>manmal</strong>: I agree, codex is great at reviewing as well. I think that’s because code is the ideal description of what we want to achieve, and codex is good (only) when it knows what must be achieved, as&hellip;</p>
</blockquote>
</blockquote>
<p><strong>minimaxir</strong>: See also: a post from a couple days ago which came to the same conclusion that Opus 4.5 is an inflection point above Sonnet 4.5 despite that conclusion being counterintuitive:&hellip;</p>
<p><strong>thedangler</strong>: I&rsquo;ve only started but I mostly use Claude Code for building out code that has been done a million times. So its good at setting up a project to get all the boiler plate crap out of the way. When you&hellip;</p>
<p><strong>p0w3n3d</strong>: Disclaimer: This post was written by a human and edited for spelling, grammer by Haiku 4.5 I recently am finishing the reading of Mistborn series, so please do not read further unless you want a&hellip;</p>
<p><strong>karmasimida</strong>: As impressive as Opus 4.5 is, it still fails in one situation that it assumes 0-index while the component it supposes to work with assume 1-index. It has access to the said information on disk, but&hellip;</p>
<p><strong>weatherlite</strong>: The main issue in this discussion is the word &ldquo;replace&rdquo; . People will come up with a bunch of examples where humans are still needed in SWE and can&rsquo;t be fully replaced, that is true. I think claiming&hellip;</p>
<p><strong>lifetimerubyist</strong>: Opus helped me optimized a wonky SQL query today from 4s to 5min.  Truly something that only a super intelligence is capable of.</p>
<p><strong>hsn915</strong>: I had a similar feeling expressed in the title regarding ChatGPT 5.2 I haven&rsquo;t tried it for coding. I&rsquo;m just talking about regular chatting. It&rsquo;s doing something different from prior models. It seems&hellip;</p>
<p><strong>Snuggly73</strong>: Ok, if its almighty, then why is not the benchmarks at 100%? If you look at the individual issues, those are somewhat small and trivial changes in existing codebases. <a href="https://swe-rebench.com/">https://swe-rebench.com/</a> (note&hellip;</p>
<p><strong>waynenilsen</strong>: Once you get your setup bulletproof such that you can have multiple agents running at the same time that can run unit tests and close their own loops things get even faster. However you accomplish&hellip;</p>
<blockquote>
<p><strong>koiueo</strong>: Can&rsquo;t you, like, ask Claude to fix port collision for you? Duh</p>
</blockquote>
<blockquote>
<p><strong>manmal</strong>: Just let it test in different containers? That’s not the hard part IMO.</p>
</blockquote>
<p><strong>dudeinhawaii</strong>: LLMS like Opus, Gemini 3, and GPT-5.2/5.1-Codex-max, are phenomenal for coding and have only very recently crossed that gap between being &ldquo;eh&rdquo; and being quite fantastic to let operate on their own&hellip;</p>
<p><strong>jackdoe</strong>: most of software engineering was rational, now it is becoming empirical it is quite strange, you have to make it write the code in a way it can reason about it without it reading it, you also have to&hellip;</p>
<p><strong>Sxubas</strong>: Just an open thought, what if most improvement we are seeing is not mostly due to LLM improvements but to context management and better prompting? Ofc the reality is a mix of both, but really curious&hellip;</p>
<p><strong>SergeAx</strong>: This article is much better than hundred of similar articles &ldquo;AI will change software engineering&rdquo; because it have links to actual products created with said &ldquo;AI&rdquo;. I can&rsquo;t say they are impressive,&hellip;</p>
<p><strong>_se</strong>: It&rsquo;s always fun to ask Opus what it thinks about articles like this. Here&rsquo;s what I got with no history or system prompt: <a href="https://burkeholland.github.io/posts/opus-4-5-change-everyth">https://burkeholland.github.io/posts/opus-4-5-change-everyth</a>&hellip; Read this&hellip;</p>
<blockquote>
<p><strong>stantonius</strong>: There&rsquo;s something eerily recursive about Opus 4.5’s sensible take calming the anxiety about Opus 4.5’s capabilities and impact. It&rsquo;s probably the right take, but I feel weird the most pragmatic&hellip;</p>
</blockquote>
<p><strong>killerstorm</strong>: Weird title. Obviously, early AI agents were clumsy, and we should expect more mature performance in future. Leopold Aschenbrenner was talking about &ldquo;unhobbling&rdquo; as an ongoing process. That&rsquo;s what we&hellip;</p>
<p><strong>orthoxerox</strong>: What&rsquo;s the best coding agent you can run locally? How far behind Opus 4.5 is it?</p>
<blockquote>
<p><strong>Tiberium</strong>: The best is probably something like GLM 4.7/Minimax M2.1, and those are probably at most Sonnet 4 level, which is behind Opus 4.1, which is behind Sonnet 4.5, which is behind Opus 4.5 ;) And honestly&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>orthoxerox</strong>: Does it even fit into a 5090 or a Ryzen 395+?</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>Tiberium</strong>: Oh, of course not, you might need up to 100GB VRAM to have those models at decent speeds even just for low-quant versions. And all the hype about Macs with unified memory is a bit dishonest because&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>jdthedisciple</strong>: To those of you who use it: How much does Claude Code cost you a month on avg? I only use VS Code with Copilot subscription ($10) and already get quite a lot out of it. My experience is that Claude&hellip;</p>
<blockquote>
<p><strong>rleigh</strong>: I started on the cheapest £15/mo &ldquo;Pro&rdquo; plan and it was great for home use when I&rsquo;d do a bit of coding in the evenings only, but it wasn&rsquo;t really that usable with Opus&ndash;you can burn through your&hellip;</p>
</blockquote>
<p><strong>sachahjkl</strong>: Yowza, AIs excel at writing low performance CRUD apps, REVOLUTION INCOMING</p>
<p><strong>nsb1</strong>: A lot of the complaints about these tools seems to revolve around their current lack of ability to innovate for greenfield or overly complex tasks.  I would agree with this assessment in their&hellip;</p>
<blockquote>
<p><strong>thewillowcat</strong>: The vast majority of engineers aren&rsquo;t refusing to use AI until it can do 100% of their job. They are just sick of being told it already can, when their direct experience contradicts that claim.</p>
</blockquote>
<p><strong>alex1138</strong>: Are the LLMs in any way trained semantically or by hooks that you can plug in, say, Python docs? And if a new version of Python then gets released then the training data changes, etc</p>
<p><strong>infinitezest</strong>: The question I keep asking myself is &ldquo;how feasible will any of this be when the VC money runs out?&rdquo;  Right now tokens are crazy cheap.  Will the continue to be?</p>
<blockquote>
<p><strong>user34283</strong>: No, they will get even cheaper.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>infinitezest</strong>: Based on what logic?</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>user34283</strong>: New research and hardware improvements increasing efficiency, strong competition, historic trend.</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>on_the_train</strong>: Oh another run of new small apps. Why not unleash this oh so powerful tools not on a jira ticket written two years ago, targeting 3 different repos in an old legacy moloch, like actual work? It&rsquo;s&hellip;</p>
<blockquote>
<p><strong>asmor</strong>: Did some of that today. Extracting logic from Helm templates that read like 2000s PHP and moving it to a nushell script rendering values. Took a lot of guidance both in terms of making it test its&hellip;</p>
</blockquote>
<p><strong>mrankin</strong>: I think a lot of people are going to be singing a different tune when the hype money runs out and you have to pay the real bill.</p>
<p><strong>scotty79</strong>: &gt; And if it ran into errors, it would try and build using the dotnet CLI, read the errors and iterate until fixed. Antigravity with Gemini 3 pro from Google has the same capability.</p>
<p><strong>arielweisberg</strong>: I agree. Claude Code went from being slower than doing it myself to being on average faster, but also far less exhausting so I can do more things in general while it works.</p>
<p><strong><em>pdp</em></strong>: YEP Things are changing. Now everyone can build bespoke apps. Are these apps pushing the limits of technology? No! But they work for the very narrow and specific domain they where designed. And yes&hellip;</p>
<p><strong>Papazsazsa</strong>: &ldquo;Opus 4.5 feels to me like&rdquo; The article is fine opinion but at what point are we going to either: a) establish benchmarks that make sense and are reliable, or b) stop with the hypecycle stuff?</p>
<blockquote>
<p><strong>NewsaHackO</strong>: &gt;establish benchmarks that make sense and are reliable How aren&rsquo;t current LLM coding benchmarks reliable?</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>Papazsazsa</strong>: They&rsquo;re manipulated.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>NewsaHackO</strong>: Unless you are going to be more specific, that criticism applies to all benchmarks that are connected to a positive gain, not just AI coding benchmarks.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>cardine</strong>: &gt; make sense and are reliable If you can figure out how to create benchmarks that make sense, are reliable, correlate strongly to business goals, and don&rsquo;t get immediately saturated or contorted once&hellip;</p>
</blockquote>
<p><strong>adithyassekhar</strong>: I like writing code</p>
<p><strong>ironbound</strong>: This is great   can&rsquo;t wait for the future when our VC ideas can become unicorns, without CEO&rsquo;s &amp; Founders..</p>
<p><strong>elendee</strong>: the author asks one interesting question and then glides right by it. If the agents only need their own code, what should that code look like?  If all their learning has come from old human code, how&hellip;</p>
<p><strong>chris_st</strong>: I&rsquo;ve found asking GPT-5.2 High to review Opus 4.5&rsquo;s code to be really productive. They find different things.</p>
<p><strong>Fischgericht</strong>: People should finally understand that LLMs are a lossy database of PAST knowledge. Yes, if you throw a task at it that has been done tons of times before, it works. Which is not a surprise, because&hellip;</p>
<blockquote>
<p><strong>fl7305</strong>: &gt; What LLMs will NOT do however, is write or invent SOMETHING KNEW. Counterpoint: ChatGPT came up with the new expression &ldquo;The confetti has left the cannon&rdquo; a few years ago. So, your claim is not&hellip;</p>
</blockquote>
<p><strong>thallukrish</strong>: When complexity increases, you end up handholding them in pieces.</p>
<p><strong>jcadam</strong>: Yea, my issue with Opus 4.5 is it&rsquo;s the first model that&rsquo;s good enough that I&rsquo;m starting to feel myself slip into laziness.  I catch myself reviewing its output less rigorously than I had with&hellip;</p>
<p><strong>dmarwicke</strong>: this is just optimizing for token windows. flat code = less context. we did the same thing with java when memory was expensive, called it &ldquo;lightweight frameworks&rdquo;</p>
<p><strong>exabrial</strong>: What is with all the Claude spam lately on hn?</p>
<p><strong>DustinBrett</strong>: Post the code open source and run it on prod.</p>
<p><strong>ggregoire</strong>: I&rsquo;m always surprised to never see any comments in those discussions from people who just like coding, learning, solving problems… I mean, it&rsquo;s amazing that LLMs can build an image converter or&hellip;</p>
<blockquote>
<p><strong>hu3</strong>: After decade(s) working with either enterprise crud or web agency fancy websites, the novelty wears off. It&rsquo;s just boring and I&rsquo;m glad to delegate most of the repetitive work. But sure, if I&rsquo;m doing&hellip;</p>
</blockquote>
<p><strong>vladsh</strong>: It’s a bit strange how anecdotes have become acceptable fuel for 1000 comment technical debates. I’ve always liked the quote that sufficiently advanced tech looks like magic, but its mistake to&hellip;</p>
<blockquote>
<p><strong>scosman</strong>: &gt; It’s a bit strange how anecdotes have become acceptable fuel for 1000 comment technical debates. Progress is so fast right now anecdotes are sometimes more interesting than proper benchmarks. &ldquo;Wow&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>elfly</strong>: At this point I believe the anecdotes more than benchmarks, cause I know the LLM devs train the damn things on the benchmarks. A benchmark? probably was gamed. A guy made an app to right click and&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>flumpcakes</strong>: &gt; It’s a bit strange how anecdotes have become acceptable fuel for 1000 comment technical debates. It&rsquo;s a very subjective topic. Some people claim it increases their productivity 100x. Some think it&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>weitendorf</strong>: How many 1+ hour videos of someone building with AI tools have you sought out and watched? Those definitely exist, it sounds like you didn&rsquo;t go seeking them out or watch them because even with 7 less&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>forgotaccount3</strong>: &gt; In my opinion most of the people who refuse to believe AI can help them while work with software are just incurious/archetypical late adopters. The biggest blocker I see to having AI help us be&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>mossTechnician</strong>: It could be really beneficial for Anthropic to showcase how they use their own product; since they&rsquo;re developers already, they&rsquo;re probably dogfooding their product, and the effort required should be&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>flumpcakes</strong>: &gt; How many 1+ hour videos of someone building with AI tools have you sought out and watched? A lot, they&rsquo;ve mostly all been advertising trite and completely useless. I don&rsquo;t want a demonstration of&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>andai</strong>: The honest answer is that I would probably ask AI to analyze the video for me, and that it would probably do a pretty good job.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>pksebben</strong>: I can only speak for myself, but it feels like playing with fire to productize this stuff too quick. Like, I woke up one day and a magical owl told me that I was a wizard.  Now I control the elements&hellip;</p>
</blockquote>
<blockquote>
<p><strong>FuriouslyAdrift</strong>: LLMs are lossy compression of a corpus with a really good parser as a front end. As human made content dries up (due to LLM use), the AI products will plateau. I see inference as the much bigger&hellip;</p>
</blockquote>
<blockquote>
<p><strong>ChaseRensberger</strong>: Well said.</p>
</blockquote>
<p><strong>pyuser583</strong>: Opus 4.5 burns through tokens really fast.</p>
<blockquote>
<p><strong>jghn</strong>: I&rsquo;ve been noticing it&rsquo;s more on par with sonnet these days. I don&rsquo;t know if that means Opus is getting more efficient, sonnet getting less efficient, or perhaps Opus is getting to the answer fast&hellip;</p>
</blockquote>
<blockquote>
<p><strong>mcv</strong>: I&rsquo;ve noticed. I&rsquo;m already through 48% of my quota for this month.</p>
</blockquote>
<p><strong>satisfice</strong>: Doing things for your own use, where you are taking all the risks, is perfectly fine. As soon as you try to sell it to me, you have a duty of care. You are not meeting that duty of care with this&hellip;</p>
<p><strong>bluelightning2k</strong>: The harness here was Claude Code?</p>
<p><strong>rubzah</strong>: Once again. It is not greenfield projects most of us want to use AI coding assistance for. It is for an existing project, with a byzantine mess of a codebase, and even worse messes of infrastructure,&hellip;</p>
<p><strong>lawlessone</strong>: Blogspam.</p>
<blockquote>
<p><strong>catoAppreciator</strong>: blogslop</p>
</blockquote>
<p><strong>DGAP</strong>: Time to get a new job.</p>
<p><strong>overgard</strong>: Ugh, I&rsquo;m so sick of these &ldquo;I can use AI to solve an already solved problem, thus programmers aren&rsquo;t relevant.&rdquo; Note the solved problem part. This isn&rsquo;t convincing except to people that want a (bad)&hellip;</p>
<blockquote>
<p><strong>emodendroket</strong>: Aren&rsquo;t most products that actually ship some kind of &ldquo;solved problem&rdquo; though?</p>
</blockquote>
<p><strong>bigcloud1299</strong>: Oh shit your UI looks exactly 100% like mine.</p>
<p><strong>drchiu</strong>: Having used Opus 4.5 for the past 5 weeks, I estimate it codes better than 95% of the people I&rsquo;ve ever worked with. And it writes with more clarity too. The only people who are complaining about &ldquo;AI&hellip;</p>
<p><strong>danfritz</strong>: Every time I see a post like this on HN I try again and every time I come to the same conclusion. I have never see one agent managing to pull something off that I could instantly ship. It still ends&hellip;</p>
<blockquote>
<p><strong>thewillowcat</strong>: These posts are never, never made by someone who is responsible for shipping production code in a large, heavily used application. It&rsquo;s always someone at a director+ level who stopped production&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>moduspol</strong>: It is also often low-proficiency developers with their minds blown over how quickly they can build something using frameworks / languages they never wanted to learn or understand. Though even that&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>weitendorf</strong>: Back in the day when you found a solution to your problem on Stackoverflow, you typically had to make some minor changes and perhaps engage in some critical thinking to integrate it into your code&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>eudamoniac</strong>: &gt; it was much easier to complete the fix starting from something 90% working than 0%. As an expert now though, it is genuinely easier and faster to complete the work starting from 0 than to modify&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>weitendorf</strong>: Anecdotally I think you&rsquo;re right that the more skilled you are at something, the less utility there is for something that quickly but incompletely takes you from 0 to 90% But I would generally be&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>Forgeties79</strong>: The difference is you’re generally retooling for your purpose rather than scouring for multiple, easily avoidable screw ups that if overlooked will cause massive headaches later on.</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>ammut</strong>: I&rsquo;ve spent quite a bit of time with Codex recently and come to the conclusion that you can&rsquo;t simply say &ldquo;Let&rsquo;s add custom video controls around ReactPlayer.&rdquo; You need to follow up with a set of&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>strobe</strong>: &gt;You need to follow up with a set of strict requirements to set expectations, guard rails, and what the final product should do (and not do). that usually very hard to do part, and is was possible to&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>danfritz</strong>: By the time I have figured out all those quirks and guardrails I could have done it myself in 45min tops.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>pluralmonad</strong>: This is very true. But each iteration of learning quirks and installing guardrails carries value forward to later sessions. These rough edges get smoother with use, is my point.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>lucianbr</strong>: It sounds like it takes you at least 10 minutes to just write the prompt with all the details you mentioned. Especially if you need to continue and prompt again (and again?).</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>solumunus</strong>: Not the OP but, easily. My tasks are usually taking at least that, but up to hours of brainstorming and planning, sometimes I’ll do this over days in between other tasks just so I can think about all&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>Gud</strong>: I mean, I typically do a lot more thinking than 10 minutes. I’m writing some (for me) seriously advanced software that would have taken me months to write, in weeks, using Claude and ChatGPT. It’s&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>enraged_camel</strong>: I find anecdotes like yours bewildering, because I&rsquo;ve been using Opus with Vue.js and it crushes everything I throw at it. The amount of corrections I need to make tend to be minimal, and mostly&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>alternatex</strong>: Created a WYSIWYG editor or copied it off the internet like your average junior would, bugs included? If that editor is very complicated (as they usually are) it makes sense to just opt for a&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>PaulHoule</strong>: There is contenteditable and EditContext hese days,  it&rsquo;s not that hard to make a simple WYSIWYG editor.  An LLM could figure out how to operationalize these things quicker than I could.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>gejose</strong>: I used to run into this quite a bit until I added an explicit instruction in CLAUDE.md to the effect of: &gt; Be thoughtful when using <code>useEffect</code>. Read docs at&hellip;</p>
</blockquote>
<blockquote>
<p><strong>phn</strong>: Have you tried Roo Code in &ldquo;Orchestrator&rdquo; mode? I find it generally &ldquo;chews&rdquo; the tasks I give it to then spoon feed into sub-tasks in &ldquo;Code&rdquo; (or others) mode, leaving less room to stray from very&hellip;</p>
</blockquote>
<blockquote>
<p><strong>andai</strong>: I have a vanilla JS project. I find that very small llms are able to work on it with no issue. (Including complete rewrites.) But I asked even large LLMs to port it to React and they all consistently&hellip;</p>
</blockquote>
<blockquote>
<p><strong>doubleorseven</strong>: usually for me, after a good plan is 90% solid working code. the problem do arise when you ask it to change the colors it choose of light grey text over a white background. this thing still can&rsquo;t see&hellip;</p>
</blockquote>
<blockquote>
<p><strong>mnky9800n</strong>: I always assume the person either didn&rsquo;t use coding agents in a while or its their first time. don&rsquo;t get me wrong, i love claude code, but my students are still better at getting stuff done that i&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>PaulHoule</strong>: Around a Uni I think a lot about what students are good at and what they aren&rsquo;t good at. I wouldn&rsquo;t even think about hiring a student to do marketing work.  They just don&rsquo;t understand how hard it is&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>hu3</strong>: Yep. It sucks. People are delusional. Let&rsquo;s ignore LLMs and carry on&hellip; On a more serious note: 1) Split tasks into smaller tasks just like a human would do Would you bash your keyboard for an hour,&hellip;</p>
</blockquote>
<blockquote>
<p><strong>jf22</strong>: So? Getting a months&rsquo; worth of junior level code in an hour is still unbelievable.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>danfritz</strong>: Whats the improvement here? I spend more time fixing it then doing it myself anyways. And I have less confidence in the code Opus generates</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>hasmolo</strong>: i’ve become convinced that the devs that talk about having to fix the code are the same ones that would make incredibly poor managers. when you manage a team you need to be focused on the effect of&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>jf22</strong>: What are you fixing?</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>skerit</strong>: Ah, another thread filled with people sharing anecdotes about how they asked Claude to one-shot an entire project that would take people weeks if not months.</p>
<p><strong>kypro</strong>: It&rsquo;s been interesting watching HN shift in my direction on this in recent weeks&hellip; I had been saying since around summer of this year that coding agents were getting extremely good. The base model&hellip;</p>
<blockquote>
<p><strong>billmalarky</strong>: Hi Kypro this is very interesting perspective. Can you reach out to me? I&rsquo;d like to discuss what you&rsquo;re observing with you a bit in private as it relates heavily to a project I&rsquo;m currently working&hellip;</p>
</blockquote>
<blockquote>
<p><strong>rdos</strong>: LLM&rsquo;s are good at making stuff from scratch and perfect when you don&rsquo;t have to worry about the codes future. &lsquo;Research&rsquo; can be a great tool. But LLMs are horrible in big codebases and multiple micro&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>kypro</strong>: Are you saying this from experience? We have a large monorepo at my company. You&rsquo;re right that for adding entirely new core concepts to an existing codebase we wouldn&rsquo;t give an AI some vague&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>rdos</strong>: &gt; Are you saying this from experience? Yes. I mostly work on Quarkus microservices and use cursor with auto agent mode. &gt; we wouldn&rsquo;t give an AI some vague requirements and ask it to build something&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>Rapzid</strong>: &gt; a steady stream of shippable products Software/web meat shops have bean around since the dawn of the time. I worked at McDonald&rsquo;s in my teens. One of the best managers I ever worked for was the&hellip;</p>
</blockquote>
<p><strong>vivzkestrel</strong>: - does it understand the difference between eslint 8x and eslint 9.x? - or biome 1.x and biome 2.x ? - nah! it never will and that is why it ll never replace mid level engineers, FTFY</p>
<blockquote>
<p><strong>hu3</strong>: it does if you feed docs. just like humans</p>
</blockquote>
<p><strong>hollowturtle</strong>: I&rsquo;m tired of constantly debating the same thing again and again. Where are the products? Where is some great performing software all LLM/agent crafted? All I see is software bloatness and decline&hellip;.</p>
<blockquote>
<p><strong>g947o</strong>: This deserves more upvotes. Even if there is a &ldquo;fully vibe-coded&rdquo; product that has real customers, the fact that it&rsquo;s vibe-coded means that others can do the same. Unless you have a secret LLM or&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>kaydub</strong>: I&rsquo;m not sure what point you&rsquo;re making here. Tech is rarely the moat, you even get to that point at the end of your post. The &ldquo;vibe coding&rdquo; advantage is faster time to market, faster iterations, etc&hellip;.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>hollowturtle</strong>: Faster, faster, faster. All to release something that is slower, by people that now know lesser, with bloat that explodes. All for a yet another useless saas that nobody or fee people wants and a&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>enraged_camel</strong>: &raquo; Even if there is a &ldquo;fully vibe-coded&rdquo; product that has real customers, the fact that it&rsquo;s vibe-coded means that others can do the same. But that&rsquo;s precisely why you don&rsquo;t hear about these&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>hollowturtle</strong>: We all have a cousin that makes $10k/mo and has super powers</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>g947o</strong>: And I know 100 such products that are making $100k/month, do you believe me or not? I&rsquo;m afraid your numbers are not any more informative or useful than mine.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>weitendorf</strong>: &gt; Even if there is a &ldquo;fully vibe-coded&rdquo; product that has real customers, the fact that it&rsquo;s vibe-coded means that others can do the same. I think you are strawmanning what &ldquo;vibe coders&rdquo; do when they&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>g947o</strong>: Friendly reminder: the comment is under a post that is hyping the capability of LLMs.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>jwblackwell</strong>: With all due respect somebody could launch a version of Discord that&rsquo;s 10x faster tomorrow and nobody would know about it It&rsquo;s very difficult to unseat those incumbents, especially those with strong&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>twak</strong>: you can build it and simply use it in your own office? There is no need to shout about it if the cost of writing software goes to zero (but the value remains non-zero!).</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>exographicskip</strong>: Get the feeling with the pending IPO, there might be some challengers to discord that get more traction due to the protracted enshittification of the platform (cf. bluesky)</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>hollowturtle</strong>: Totally disagree. One example is Zed which is very well known and it&rsquo;s faster than any other editor, wasn&rsquo;t built with AI though. &gt; People on larger companies are not at the edge of AI coding False&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>throwup238</strong>: &gt; One example is Zed which is very well known and it&rsquo;s faster than any other editor, wasn&rsquo;t built with AI though. Not according to a Zed team member, in these very comments:&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>scottyeager</strong>: Do you mean to say Zed wasn&rsquo;t vibe coded? There&rsquo;s actually another comment on this post describing how someone is using Opus 4.5 to work on Zed. Given how forward the AI features are in Zed I&rsquo;d be&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>PretzelPirate</strong>: &gt; Yet no better vscode, still bloated teams etc etc Why do you assume that Microsoft would focus on building a better (to you) VSCode or less bloated Teams? I assume they&rsquo;d use Github Copilot to make&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>pluralmonad</strong>: I don&rsquo;t recall if it was an AGENT.md or CLAUDE.md but one of those was definitely in the Zed repo last time I looked at it. Someone is using AI to work on it.</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>ciupicri</strong>: Zed fast? No way as I&rsquo;ve mentioned last year <a href="https://news.ycombinator.com/item?id=42819817">https://news.ycombinator.com/item?id=42819817</a></p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>broken_ceiling</strong>: This argument falls a little flat when you consider how much software may or may not be written inside one&rsquo;s own personal work flow, or to scale that up, inside a small business. The idea that a&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>hollowturtle</strong>: Your argument falls a little flat considering that you mention &ldquo;hire a dev or two&rdquo; while the whole narrative is &ldquo;we don&rsquo;t need software engineers anymore&rdquo; and Anthropic alone declares that &ldquo;Although&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>broken_ceiling</strong>: When was I arguing about job displacement or the replacing of engineers?  You are projecting hard, and reaching.  If anything, I am in the camp that accessibility to custom tooling equals a net&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>krageon</strong>: <a href="https://www.anthropic.com/research/how-ai-is-transforming-wo">https://www.anthropic.com/research/how-ai-is-transforming-wo</a>&hellip; see &ldquo;How much work can be fully delegated to Claude?&rdquo;: &ldquo;Although engineers use Claude frequently, more than half said they can “fully&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>hollowturtle</strong>: I&rsquo;m not asking for it, i&rsquo;m asking to stop bulshitting about ai</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>krageon</strong>: My point is that you can ignore every article about ai being super good as long as you see the vendor research (that you read once a year or less) is still the same. It saves everyone a lot of&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>D-Machine</strong>: Thank you for linking this very useful and much more realistic / grounded stat.</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>konhi</strong>: I share similar feelings. I feel like I&rsquo;m reading the same comments about LLM since a year, only model version changes. Obviously there&rsquo;s improvement in the models and tooling, but the debate seems&hellip;</p>
</blockquote>
<blockquote>
<p><strong>ebiester</strong>: The bigger the product, the harder this is. However, I think the biggest thing is the replacement of products. We are in a place where he talked about replacing two products his wife was using with&hellip;</p>
</blockquote>
<blockquote>
<p><strong>lunias</strong>: This is true. I think most people are mostly using AI at work to fix bugs in existing codebases. A smaller group of people are benchmarking AI by giving it ideas for apps that no one needs and seeing&hellip;</p>
</blockquote>
<blockquote>
<p><strong>taytus</strong>: Could someone explain this to me? I have the same question: why Cursor team don&rsquo;t use Cursor to get rid of vscode base and code its super duper code editor?</p>
</blockquote>
<blockquote>
<p><strong>weitendorf</strong>: Except for maybe an &ldquo;Excel killer&rdquo;, all those things you listed are not things people are willing to pay for. Also agents are bad at that kind of work (most devs are bad at that stuff, it&rsquo;s why it&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>hollowturtle</strong>: Not willing to pay for? How can you be sure? For example explain then why many gamers are ditching Windows for Linux and buying hardware from Valve&hellip; There must be a reason. Every person I talked to&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>weitendorf</strong>: Generally if something is fast enough/efficient enough that a paying customer can use it without having to worry or actively think about performance and un-bloatedness, that&rsquo;s enough for them. The&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>PaulHoule</strong>: I did a lot of analysis and biz dev work on the &ldquo;Excel killer&rdquo; and came to the conclusion that it would be hard to get people to pay for. For one thing most enterprises and many individuals have an&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p><strong>hollowturtle</strong>: Wrt statue.dev good luck for sure with the project  but I personally don&rsquo;t need yet another static site generator, nextjs like but with unpopular svelte, bloated with tons of node modules creating&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>quest88</strong>: Anecdotally I had Gemini convert a simple react native app to swift in two prompts. If it&rsquo;s that simple then maybe we will see less of the chromium desktop apps</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>hollowturtle</strong>: I&rsquo;d argue the contrary, YOU KNOW you have the option, ease of entering doesn&rsquo;t mean they will know how to choose better, they will just vibe code more electron apps. In fact my prediction is not&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>xnx</strong>: AI amplified development has the most impact on build-vs-buy decisions. We should expect the decreased difficulty of creating software to drive down prices.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>hollowturtle</strong>: &gt; decreased difficulty of creating software to drive down prices. And here we go again, if difficulty has been decreased so much, where are the fixes or the products?</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>michalsustr</strong>: Hi, I’m building such one: <a href="https://minfx.ai/">https://minfx.ai/</a> Still early, but iterating really fast!</p>
</blockquote>
<blockquote>
<p><strong>maxdo</strong>: who told you that mb of ram is a definition of success? Opus was out only few months, and it will take time to get this new wave to market. i can assure you my team become way more productive because&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>hollowturtle</strong>: It&rsquo;s a definition of what runs and what not on consumer grade computers, Discord has a routine that now checks if memory goes over a certain threshold and eventually restart itselfs, this is a&hellip;</p>
</blockquote>
</blockquote>
<p><strong>yolkedgeek</strong>: I really can&rsquo;t tell if this is satire or not</p>
<p><strong>kelseyfrog</strong>: Can it pre-emptively write the HN comment where someone says it utterly fails for them but no one else is able to reproduce?</p>
<p><strong>llmslave2</strong>: I see Anthropics marketing campaign is out in full force today ahead of their IPO.</p>
<p><strong>hannofcart</strong>: To the sceptics still saying that LLMs still can&rsquo;t solve &ldquo;slime mold pathing algorithm and creating completely new shoe-lacing patterns&rdquo; (literally a quote from a different comment here), please&hellip;</p>
<p><strong>nikisil80</strong>: [flagged]</p>
<blockquote>
<p><strong>tomhow</strong>: Don&rsquo;t be curmudgeonly. Thoughtful criticism is fine, but please don&rsquo;t be rigidly or generically negative. <a href="https://news.ycombinator.com/newsguidelines.html">https://news.ycombinator.com/newsguidelines.html</a></p>
</blockquote>
<blockquote>
<p><strong>codepoet80</strong>: I don&rsquo;t think you&rsquo;ve used it.  I used it intensely and mostly autonomously (with clear instructions, including how to measure good output) almost non-stop over the holidays. Its a new abstraction for&hellip;</p>
</blockquote>
<blockquote>
<p><strong>Johanx64</strong>: &gt; none of this is going to improve people&rsquo;s lives. I have some old borderline senile relatives writting apps (asking LLMs to write for it them) for their own personal use. Stuff they surely haven&rsquo;t&hellip;</p>
</blockquote>
<blockquote>
<p><strong>minimaxir</strong>: &gt; Re-building things that most probably already exist, simply with your own little special flavour? That describes half of the current unicorn startups nowadays.</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>christophilus</strong>: More than half. What has anyone written that was truly new? Regardless, if you have an idea, you will build it out of some combination of conditionals, loops, and expressions… turns out agents are&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<p><strong>empiko</strong>: This is a natural response to software enshittification. You can hardly find an iOS app that is not plagued by ads, subscriptions, or hostile data collection. Now you can have your own small&hellip;</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>nikisil80</strong>: Yeah sure but have you considered that the actual cost of running these models is actually much greater than whatever cost you might be shelling out for the ad-free apps? You&rsquo;re talking to someone&hellip;</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>falloutx</strong>: At this point it doesn&rsquo;t matter that much whether we use AI or not, the apps are not selling and they are being produced at an alarming rate. The projects being submitted to product hunt is 4x the&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p><strong>minimaxir</strong>: You are attempting to move the goalposts. There are two different points in this debate: 1) Modern LLMs are an inflection point for coding. 2) The current LLM ecosystem is unsustainable. This&hellip;</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<p><strong>jgbuddy</strong>: [flagged]</p>
</blockquote>
<blockquote>
<blockquote>
<p><strong>tomhow</strong>: When disagreeing, please reply to the argument instead of calling names. <a href="https://news.ycombinator.com/newsguidelines.html">https://news.ycombinator.com/newsguidelines.html</a></p>
</blockquote>
</blockquote>

      </div>

      

      <nav class="article-nav">
        
        <a href="../sources/2025-12-22-claude-code-lsp-support.html" class="article-nav-link article-nav-link--prev">
          <span class="article-nav-direction">Previous</span>
          <span class="article-nav-title">Claude Code gets native LSP support</span>
        </a>
        
        
        <a href="../sources/2026-01-24-claude-code-swarms.html" class="article-nav-link article-nav-link--next">
          <span class="article-nav-direction">Next</span>
          <span class="article-nav-title">Claude Code&#39;s New Hidden Feature: Swarms</span>
        </a>
        
      </nav>
    </article>

    
<aside class="toc-sidebar" aria-label="Table of Contents">
  <div class="toc-container">
    <h2 class="toc-title">On this page</h2>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#summary">Summary</a></li>
    <li><a href="#key-insights">Key Insights</a></li>
    <li><a href="#notable-quotes">Notable Quotes</a></li>
    <li><a href="#hn-discussion-highlights">HN Discussion Highlights</a></li>
  </ul>
</nav>
  </div>
</aside>


  </div>
</div>

    </main><footer class="site-footer">
  <div class="footer-container">
    <div class="footer-brand">
      <span class="footer-logo">AI Best Practices</span>
      <p class="footer-description">What actually works in AI-assisted development — synthesized from 6,000&#43; practitioner comments across 20 major HN discussions.</p>
    </div>
    <div class="footer-nav">
      <div class="footer-section">
        <h3>Learn</h3>
        <ul>
          <li><a href="../guide/index.html">Guide</a></li>
          <li><a href="../practices/index.html">Practices</a></li>
          <li><a href="../debates/index.html">Debates</a></li>
        </ul>
      </div>
      <div class="footer-section">
        <h3>Explore</h3>
        <ul>
          <li><a href="../tools/index.html">Tools</a></li>
          <li><a href="../evidence/index.html">Evidence</a></li>
          <li><a href="../voices/index.html">Voices</a></li>
          <li><a href="../sources/index.html">Sources</a></li>
        </ul>
      </div>
    </div>
    <div class="footer-bottom">
      <p>Built with Hugo. Synthesized from 32 HN discussions and 6,000+ practitioner comments. 78 pages across 198 topics.</p>
    </div>
  </div>
</footer>
<script src="../js/main.js" defer></script>
  </body>
</html>
