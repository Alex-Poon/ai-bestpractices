[
{"title":"Case Study: Building a C Compiler with AI Agents","url":"/evidence/carlini-compiler.html","section":"evidence","desc":"Carlini\u0026#39;s experiment with parallel Claude agents on a real compiler project.","content":"Nicholas Carlini set out to answer a simple question: can you build real, production-grade software using nothing but parallel AI agents? The result was a 100,000-line Rust-based C compiler, produced by 16 parallel Claude instances over two weeks, that passed 99% of the GCC torture test suite and compiled the Linux 6.9 kernel across x86, ARM, and RISC-V architectures.\nThe compiler itself is …","tags":["case-study","parallel-agents","autonomous-coding","test-design"]},
{"title":"Claude Code Deep Dive","url":"/tools/claude-code.html","section":"tools","desc":"Swarms, LSP support, AGENTS.md, benchmarks — everything practitioners need to know.","content":"Claude Code is Anthropic\u0026amp;rsquo;s CLI-first coding agent. It runs in the terminal, takes natural language task descriptions, and executes autonomously \u0026amp;ndash; reading files, running commands, editing code, and iterating on failures. It is single-model (Anthropic\u0026amp;rsquo;s Claude family), available through Claude Max subscriptions at $100-200/month, and focused entirely on agentic workflows with no …","tags":["claude-code","agent-workflows","swarms","harness-engineering"]},
{"title":"Daily Practice","url":"/workflows/daily-practice.html","section":"workflows","desc":"A practical daily checklist for AI-assisted development.","content":"Using AI coding tools effectively is not about writing better prompts on any given day. It is about building habits that compound over weeks and months. This page distills the daily routines that experienced practitioners follow, drawn from Karpathy\u0026amp;rsquo;s coding notes, Addy Osmani\u0026amp;rsquo;s LLM workflow, and patterns observed across the broader practitioner community.\nMorning Setup Review your …","tags":["workflow","checklist","daily-practice","productivity"]},
{"title":"Model Releases in 2026","url":"/landscape/model-releases-2026.html","section":"landscape","desc":"Claude 4.6, Gemini 3, DeepSeek, Llama 4, Mistral 3 — the rapidly evolving model landscape.","content":"The first weeks of 2026 have seen an extraordinary density of model releases. The pace itself is informative: frontier model competition has intensified to the point where simultaneous launches are the norm rather than the exception. Here is what has shipped and what it means for practitioners.\nClaude Opus 4.6 (February 2026) Anthropic\u0026amp;rsquo;s latest flagship arrived with a 1M-token context window …","tags":["model-releases","claude-code","gemini","llama","mistral","deepseek"]},
{"title":"Task Scoping for AI Agents","url":"/skills/task-scoping.html","section":"skills","desc":"How to decompose work into tasks AI can actually complete well.","content":"Task scoping is the single most important skill in AI-assisted development. It determines whether the time you spend prompting, waiting, and reviewing produces usable output or wasted effort. Every practitioner who has moved past the initial novelty phase identifies decomposition as the core discipline.\nThe Size Sweet Spot There is a narrow band where AI delegation works well. Too small, and the …","tags":["task-scoping","core-skill","agent-workflows"]},
{"title":"The Core Loop: Plan, Delegate, Verify, Harness","url":"/start-here/core-loop.html","section":"start-here","desc":"The fundamental workflow for effective AI-assisted development.","content":"Effective AI-assisted development is not about typing prompts and hoping for the best. It follows a repeating four-phase loop: Plan, Delegate, Verify, Harness. Every technique on this site maps back to one of these phases. If you internalize this loop and practice each phase deliberately, you will get better results from AI agents than the vast majority of developers who use them casually.\nThe …","tags":["core-concepts","getting-started","agent-workflows"]},
{"title":"The State of Agentic Coding Practice (Feb 2026)","url":"/synthesis/state-of-practice-feb-2026.html","section":"synthesis","desc":"Where serious practitioners have landed on AI-assisted development — synthesized from 35+ HN discussions and practitioner articles.","content":"A synthesis of where serious practitioners have landed on AI-assisted development, drawn from 35+ articles and Hacker News discussions spanning late 2025 through early 2026.\n1. Where Practitioners Actually Are Most serious practitioners have converged on a remarkably similar workflow loop:\nPlan in chat → Execute narrow diffs via agent → Verify fast → Tighten harness\nThe variation between …","tags":["synthesis","best-practices","agent-workflows"]},
{"title":"Claude Opus 4.6","url":"/sources/2026-02-05-claude-opus-4-6.html","section":"sources","desc":"","content":"Summary Anthropic announced Claude Opus 4.6, their most advanced model to date, featuring a landmark 1 million token context window in beta \u0026amp;ndash; the first for an Opus-class model. The release emphasizes substantial improvements in agentic coding, long-context work, and sustained multi-step workflows.\nOn benchmarks, Opus 4.6 achieved the top score on Terminal-Bench 2.0 for agentic coding and led …","tags":["model-release","anthropic","claude","opus","benchmarks","agent-teams","long-context"]},
{"title":"Claude Code daily benchmarks for degradation tracking","url":"/sources/2026-01-29-claude-code-benchmarks.html","section":"sources","desc":"","content":"Summary MarginLab launched a daily benchmark tracker for Claude Code performance, measuring the CLI tool against a curated subset of SWE-Bench-Pro tasks using the Opus 4.5 model. The tracker was created in response to widespread community concerns about silent model degradation, where users noticed performance fluctuations but had no systematic way to measure or verify them.\nThe methodology …","tags":["claude-code","benchmarks","model-degradation","evaluation","swe-bench","reliability"]},
{"title":"Case Study: Hashimoto's AI Adoption Journey","url":"/evidence/hashimoto-journey.html","section":"evidence","desc":"How the HashiCorp founder evolved from skeptic to power user.","content":"Mitchell Hashimoto \u0026amp;ndash; co-founder of HashiCorp, creator of Vagrant, Terraform, and Consul \u0026amp;ndash; published a detailed account of his personal journey adopting AI coding tools. The article resonated far beyond the usual AI discourse because Hashimoto is not a hype-prone commentator. He is a practitioner with decades of experience shipping infrastructure software used by millions of developers. …","tags":["case-study","adoption-strategy","harness-engineering"]},
{"title":"Cursor","url":"/tools/cursor.html","section":"tools","desc":"What practitioners say about the AI-native IDE.","content":"Cursor is a VS Code fork with AI capabilities built directly into the editor. It offers both autocomplete (Tab) and agentic (Composer/Agent) modes as first-class features, multi-model support with user-selectable models, and pricing starting at $20/month with usage-based tiers for heavier workloads. It has the largest adoption among AI coding tools in the IDE-first category.\nWhat Cursor Does Well …","tags":["cursor","ide-tools","tool-comparison"]},
{"title":"Harness Engineering","url":"/skills/harness-engineering.html","section":"skills","desc":"Configure your AI tools for maximum effectiveness with AGENTS.md, custom instructions, and project context.","content":"Harness engineering is the practice of building persistent infrastructure that constrains and guides AI agents across sessions. It is the highest-leverage investment in AI-assisted development because it compounds: every mistake you document is a mistake that never recurs.\nWhy the Harness Matters More Than the Prompt A well-harnessed mediocre prompt outperforms a perfect prompt with no harness. …","tags":["harness-engineering","core-skill","agents-md","claude-code"]},
{"title":"Parallel Agent Coordination","url":"/workflows/parallel-agents.html","section":"workflows","desc":"Patterns for orchestrating multiple AI agents on a single project.","content":"A single agent is often too slow for large projects. Running multiple agents in parallel is the obvious solution, but naive parallelism introduces failure modes that can waste more time and money than sequential work. This page covers when parallel agents help, when they hurt, and the coordination infrastructure that makes the difference.\nThe strongest empirical evidence comes from Nicholas …","tags":["parallel-agents","coordination","agent-workflows","swarms"]},
{"title":"The Adoption Curve","url":"/landscape/adoption-curve.html","section":"landscape","desc":"Where the industry stands on AI-assisted development adoption.","content":"AI-assisted development in early 2026 is past the novelty phase but far from universal. The community is split, the data is mixed, and where a given developer lands depends as much on their workflow and identity as on the technology itself.\nThe Six Stages Framework The Six Stages of AI Adoption framework, synthesized from Mitchell Hashimoto\u0026amp;rsquo;s influential account and extensive practitioner …","tags":["adoption-strategy","industry-trends"]},
{"title":"The Adoption Curve: Where Are You?","url":"/start-here/adoption-stages.html","section":"start-here","desc":"From skeptic to power user — understanding the stages of AI coding adoption.","content":"Developers who successfully adopt AI coding agents tend to follow the same progression. Not because someone prescribed it, but because each stage builds the calibration and infrastructure the next stage requires. Skipping stages leads to frustration, wasted money, and the conclusion that agents do not work \u0026amp;mdash; when the real problem was missing foundations.\nThis framework synthesizes Mitchell …","tags":["adoption-strategy","getting-started"]},
{"title":"A few random notes from Claude coding quite a bit last week","url":"/sources/2026-01-26-karpathy-claude-coding-notes.html","section":"sources","desc":"","content":"Summary Andrej Karpathy shared a widely discussed thread of observations from extensive Claude Code usage. His notes touched on several key themes that resonated deeply with the developer community, generating nearly 100 HN comments and over 900 upvotes.\nOne of Karpathy\u0026amp;rsquo;s central observations was around the tension between AI-assisted productivity and personal skill development. He noted …","tags":["claude-code","vibe-coding","agent-workflows","skill-atrophy","productivity","ide-tools"]},
{"title":"Apple picks Gemini to power Siri","url":"/sources/2026-01-12-apple-picks-gemini-siri.html","section":"sources","desc":"","content":"Summary Apple announced a partnership with Google to use Gemini as the foundational AI technology powering Siri, marking one of the most significant strategic moves in the AI industry. The deal, reportedly valued near $1 billion, represents Apple\u0026amp;rsquo;s acknowledgment that building competitive frontier AI models in-house is not where their advantage lies.\nApple\u0026amp;rsquo;s decision was driven by …","tags":["apple","google","gemini","siri","ai-strategy","industry-partnerships","model-selection"]},
{"title":"How to Code Claude Code in 200 Lines of Code","url":"/sources/2026-01-08-claude-code-200-lines.html","section":"sources","desc":"","content":"Summary Mihail Eric\u0026amp;rsquo;s article, provocatively titled \u0026amp;ldquo;The Emperor Has No Clothes,\u0026amp;rdquo; argues that AI coding assistants are not magical — they follow a simple architectural loop. The user sends a request, the LLM decides which tools to call, your code executes those tools locally, and the results flow back to the LLM for context. The critical mental model is that the LLM never …","tags":["claude-code","agent-architecture","tool-calling","coding-agents","demystification"]},
{"title":"AGENTS.md Guide","url":"/workflows/agents-md-guide.html","section":"workflows","desc":"How to write effective AGENTS.md and CLAUDE.md files — the evidence-backed approach to AI harness configuration.","content":"AGENTS.md and CLAUDE.md are project-root files that AI coding agents read at the start of every session. They give agents persistent, project-specific context that would otherwise be lost between conversations. Different tools use different filenames \u0026amp;ndash; Claude Code reads CLAUDE.md, Amp reads AGENTS.md, and most tools now support both \u0026amp;ndash; but the purpose is identical: tell the agent how to …","tags":["agents-md","harness-engineering","claude-code","best-practices"]},
{"title":"Amp Code","url":"/tools/amp.html","section":"tools","desc":"Sourcegraph\u0026#39;s multi-model coding agent — architecture and practitioner reception.","content":"Amp Code is a coding agent built by the team behind Sourcegraph\u0026amp;rsquo;s code intelligence platform. Available as a CLI, VS Code extension, and JetBrains plugin, it is the most explicit implementation of multi-model routing in a production coding tool. Rather than letting users pick a single model, Amp routes tasks automatically based on type \u0026amp;ndash; sending planning, implementation, review, and …","tags":["amp-code","multi-model","agent-architecture","tool-comparison"]},
{"title":"Costs and Tradeoffs","url":"/landscape/costs-and-tradeoffs.html","section":"landscape","desc":"The real economics of AI coding — costs, reliability, and what practitioners report spending.","content":"AI coding tools promise productivity gains, but they come with real costs \u0026amp;mdash; financial, operational, and strategic. This page collects what practitioners have reported spending, the reliability challenges they face, and the economic questions that remain unresolved.\nThe $638 Study: What Heavy Usage Actually Costs One of the most detailed cost reports comes from a founder and CTO who tracked …","tags":["cost-optimization","reliability","ai-economics"]},
{"title":"Practitioner Voices","url":"/evidence/practitioner-voices.html","section":"evidence","desc":"What developers actually say — curated insights from Hacker News discussions.","content":"The best evidence for how AI coding tools actually perform comes not from marketing materials or press releases but from practitioners reporting concrete experiences. The following quotes and observations are drawn from Hacker News discussions that collectively represent thousands of upvotes and hundreds of comments from working developers.\nEach entry is attributed to its original author and …","tags":["community-discussion","practitioner-insights"]},
{"title":"Verification: Reading AI-Generated Code","url":"/skills/verification.html","section":"skills","desc":"The most critical skill -- how to effectively review and validate AI output.","content":"As AI takes over more code generation, the developer\u0026amp;rsquo;s primary contribution shifts from writing to reading. Verification \u0026amp;ndash; the ability to evaluate whether AI-generated code is correct, secure, and aligned with intent \u0026amp;ndash; becomes the skill that separates productive AI usage from expensive mistakes.\nWhy Verification Matters More Than Generation The economics of AI-assisted …","tags":["verification","core-skill","code-review","skill-atrophy"]},
{"title":"How AI assistance impacts the formation of coding skills","url":"/sources/2026-01-30-ai-assistance-coding-skills.html","section":"sources","desc":"","content":"Summary Anthropic published a randomized controlled study examining how AI assistance affects skill acquisition among junior software engineers. The research involved 52 participants divided into AI-assisted and control groups, tasked with learning and using Trio (a Python asynchronous programming library). After completing coding tasks, participants took a comprehension quiz covering debugging, …","tags":["skill-development","research","anthropic","junior-developers","productivity","code-quality"]},
{"title":"AGENTS.md Outperforms Skills in Our Agent Evals","url":"/sources/2026-01-29-agents-md-outperforms-skills.html","section":"sources","desc":"","content":"Summary Vercel\u0026amp;rsquo;s engineering team published an evaluation comparing two approaches to providing AI coding agents with documentation: AGENTS.md files (passive context embedded in the system prompt) versus skills (active retrieval tools the agent can invoke on demand). The evaluation targeted Next.js 16 APIs that were absent from model training data, including new patterns like \u0026#39;use cache\u0026#39;, …","tags":["agents-md","harness-engineering","prompt-engineering","evals","vercel","next-js"]},
{"title":"Claude Code's New Hidden Feature: Swarms","url":"/sources/2026-01-24-claude-code-swarms.html","section":"sources","desc":"","content":"Summary A tweet by @NicerInPerson revealed that Claude Code contains hidden multi-agent orchestration capabilities, colloquially referred to as \u0026amp;ldquo;swarms.\u0026amp;rdquo; The discovery, corroborated by a GitHub repository (claude-sneakpeek by mikekelly), showed that Anthropic had built native sub-agent coordination features including a TeammateTool, delegate mode for spawning background agents, and a …","tags":["claude-code","multi-agent","swarms","agent-workflows","harness-engineering"]},
{"title":"Opus 4.5 is not the normal AI agent experience","url":"/sources/2026-01-06-opus-4-5-agent-experience.html","section":"sources","desc":"","content":"Summary Burke Holland wrote an enthusiastic account of his experience using Claude\u0026amp;rsquo;s Opus 4.5 model, arguing it represents a fundamental shift in AI agent capabilities that goes beyond anything he had previously experienced. His central claim is that Opus 4.5 delivers on promises that earlier AI coding agents could not fulfill, particularly around autonomous problem-solving and first-attempt …","tags":["opus","claude-code","agent-workflows","vibe-coding","ai-capabilities","developer-experience"]},
{"title":"GitHub Copilot","url":"/tools/copilot.html","section":"tools","desc":"Where inline completion fits in the age of agentic coding.","content":"GitHub Copilot is the most widely deployed AI coding tool, with access available to over 100 million developers through the GitHub ecosystem. It started as an inline autocomplete tool and has gradually expanded into chat and agentic capabilities, but its core strength remains fast, in-flow code completion.\nWhat Copilot Does Inline autocomplete. Copilot\u0026amp;rsquo;s primary feature is suggesting code as …","tags":["copilot","tool-comparison"]},
{"title":"Model Selection","url":"/skills/model-selection.html","section":"skills","desc":"Choosing the right model for the right task -- balancing capability, cost, and speed.","content":"Model selection is the skill of matching the right model to the right task. The gap between a well-chosen and poorly-chosen model often matters more than the quality of the prompt itself. As one practitioner put it, model choice now outweighs prompt engineering as the primary lever for coding quality.\nModel Tiers Models fall into rough capability tiers, each suited to different kinds of work. …","tags":["model-selection","core-skill","cost-optimization"]},
{"title":"Open Questions","url":"/landscape/open-questions.html","section":"landscape","desc":"The debates still raging in the AI coding community.","content":"Not everything about AI-assisted development is settled. Several major questions remain genuinely open, with credible evidence and strong opinions on multiple sides. This page captures the debates as they stand in early 2026.\nIs AI Making Coding Skills Atrophy? Anthropic\u0026amp;rsquo;s own randomized controlled study provides the most rigorous data point. Junior developers using AI assistance scored 17% …","tags":["debate","open-questions","ai-skepticism","skill-atrophy"]},
{"title":"The Vibe Coding Spectrum","url":"/workflows/vibe-coding-spectrum.html","section":"workflows","desc":"From rapid prototyping to production engineering — understanding when to be rigorous.","content":"\u0026amp;ldquo;Vibe coding\u0026amp;rdquo; entered the vocabulary in early 2025, but practitioners quickly discovered that the term covered fundamentally different activities. David Bau\u0026amp;rsquo;s influential article identified two distinct types, and the community debate that followed revealed a full spectrum of approaches between them. Understanding where you are on this spectrum \u0026amp;ndash; and where you should be …","tags":["vibe-coding","workflow","code-quality","productivity"]},
{"title":"The MCP Ecosystem","url":"/tools/mcp-ecosystem.html","section":"tools","desc":"Model Context Protocol is becoming the standard for AI tool interoperability.","content":"Model Context Protocol (MCP) is an open standard introduced by Anthropic for connecting AI agents to external tools and data sources. It defines a structured interface through which an agent can discover, invoke, and receive results from tools \u0026amp;ndash; databases, APIs, file systems, cloud services, and more \u0026amp;ndash; without custom integration code for each one.\nMCP matters because it addresses a …","tags":["mcp","tooling","interoperability"]},
{"title":"Claude Code gets native LSP support","url":"/sources/2025-12-22-claude-code-lsp-support.html","section":"sources","desc":"","content":"Summary Anthropic added native Language Server Protocol (LSP) support to Claude Code, enabling the CLI-based agent to integrate with language servers for improved code understanding, navigation, and analysis. The feature was announced through Claude Code\u0026amp;rsquo;s changelog and surfaced via a plugin system where users can discover and install LSP integrations.\nLSP support represents a significant …","tags":["claude-code","lsp","developer-tools","ide","plugins","code-intelligence"]},
{"title":"The Agentic AI Handbook: Production-Ready Patterns","url":"/sources/2026-01-21-agentic-ai-handbook.html","section":"sources","desc":"","content":"Summary The Agentic AI Handbook provides a comprehensive taxonomy of production-ready patterns for building agentic AI systems. Its core definition frames an agent as an LLM wrapped in a loop that can observe state, call tools, record results, and decide when it is done. The handbook organizes patterns into eight categories covering orchestration and control, tool use, context and memory, feedback …","tags":["agent-workflows","agentic-patterns","production-engineering","multi-agent","security"]},
{"title":"Two Kinds of Vibe Coding","url":"/sources/2025-12-18-two-kinds-vibe-coding.html","section":"sources","desc":"","content":"Summary David Bau distinguishes between two fundamentally different approaches to what has broadly been called \u0026amp;ldquo;vibe coding.\u0026amp;rdquo; The first type involves delegating small tasks to an LLM while the human programmer remains fully informed and in control, reviewing each piece of work and making all key decisions. The second type involves surrendering cognitive control to an AI agent, allowing …","tags":["vibe-coding","testing","ai-coding-workflow","code-review","meta-cognition"]},
{"title":"How Vibe Coding Is Killing Open Source","url":"/sources/2026-02-02-vibe-coding-killing-open-source.html","section":"sources","desc":"","content":"Summary This Hackaday article reports on research examining how vibe coding — using LLM chatbots to generate code — creates systemic problems for open source projects. The core argument is that AI-mediated coding disrupts the traditional feedback loops between developers and open source communities in several damaging ways.\nFirst, developer engagement shifts away from open source communities …","tags":["vibe-coding","open-source","community","ai-impact","developer-experience"]},
{"title":"My LLM Coding Workflow Going into 2026","url":"/sources/2026-01-04-llm-coding-workflow-2026.html","section":"sources","desc":"","content":"Summary Addy Osmani, a well-known figure in the web development community, shares his comprehensive approach to AI-augmented software engineering. The central philosophy treats LLMs as powerful pair programmers that require clear direction, context, and human oversight rather than autonomous replacements for developers.\nThe workflow is structured around several core practices. First, planning …","tags":["ai-coding-workflow","prompt-engineering","code-review","testing","tool-selection"]},
{"title":"Tell HN: Claude Has Had 57 Incidents in the Past 3 Months","url":"/sources/2026-02-04-claude-57-incidents-3-months.html","section":"sources","desc":"","content":"Summary This HN text post by shikkra documents reliability concerns with Anthropic\u0026amp;rsquo;s Claude service, providing a detailed incident count from the official status page (status.claude.com). The author, a $100/month Max plan subscriber, was prompted to investigate after encountering a retry issue where Claude attempted to generate a response 10 times with Opus 4.5 and extended thinking enabled …","tags":["claude","reliability","anthropic","service-quality","developer-experience"]},
{"title":"Coding with LLMs in 2026: The Model Matters More Than the Prompts","url":"/sources/2026-01-18-model-matters-more-than-prompts.html","section":"sources","desc":"","content":"Summary This post by @slow_developer on X (formerly Twitter) argues that the shift from 2025 to 2026 in AI-assisted coding has been defined by a fundamental rebalancing: model choice now outweighs prompt engineering as the primary lever for coding quality. Where 2025 workflows focused heavily on crafting precise prompts and structuring interactions carefully, the advancements in frontier models …","tags":["model-selection","prompt-engineering","claude-code","cursor","agent-workflows"]},
{"title":"Agentic Frameworks in 2026: Less Hype, More Autonomy","url":"/sources/2026-01-06-agentic-frameworks-2026.html","section":"sources","desc":"","content":"Summary This HN text post by raghavchamadiya provides a practitioner-level comparison of agentic frameworks in 2026, focusing on lived behavior rather than benchmarks. The author has built, broken, and rebuilt agents across several stacks and shares observations on how the ecosystem has matured.\nThe core thesis is that the key differentiator for frameworks has shifted from how they wrap prompting …","tags":["agent-workflows","agentic-frameworks","memory-systems","multi-agent","production-engineering"]},
{"title":"Mistral 3 family of models released","url":"/sources/2025-12-02-mistral-3-models.html","section":"sources","desc":"","content":"Summary Mistral AI released the Mistral 3 family, a new generation of open-source multimodal models under the Apache 2.0 license. The lineup includes three dense models at 3B, 8B, and 14B parameters (the Ministral variants), plus Mistral Large 3, a sparse mixture-of-experts model with 41B active parameters drawn from a 675B total pool.\nAll models feature native multimodal and multilingual …","tags":["open-source-models","model-releases","multimodal","benchmarks","mistral"]},
{"title":"OpenAI's cash burn will be one of the big bubble questions of 2026","url":"/sources/2025-12-30-openai-cash-burn.html","section":"sources","desc":"","content":"Summary This Economist article examines the financial sustainability questions surrounding OpenAI and the broader AI industry heading into 2026. The piece focuses on OpenAI\u0026amp;rsquo;s extraordinary capital requirements and whether the company\u0026amp;rsquo;s spending trajectory can be justified by eventual revenue generation. The article could not be directly accessed due to the Economist\u0026amp;rsquo;s paywall, …","tags":["openai","ai-bubble","economics","venture-capital","sustainability","business-models"]},
{"title":"AI coding assistants are getting worse?","url":"/sources/2026-01-08-ai-coding-getting-worse.html","section":"sources","desc":"","content":"Summary This IEEE Spectrum article by Jamie Twiss presents the provocative claim that AI coding assistants are experiencing degradation rather than improvement. The central narrative comes from power users who report that these tools have hit a plateau, with some even declining in capability. The article identifies what it calls \u0026amp;ldquo;silent failures\u0026amp;rdquo; \u0026amp;ndash; situations where AI coding …","tags":["ai-coding-tools","model-degradation","evaluation","developer-experience","skepticism"]},
{"title":"Ask HN: 10 months since the Llama-4 release: what happened to Meta AI?","url":"/sources/2026-02-05-ask-hn-llama-4-meta.html","section":"sources","desc":"","content":"Summary An Ask HN post raised questions about the state of Meta\u0026amp;rsquo;s AI efforts roughly 10 months after the Llama 4 release, which was widely considered a disappointment. The original poster noted that Meta\u0026amp;rsquo;s API remained waitlist-only even after that long period, suggesting significant organizational or strategic problems.\nThe discussion paints a picture of a company that, despite …","tags":["meta","llama","open-source-ai","industry-analysis","model-release"]},
{"title":"How the AI Bubble Bursts in 2026","url":"/sources/2026-01-19-ai-bubble-bursts-2026.html","section":"sources","desc":"","content":"Summary This article from the \u0026amp;ldquo;Where\u0026amp;rsquo;s Your Ed At\u0026amp;rdquo; newsletter by Ed Zitron presents a detailed case for how the AI bubble might collapse in 2026. The analysis focuses on three interconnected pressure points: OpenAI\u0026amp;rsquo;s cash crisis, data center financing difficulties, and delayed infrastructure rollouts.\nOn the financial side, the article argues that OpenAI lacks sufficient …","tags":["ai-bubble","economics","infrastructure","openai","data-centers","skepticism"]},
{"title":"DeepSeek kicks off 2026 with paper signalling push to train bigger models for less","url":"/sources/2026-01-01-deepseek-bigger-models-less.html","section":"sources","desc":"","content":"Summary DeepSeek published a technical paper at the start of 2026 introducing Manifold-Constrained Hyper-Connections (mHC), a novel approach to training AI models more cost-effectively. The paper was co-authored by founder Liang Wenfeng and represents the Chinese AI startup\u0026amp;rsquo;s ongoing effort to compete with better-funded American competitors through efficiency innovations.\nThe mHC technique …","tags":["deepseek","training-efficiency","research-papers","model-architecture","china-ai"]},
{"title":"2026: The Year the IDE Died (Steve Yegge and Gene Kim)","url":"/sources/2025-12-10-year-ide-died.html","section":"sources","desc":"","content":"Summary This HN submission links to a YouTube talk by Steve Yegge and Gene Kim exploring how AI coding tools might replace the traditional IDE as the primary programming environment. The submitter (mikebiglan) frames the discussion around several key questions: how far IDEs will change, whether developers will still read and reason about code directly, and what the shift means for both senior …","tags":["ide","ai-coding-tools","vibe-coding","developer-workflows","future-of-coding"]},
{"title":"State of AI in 2026: LLMs, Coding, Scaling Laws, China, Agents, GPUs, AGI","url":"/sources/2026-02-01-state-of-ai-2026.html","section":"sources","desc":"","content":"Summary This is Lex Fridman Podcast episode #490, a comprehensive discussion on the state of AI in early 2026. The guests are Nathan Lambert, post-training lead at the Allen Institute for AI (AI2) and author of The RLHF Book, and Sebastian Raschka, author of \u0026amp;ldquo;Build a Large Language Model From Scratch\u0026amp;rdquo; and \u0026amp;ldquo;Build a Reasoning Model From Scratch.\u0026amp;rdquo;\nThe episode covers a wide …","tags":["ai-landscape","scaling-laws","coding-tools","china-ai","agents","agi","podcast"]},
{"title":"LLM coding workflow going into 2026","url":"/sources/2026-01-10-llm-coding-workflow-2026.html","section":"sources","desc":"","content":"Summary Addy Osmani, a well-known Google engineering leader, shared his comprehensive approach to integrating LLMs into daily coding workflows. The article frames LLMs not as autonomous coders but as powerful pair programmers requiring clear direction, context, and consistent oversight.\nThe workflow begins with collaborative planning, where the developer works with an AI to develop detailed …","tags":["workflow","prompt-engineering","model-selection","code-review","testing","agent-workflows"]},
{"title":"Obsidian meets Claude Code: A Markdown graph for agents and context","url":"/sources/2026-02-03-obsidian-claude-code.html","section":"sources","desc":"","content":"Summary Voicetree is an Electron-based desktop application that reimagines the development environment as a spatial graph where markdown notes and AI agent sessions coexist as interconnected nodes. The project merges Obsidian\u0026amp;rsquo;s graph-view visualization paradigm with Claude Code\u0026amp;rsquo;s agentic capabilities, addressing the growing challenge of managing multiple AI agent sessions and their …","tags":["agent-workflows","ide-tools","context-management","obsidian","spatial-computing","developer-tools"]},
{"title":"I spent $638 on AI coding agents in 6 weeks","url":"/sources/2025-11-13-ai-coding-agent-costs.html","section":"sources","desc":"","content":"Summary A founder and CTO building an AI-first CRM product shared a detailed breakdown of their AI coding costs, revealing surprisingly high expenses from using Cursor with Claude models. Over a six-week period spanning October and November 2025, the author accumulated $638 in on-demand charges, with October alone costing $348.56 and hitting Cursor\u0026amp;rsquo;s $400 limit.\nThe cost analysis revealed …","tags":["cost-optimization","cursor","claude-code","model-selection","pricing"]},
{"title":"AI Coding Toolkit: Low-overhead workflow for reliable AI coding","url":"/sources/2026-01-22-ai-coding-toolkit.html","section":"sources","desc":"","content":"Summary The AI Coding Toolkit is an open-source Git repository template designed to provide a structured yet lightweight workflow for semi-autonomous AI coding. The creator developed it after finding that existing AI coding workflows were either too complex (involving dozens of agents running in parallel) or too opinionated for the fast-moving AI coding landscape.\nThe toolkit operates through …","tags":["agent-workflows","sdlc","testing","code-quality","workflow-template"]},
{"title":"Introducing Agentic Vision in Gemini 3 Flash","url":"/sources/2026-02-03-gemini-3-agentic-vision.html","section":"sources","desc":"","content":"Summary Google introduced Agentic Vision as a new capability in Gemini 3 Flash, transforming image understanding from a static analysis task into a dynamic, action-oriented agentic process. Rather than simply analyzing images in isolation, Agentic Vision enables the model to interact with visual content across multiple steps, potentially examining images iteratively and taking actions based on …","tags":["gemini","google","agentic-vision","multimodal","model-release"]},
{"title":"Klaus – a Claude Code native delegating agentic harness","url":"/sources/2026-01-25-klaus-agentic-harness.html","section":"sources","desc":"","content":"Summary Klaus Baudelaire is an open-source agentic harness built entirely on top of Claude Code\u0026amp;rsquo;s native features, designed to automate task delegation and agent routing without external APIs or services. The system addresses the overhead of manually deciding which agent configuration to use for a given prompt by implementing a keyword-based scoring algorithm that evaluates prompt complexity …","tags":["claude-code","agent-workflows","harness-engineering","delegation","tool-routing"]},
{"title":"Claude Skill for Terraform/OpenTofu","url":"/sources/2026-01-19-terraform-skill-claude.html","section":"sources","desc":"","content":"Summary Anton Babenko, a well-known contributor in the Terraform ecosystem and maintainer of many popular terraform-aws-modules, released a Claude Code skill focused on Terraform and OpenTofu best practices. The skill aggregates trusted sources including terraform-best-practices.com and community-tested patterns from over 100 production modules.\nThe skill provides comprehensive guidance across …","tags":["terraform","claude-code","skills","infrastructure-as-code","devops"]}]
